2017-12-11 10:01:59,336 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13900 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:01:59,336 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:02:00,258 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a8c6097: startup date [Mon Dec 11 10:02:00 CST 2017]; root of context hierarchy
2017-12-11 10:02:00,680 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:02:03,696 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:02:05,165 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:02:05,743 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5500 ms
2017-12-11 10:02:06,118 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:02:06,149 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:02:06,149 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:02:07,852 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:02:08,462 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:02:08,618 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88$$FastClassBySpringCGLIB$$4cf0ef7e.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:02:08,790 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:02:08,821 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:02:08,821 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:02:08,821 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:02:08,821 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:02:08,837 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:02:09,352 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 52578.
2017-12-11 10:02:09,383 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:02:09,415 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:02:09,430 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:02:09,430 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:02:09,462 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-ca9c88e4-9251-499e-a13c-6c05798a89bb
2017-12-11 10:02:09,477 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:02:09,571 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:02:09,696 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @14879ms
2017-12-11 10:02:09,805 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:02:09,837 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @15010ms
2017-12-11 10:02:09,852 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@1d182350{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:02:09,852 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:02:09,884 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e6e40d3{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,884 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@102e5c15{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51ae9d7a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@526a153d{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58127114{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76f9a070{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a3ff03f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5068f680{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6564b3de{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d834182{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@703d0b18{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e218346{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b7293a9{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a34738f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f79fa46{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21d1295e{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f7c3feb{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bed4903{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@509e3796{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62b89fa0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@735e0f0d{/static,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a7769a5{/,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e277cad{/api,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18c96507{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3327bd38{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:02:09,930 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:02:10,165 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:02:10,212 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52596.
2017-12-11 10:02:10,212 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:52596
2017-12-11 10:02:10,212 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:02:10,212 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 52596, None)
2017-12-11 10:02:10,212 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:52596 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 52596, None)
2017-12-11 10:02:10,227 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 52596, None)
2017-12-11 10:02:10,227 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 52596, None)
2017-12-11 10:02:10,259 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5775e6b7{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:10,399 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:02:10,399 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:02:10,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6099b325{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:02:10,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e38f03{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:10,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cc81276{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:02:10,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13fba53a{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:02:10,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7682677e{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:02:11,337 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:02:11,571 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:02:12,368 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:02:12,384 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:02:12,384 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:02:12,602 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:02:12,602 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:02:12,774 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a8c6097: startup date [Mon Dec 11 10:02:00 CST 2017]; root of context hierarchy
2017-12-11 10:02:12,790 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:02:12,915 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:02:12,946 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:02:16,524 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:02:16,649 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:02:16,649 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:02:16,649 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:02:16,696 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:02:16,743 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:02:17,587 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:02:17,728 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:02:18,009 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:02:18,087 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:02:18,212 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:02:18,228 INFO [restartedMain]                       com.Application : Started Application in 20.329 seconds (JVM running for 23.408)
2017-12-11 10:03:41,058 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:03:41,058 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:03:41,105 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms
2017-12-11 10:03:41,121 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:03:41,168 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:03:41,227 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:03:41,330 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:03:42,164 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:03:42,205 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:07:01,066 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:07:01,071 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/index] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:07:21,476 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1496 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:07:21,476 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:07:22,476 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:07:22 CST 2017]; root of context hierarchy
2017-12-11 10:07:22,882 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:07:26,163 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:07:28,116 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:07:28,773 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6344 ms
2017-12-11 10:07:29,398 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:07:29,413 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:07:29,413 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:07:30,773 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:07:31,195 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:07:31,320 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7306c2bf.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7306c2bf$$FastClassBySpringCGLIB$$56b7c9bd.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7306c2bf.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:07:31,492 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:07:31,538 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:07:31,538 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:07:31,538 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:07:31,538 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:07:31,538 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:07:32,132 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 52718.
2017-12-11 10:07:32,163 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:07:32,226 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:07:32,242 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:07:32,242 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:07:32,273 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-00a00365-f382-4da3-afda-fbdbbf0f2d16
2017-12-11 10:07:32,304 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:07:32,476 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:07:32,773 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @15593ms
2017-12-11 10:07:33,304 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:07:33,382 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @16212ms
2017-12-11 10:07:33,679 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@38e7f2b1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:07:33,679 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:07:33,773 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f03a169{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,773 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51c77dc{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,773 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2179522b{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1409ea31{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f1b4295{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63495e40{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@196272d2{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59f6fb4e{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67806596{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d66efd7{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@658790c{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,835 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dac5db4{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,835 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a6b5c8a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@624a0ccb{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ba1891f{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@618ab899{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dee3591{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ca6b840{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,851 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fe267e8{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,867 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ae230b8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51ed7fcf{/static,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a084552{/,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@339308f5{/api,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17e83597{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47a6d543{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:07:33,898 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:07:34,164 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:07:34,210 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52735.
2017-12-11 10:07:34,210 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:52735
2017-12-11 10:07:34,210 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:07:34,210 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 52735, None)
2017-12-11 10:07:34,226 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:52735 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 52735, None)
2017-12-11 10:07:34,226 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 52735, None)
2017-12-11 10:07:34,226 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 52735, None)
2017-12-11 10:07:34,273 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14fda60e{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:34,429 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:07:34,429 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:07:34,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@180b09ba{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:07:34,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5868647e{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:34,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f3a1c47{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:07:34,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@154972d2{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:07:34,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@280c22ec{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:07:35,798 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:07:36,267 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:07:37,548 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:07:37,548 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:07:37,548 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:07:37,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:07:37,580 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:07:37,580 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:07:37,798 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:07:37,798 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:07:37,970 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:07:22 CST 2017]; root of context hierarchy
2017-12-11 10:07:38,002 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:07:38,111 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:07:38,158 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:07:40,455 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:07:40,595 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:07:40,611 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:07:40,611 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:07:40,658 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:07:40,689 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:07:41,830 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:07:41,955 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:07:42,220 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:07:42,361 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:07:42,674 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:07:42,689 INFO [restartedMain]                       com.Application : Started Application in 22.62 seconds (JVM running for 25.515)
2017-12-11 10:07:59,335 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:07:59,335 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:07:59,382 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms
2017-12-11 10:07:59,397 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:07:59,447 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:07:59,494 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:07:59,494 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:07:59,494 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:07:59,494 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:07:59,510 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:07:59,510 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:07:59,572 ERROR [http-nio-8080-exec-1] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-1] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 27; columnNumber: 5; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:07:59,588 ERROR [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-1] Exception processing template "index": Exception parsing document: template="index", line 27 - column 5
2017-12-11 10:07:59,588 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 27 - column 5] with root cause
org.xml.sax.SAXParseException; lineNumber: 27; columnNumber: 5; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:09:22,155 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:09:22,163 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/test] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:09:26,143 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:09:26,147 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/test] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:11:07,271 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 7012 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:11:07,271 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:11:08,428 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@24c531ee: startup date [Mon Dec 11 10:11:08 CST 2017]; root of context hierarchy
2017-12-11 10:11:08,584 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:11:12,443 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:11:15,506 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:11:16,115 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7719 ms
2017-12-11 10:11:16,537 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:11:16,553 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:11:16,569 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:11:17,694 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:11:18,006 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:11:18,115 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$34f2ed5f.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$34f2ed5f$$FastClassBySpringCGLIB$$48084405.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$34f2ed5f.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:11:18,256 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:11:18,319 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:11:18,319 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:11:18,319 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:11:18,350 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:11:18,350 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:11:18,897 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 52814.
2017-12-11 10:11:19,147 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:11:19,178 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:11:19,178 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:11:19,194 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:11:19,194 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e9c075f0-45d9-4c07-ab5c-476c118466ab
2017-12-11 10:11:19,225 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:11:19,303 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:11:19,444 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @17550ms
2017-12-11 10:11:19,569 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:11:19,584 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @17691ms
2017-12-11 10:11:19,616 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@37c45abd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:11:19,616 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:11:19,647 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f92e234{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,647 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67fd100{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,647 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47d30eb{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c9f9a45{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60e83234{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1015a667{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@402e7a03{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69c1a61a{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9cf7812{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56641cc2{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b9ff6c6{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@534beca1{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4efd1292{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c88ec63{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@179cbc54{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@de69c75{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5419928c{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f58e963{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ef176e8{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46292bba{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,694 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75f2a826{/static,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,694 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19fd5c5d{/,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,709 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a81e61e{/api,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,709 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a4c44c1{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,709 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ac93787{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:11:19,709 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:11:19,944 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:11:19,975 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52831.
2017-12-11 10:11:19,975 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:52831
2017-12-11 10:11:19,975 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:11:19,991 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 52831, None)
2017-12-11 10:11:19,991 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:52831 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 52831, None)
2017-12-11 10:11:19,991 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 52831, None)
2017-12-11 10:11:19,991 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 52831, None)
2017-12-11 10:11:20,022 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b017851{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:20,303 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:11:20,303 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:11:20,319 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5969228{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:11:20,319 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4eaace0e{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:20,319 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43a1ed1e{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:11:20,319 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53f1bed8{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:11:20,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5aaf8117{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:11:21,959 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:11:22,350 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:11:23,319 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:11:23,334 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:11:23,334 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:11:23,334 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:11:23,350 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:11:23,350 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:11:23,584 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:11:24,366 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:11:24,475 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@24c531ee: startup date [Mon Dec 11 10:11:08 CST 2017]; root of context hierarchy
2017-12-11 10:11:24,491 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:11:24,569 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:11:24,584 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:11:27,069 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:11:27,194 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:11:27,210 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:11:27,210 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:11:27,256 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:11:27,319 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:11:29,100 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:11:29,600 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:11:30,194 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:11:30,382 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:11:30,725 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:11:31,038 INFO [restartedMain]                       com.Application : Started Application in 25.423 seconds (JVM running for 29.135)
2017-12-11 10:11:36,521 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:11:36,521 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:11:36,693 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 172 ms
2017-12-11 10:11:36,725 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:11:36,844 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:11:36,953 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:11:37,032 ERROR [http-nio-8080-exec-1] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-1] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:11:37,047 ERROR [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-1] Exception processing template "test": Exception parsing document: template="test", line 6 - column 3
2017-12-11 10:11:37,047 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="test", line 6 - column 3] with root cause
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:11:58,045 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:11:58,045 ERROR [http-nio-8080-exec-2] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-2] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:11:58,061 ERROR [http-nio-8080-exec-2]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-2] Exception processing template "test": Exception parsing document: template="test", line 6 - column 3
2017-12-11 10:11:58,061 ERROR [http-nio-8080-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="test", line 6 - column 3] with root cause
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:11:59,228 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:11:59,228 ERROR [http-nio-8080-exec-3] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-3] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:11:59,244 ERROR [http-nio-8080-exec-3]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-3] Exception processing template "test": Exception parsing document: template="test", line 6 - column 3
2017-12-11 10:11:59,244 ERROR [http-nio-8080-exec-3] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="test", line 6 - column 3] with root cause
org.xml.sax.SAXParseException; lineNumber: 6; columnNumber: 3; The element type "meta" must be terminated by the matching end-tag "</meta>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:12:11,012 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 8756 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:12:11,012 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:12:11,871 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1cce2ce6: startup date [Mon Dec 11 10:12:11 CST 2017]; root of context hierarchy
2017-12-11 10:12:12,184 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:12:19,223 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:12:21,125 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:12:21,851 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 9996 ms
2017-12-11 10:12:22,195 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:12:22,211 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:12:22,211 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:12:23,428 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:12:24,007 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:12:24,273 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$9a673c2d.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$9a673c2d$$FastClassBySpringCGLIB$$b20ed4b3.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$9a673c2d.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:12:24,586 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:12:24,664 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:12:24,664 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:12:24,664 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:12:24,664 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:12:24,679 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:12:25,876 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 52929.
2017-12-11 10:12:25,923 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:12:25,965 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:12:25,965 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:12:25,965 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:12:25,996 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-ea0fedae-a144-47af-a4f1-c94424eff19b
2017-12-11 10:12:26,043 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:12:26,168 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:12:26,348 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @20839ms
2017-12-11 10:12:26,640 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:12:26,678 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @21161ms
2017-12-11 10:12:26,730 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@360e589f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:12:26,730 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:12:26,813 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57f7ddb7{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,815 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a6e161d{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,817 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@640c65eb{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,821 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cfc021a{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@131b99a7{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,827 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ce9d3f5{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,829 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@809ea46{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,832 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19042c4{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,833 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38d86eb{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,835 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@207835d9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72886353{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e27d111{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,839 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a8a31b9{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,840 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42836b6b{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,841 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68ec2606{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,844 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@772c0bb5{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,847 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b1d4867{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,856 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dbe3354{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,860 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a4eeed6{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,862 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b83a080{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,923 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@434f9373{/static,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a3c9520{/,null,AVAILABLE,@Spark}
2017-12-11 10:12:26,936 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71d29f87{/api,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,009 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c87702d{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,011 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5436013{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,022 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:12:27,337 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:12:27,411 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52957.
2017-12-11 10:12:27,413 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:52957
2017-12-11 10:12:27,416 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:12:27,420 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 52957, None)
2017-12-11 10:12:27,428 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:52957 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 52957, None)
2017-12-11 10:12:27,439 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 52957, None)
2017-12-11 10:12:27,441 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 52957, None)
2017-12-11 10:12:27,508 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@456c35e4{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,700 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:12:27,700 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:12:27,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2db1c57d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b6d5950{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12cfd41{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,732 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a77a1b3{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:12:27,732 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b669441{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:12:28,815 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:12:29,155 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:12:30,194 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:12:30,196 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:12:30,196 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:12:30,200 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:12:30,200 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:12:30,201 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:12:30,202 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:12:30,202 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:12:30,202 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:12:30,203 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:12:30,207 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:12:30,227 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:12:30,228 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:12:30,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:12:30,231 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:12:30,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:12:30,842 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:12:30,842 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:12:31,119 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1cce2ce6: startup date [Mon Dec 11 10:12:11 CST 2017]; root of context hierarchy
2017-12-11 10:12:31,167 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:12:31,408 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:12:31,492 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:12:35,847 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:12:36,045 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:12:36,094 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:12:36,094 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:12:36,223 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:12:36,286 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:12:37,502 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:12:37,737 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:12:38,123 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:12:38,201 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:12:38,342 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:12:38,358 INFO [restartedMain]                       com.Application : Started Application in 28.728 seconds (JVM running for 32.845)
2017-12-11 10:15:01,885 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:15:01,885 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:15:01,947 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 62 ms
2017-12-11 10:15:01,963 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:15:02,025 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * HTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:15:02,119 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:15:09,641 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:15:09,660 ERROR [http-nio-8080-exec-2] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-2] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:15:09,668 ERROR [http-nio-8080-exec-2]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-2] Exception processing template "index": Exception parsing document: template="index", line 67 - column 5
2017-12-11 10:15:09,670 ERROR [http-nio-8080-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 67 - column 5] with root cause
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:16:22,276 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:16:22,276 ERROR [http-nio-8080-exec-4] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-4] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:16:22,307 ERROR [http-nio-8080-exec-4]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-4] Exception processing template "index": Exception parsing document: template="index", line 67 - column 5
2017-12-11 10:16:22,307 ERROR [http-nio-8080-exec-4] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 67 - column 5] with root cause
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:16:22,963 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:16:22,979 ERROR [http-nio-8080-exec-5] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-5] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:16:22,995 ERROR [http-nio-8080-exec-5]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-5] Exception processing template "index": Exception parsing document: template="index", line 67 - column 5
2017-12-11 10:16:22,995 ERROR [http-nio-8080-exec-5] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 67 - column 5] with root cause
org.xml.sax.SAXParseException; lineNumber: 67; columnNumber: 5; The element type "hr" must be terminated by the matching end-tag "</hr>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:17:06,733 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13492 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:17:06,779 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:17:07,811 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:17:07 CST 2017]; root of context hierarchy
2017-12-11 10:17:08,139 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:17:11,876 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:17:13,452 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:17:14,170 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6359 ms
2017-12-11 10:17:14,577 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:17:14,592 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:17:14,592 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:17:16,358 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:17:17,077 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:17:17,374 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$d3848d02.CGLIB$getSparkContext$4(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$d3848d02$$FastClassBySpringCGLIB$$a6c46c61.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$d3848d02.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:17:17,635 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:17:17,713 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:17:17,713 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:17:17,713 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:17:17,713 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:17:17,713 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:17:18,282 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 53325.
2017-12-11 10:17:18,298 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:17:18,313 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:17:18,329 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:17:18,329 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:17:18,329 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e07c22da-e5ed-4016-a13c-8e7c2c7b1655
2017-12-11 10:17:18,360 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:17:18,423 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:17:18,548 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @16224ms
2017-12-11 10:17:18,642 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:17:18,657 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @16339ms
2017-12-11 10:17:18,688 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2199a5b3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:17:18,688 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20346f3a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fd7162a{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f0a0a91{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63495e40{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@196272d2{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5bc97b02{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59f6fb4e{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d66efd7{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@658790c{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dac5db4{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a6b5c8a{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@624a0ccb{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ba1891f{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@618ab899{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dee3591{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ca6b840{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fe267e8{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,767 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ae230b8{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,782 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51ed7fcf{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,782 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56a3cdb4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@654a9165{/static,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54b90888{/,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@685d938c{/api,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56f32536{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bcb990f{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:17:18,813 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:17:19,032 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:17:19,110 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53342.
2017-12-11 10:17:19,110 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:53342
2017-12-11 10:17:19,110 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:17:19,126 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 53342, None)
2017-12-11 10:17:19,126 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:53342 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 53342, None)
2017-12-11 10:17:19,126 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 53342, None)
2017-12-11 10:17:19,126 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 53342, None)
2017-12-11 10:17:19,173 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cfa4753{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:19,360 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:17:19,360 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:17:19,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ce98935{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:17:19,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b9f9330{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:19,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d4f856c{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:17:19,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38ea10be{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:17:19,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62883a02{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:17:20,360 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:17:20,579 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:17:21,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:17:21,592 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:17:21,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:17:21,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:17:21,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:17:21,623 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:17:21,623 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:17:21,920 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:17:21,920 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:17:22,030 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:17:07 CST 2017]; root of context hierarchy
2017-12-11 10:17:22,061 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:17:22,170 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:17:22,201 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:17:25,346 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:17:25,455 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:17:25,471 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:17:25,471 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:17:25,517 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:17:25,564 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:17:27,372 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:17:27,585 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:17:27,963 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:17:28,085 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:17:28,368 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:17:28,368 INFO [restartedMain]                       com.Application : Started Application in 22.973 seconds (JVM running for 26.056)
2017-12-11 10:17:49,272 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:17:49,272 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:17:49,319 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms
2017-12-11 10:17:49,335 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:17:49,397 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:17:49,538 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:17:49,538 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:17:49,553 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:17:49,553 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:17:49,569 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:17:49,569 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:17:49,712 ERROR [http-nio-8080-exec-1] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-1] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:17:49,743 ERROR [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-1] Exception processing template "index": Exception parsing document: template="index", line 52 - column 7
2017-12-11 10:17:49,743 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 52 - column 7] with root cause
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:20:21,769 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 9016 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:20:21,816 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:20:22,862 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@52eec52d: startup date [Mon Dec 11 10:20:22 CST 2017]; root of context hierarchy
2017-12-11 10:20:23,074 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:20:29,807 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:20:31,697 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:20:32,252 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 9390 ms
2017-12-11 10:20:32,678 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:20:32,678 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:20:32,678 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:20:34,667 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:20:35,294 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:20:35,546 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4c13e0de.CGLIB$getSparkContext$5(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4c13e0de$$FastClassBySpringCGLIB$$bcad2e5.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4c13e0de.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:20:35,755 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:20:35,794 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:20:35,795 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:20:35,797 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:20:35,798 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:20:35,799 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:20:36,358 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 53520.
2017-12-11 10:20:36,374 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:20:36,405 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:20:36,405 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:20:36,405 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:20:36,420 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-14c4cd11-5fab-4f4b-a6eb-983b6a2c26e2
2017-12-11 10:20:36,452 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:20:36,533 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:20:36,668 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @18653ms
2017-12-11 10:20:36,778 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:20:36,799 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @18788ms
2017-12-11 10:20:36,829 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@5324f1ae{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:20:36,829 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76388622{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e205721{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@607106b2{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41236502{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@777c8afe{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@511cc58a{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1607c637{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,858 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@161f0bbc{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cca69c9{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46f28ad5{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f09faef{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@744c6349{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@660a104f{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8beb55{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4212e0be{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e3372f7{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f39c522{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@340d5dd3{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71fdfcb2{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f527fd0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,899 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6043e8c3{/static,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,900 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@592486ba{/,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,904 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@446a37b0{/api,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,906 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19e8df40{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,907 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f3fd03d{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:20:36,912 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:20:37,191 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:20:37,256 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53537.
2017-12-11 10:20:37,256 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:53537
2017-12-11 10:20:37,256 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:20:37,256 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 53537, None)
2017-12-11 10:20:37,256 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:53537 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 53537, None)
2017-12-11 10:20:37,272 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 53537, None)
2017-12-11 10:20:37,272 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 53537, None)
2017-12-11 10:20:37,317 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8607c24{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:37,491 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:20:37,491 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:20:37,491 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13423b65{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:20:37,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cedb800{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:37,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fb79053{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:20:37,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b2d8e13{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:20:37,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7195535b{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:20:38,437 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:20:38,737 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:20:39,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:20:39,420 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:20:39,420 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:20:39,420 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:20:39,452 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:20:39,452 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:20:39,699 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:20:39,699 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:20:39,824 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@52eec52d: startup date [Mon Dec 11 10:20:22 CST 2017]; root of context hierarchy
2017-12-11 10:20:39,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:20:39,935 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:20:39,955 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:20:43,302 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:20:43,427 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:20:43,442 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:20:43,458 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:20:43,505 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:20:43,536 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:20:44,359 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:20:44,496 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:20:44,802 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:20:44,893 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:20:45,027 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:20:45,043 INFO [restartedMain]                       com.Application : Started Application in 24.543 seconds (JVM running for 27.041)
2017-12-11 10:21:56,186 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:21:56,186 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:21:56,232 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 46 ms
2017-12-11 10:21:56,248 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:21:56,326 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:21:56,448 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:21:56,448 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:21:56,448 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:21:56,448 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:21:56,463 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:21:56,463 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:21:56,557 ERROR [http-nio-8080-exec-1] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-1] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:21:56,573 ERROR [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-1] Exception processing template "index": Exception parsing document: template="index", line 52 - column 7
2017-12-11 10:21:56,573 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 52 - column 7] with root cause
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:21:56,856 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:21:56,882 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:21:58,181 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:21:58,181 ERROR [http-nio-8080-exec-3] org.thymeleaf.templateparser.ErrorHandler : [THYMELEAF][http-nio-8080-exec-3] Fatal error during parsing
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:21:58,196 ERROR [http-nio-8080-exec-3]          org.thymeleaf.TemplateEngine : [THYMELEAF][http-nio-8080-exec-3] Exception processing template "index": Exception parsing document: template="index", line 52 - column 7
2017-12-11 10:21:58,196 ERROR [http-nio-8080-exec-3] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Exception parsing document: template="index", line 52 - column 7] with root cause
org.xml.sax.SAXParseException; lineNumber: 52; columnNumber: 7; The element type "body" must be terminated by the matching end-tag "</body>".
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.doParse(AbstractNonValidatingSAXTemplateParser.java:209)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplateUsingPool(AbstractNonValidatingSAXTemplateParser.java:134)
	at org.thymeleaf.templateparser.xmlsax.AbstractNonValidatingSAXTemplateParser.parseTemplate(AbstractNonValidatingSAXTemplateParser.java:116)
	at org.thymeleaf.TemplateRepository.getTemplate(TemplateRepository.java:278)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1104)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1060)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1011)
	at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:335)
	at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:190)
	at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1282)
	at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1037)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:980)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at com.spark.config.CorsFilter.doFilter(CorsFilter.java:26)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2017-12-11 10:23:24,380 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 8596 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:23:24,380 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:23:25,381 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@420f2815: startup date [Mon Dec 11 10:23:25 CST 2017]; root of context hierarchy
2017-12-11 10:23:25,521 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:23:31,934 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:23:34,074 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:23:34,900 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 9519 ms
2017-12-11 10:23:35,278 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:23:35,306 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:23:35,307 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:23:36,468 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:23:37,503 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:23:37,776 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4a5c9424.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4a5c9424$$FastClassBySpringCGLIB$$ab622f80.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$4a5c9424.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:23:38,092 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:23:38,233 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:23:38,233 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:23:38,233 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:23:38,233 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:23:38,233 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:23:40,868 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 53803.
2017-12-11 10:23:40,916 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:23:40,963 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:23:40,987 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:23:40,989 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:23:41,017 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e0500c29-a10d-4cbc-8a80-9cfdfc9cfabd
2017-12-11 10:23:41,060 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:23:41,197 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:23:41,426 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @21657ms
2017-12-11 10:23:41,535 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:23:41,566 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @21797ms
2017-12-11 10:23:41,597 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@7fcb51ad{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:23:41,597 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24c4a12e{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74c8ff73{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f45ddd5{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f4716de{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5473b531{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@388aeee9{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41589b0e{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70ba7f14{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dc618e7{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2347d37c{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7defb541{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@524fd9a7{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ee171a6{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c871457{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,676 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33a4a40f{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cffd25a{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@208332e2{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@82d036c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ccba012{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@653d5248{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,707 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35c32cc8{/static,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,707 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60baa36c{/,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,707 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35c03bea{/api,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,707 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2803a19a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,707 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4769387d{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:23:41,722 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:23:42,006 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:23:42,084 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53821.
2017-12-11 10:23:42,084 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:53821
2017-12-11 10:23:42,084 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:23:42,084 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 53821, None)
2017-12-11 10:23:42,100 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:53821 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 53821, None)
2017-12-11 10:23:42,100 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 53821, None)
2017-12-11 10:23:42,100 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 53821, None)
2017-12-11 10:23:42,162 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bebfeb8{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:42,340 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:23:42,341 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:23:42,354 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75f79dcf{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:23:42,355 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f39c1c0{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:42,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ef9275a{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:23:42,358 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@191ad862{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:23:42,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@777d35e2{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:23:43,762 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:23:44,052 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:23:44,927 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:23:44,930 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:23:44,930 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:23:44,936 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:23:44,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:23:44,938 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:23:44,939 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:23:44,939 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:23:44,940 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:23:44,941 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:23:44,944 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:23:44,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:23:44,965 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:23:44,968 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:23:44,994 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:23:44,995 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:23:45,427 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:23:45,427 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:23:45,630 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@420f2815: startup date [Mon Dec 11 10:23:25 CST 2017]; root of context hierarchy
2017-12-11 10:23:45,646 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:23:46,094 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:23:46,196 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:23:49,076 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:23:49,217 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:23:49,232 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:23:49,232 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:23:49,295 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:23:49,326 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:23:50,376 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:23:50,595 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:23:50,923 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:23:51,032 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:23:51,188 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:23:51,204 INFO [restartedMain]                       com.Application : Started Application in 27.87 seconds (JVM running for 31.442)
2017-12-11 10:24:44,260 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:24:44,260 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:24:44,291 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 31 ms
2017-12-11 10:24:44,322 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,385 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:24:44,432 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:24:44,432 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:24:44,432 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:24:44,432 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:24:44,447 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:24:44,447 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,582 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,597 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,582 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,597 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,597 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,582 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,613 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,566 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,613 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,597 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,613 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,791 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,793 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,814 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,816 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,832 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,834 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,851 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,855 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,873 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,878 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,891 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,894 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,910 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,912 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,921 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,923 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:44,932 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:44,939 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:54,081 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:54,081 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:54,085 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:54,087 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:24:54,083 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:24:54,089 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,454 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,613 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,614 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,615 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,617 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,615 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,622 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,657 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,669 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,687 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,689 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,696 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,697 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,702 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,703 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,712 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,714 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,719 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,721 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,723 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,726 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,732 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,733 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,736 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,738 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:48,751 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:48,752 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,330 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,411 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,413 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,449 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,450 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,450 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,450 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,451 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,452 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,454 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,455 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,457 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,462 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,461 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,460 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,460 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,468 WARN [http-nio-8080-exec-18] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,457 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,468 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,467 WARN [http-nio-8080-exec-16] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,463 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,487 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,463 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,463 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,463 WARN [http-nio-8080-exec-17] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,497 WARN [http-nio-8080-exec-15] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,475 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,612 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,613 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,629 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,630 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,646 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,647 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,677 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,678 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,704 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,707 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,729 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,730 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,758 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,759 WARN [http-nio-8080-exec-18] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,784 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,786 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:50,817 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:50,818 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:26:51,065 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:26:51,093 WARN [http-nio-8080-exec-16] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:27:35,634 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1192 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:27:35,638 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:27:37,462 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a8c6097: startup date [Mon Dec 11 10:27:37 CST 2017]; root of context hierarchy
2017-12-11 10:27:37,537 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:27:42,241 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:27:44,117 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:27:45,404 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7957 ms
2017-12-11 10:27:46,244 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:27:46,259 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:27:46,260 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:27:47,536 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:27:47,985 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:27:48,125 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88.CGLIB$getSparkContext$4(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88$$FastClassBySpringCGLIB$$4cf0ef7e.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$18ef5c88.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:27:48,277 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:27:48,340 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:27:48,340 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:27:48,340 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:27:48,355 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:27:48,355 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:27:49,048 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 53935.
2017-12-11 10:27:49,079 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:27:49,111 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:27:49,126 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:27:49,126 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:27:49,142 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-d8381070-6689-4c59-8665-2ae175b4686c
2017-12-11 10:27:49,173 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:27:49,302 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:27:49,411 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @18480ms
2017-12-11 10:27:49,520 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:27:49,552 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @18613ms
2017-12-11 10:27:49,599 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2399dc46{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:27:49,599 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:27:49,645 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4674e2fd{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a0cb76d{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@526a153d{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74b88027{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@516ea1d7{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ab6f2e7{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35334611{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ac872ad{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3087a495{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79e952a8{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@330f2b1b{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@183de87d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60a9c221{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28708fd4{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f475f8f{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33de0dff{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e63c6d6{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13ec698f{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,692 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@525da057{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,692 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38eb0f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a0d2944{/static,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23c0991c{/,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27831ba8{/api,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b62f85c{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c837296{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:27:49,708 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:27:49,923 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:27:49,970 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53953.
2017-12-11 10:27:49,970 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:53953
2017-12-11 10:27:49,985 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:27:49,985 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 53953, None)
2017-12-11 10:27:49,985 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:53953 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 53953, None)
2017-12-11 10:27:50,001 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 53953, None)
2017-12-11 10:27:50,003 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 53953, None)
2017-12-11 10:27:50,037 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17afcca2{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:50,178 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:27:50,178 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:27:50,225 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b0322b6{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:27:50,225 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60698906{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:50,225 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@94166bb{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:27:50,225 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@bbdd9ec{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:27:50,225 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@274282d2{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:27:51,273 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:27:51,589 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:27:53,083 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:27:53,086 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:27:53,086 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:27:53,091 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:27:53,092 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:27:53,092 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:27:53,093 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:27:53,093 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:27:53,096 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:27:53,097 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:27:53,108 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:27:53,141 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:27:53,144 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:27:53,147 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:27:53,181 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:27:53,199 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:27:53,884 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:27:53,884 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:27:54,199 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a8c6097: startup date [Mon Dec 11 10:27:37 CST 2017]; root of context hierarchy
2017-12-11 10:27:54,261 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:27:54,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:27:54,556 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:27:57,319 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:27:57,681 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:27:57,712 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:27:57,712 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:27:57,850 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:27:57,918 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:28:01,884 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:28:02,679 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:28:04,026 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:28:04,390 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:28:05,261 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:28:05,300 INFO [restartedMain]                       com.Application : Started Application in 31.197 seconds (JVM running for 34.357)
2017-12-11 10:28:47,350 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:28:47,350 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:28:47,491 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 141 ms
2017-12-11 10:28:47,522 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:47,654 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:28:47,810 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:28:47,810 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:28:47,810 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:28:47,810 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:28:47,826 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * XML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:28:47,826 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:28:48,089 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,093 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,104 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,106 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,109 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,111 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,115 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,120 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,127 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,131 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,133 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,136 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,139 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,140 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,142 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,147 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,162 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,170 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,191 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,194 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,204 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,211 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,218 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,223 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,218 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,229 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,397 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,494 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,512 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,514 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,530 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,531 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,553 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,555 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,567 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,569 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,581 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,583 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,603 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,605 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,623 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,625 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:28:48,638 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:28:48,640 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:33:51,780 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a8c6097: startup date [Mon Dec 11 10:27:37 CST 2017]; root of context hierarchy
2017-12-11 10:33:51,793 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:33:51,794 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:33:51,808 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2399dc46{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:33:51,811 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:33:51,830 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:33:51,846 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:33:51,846 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:33:51,847 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:33:51,854 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:33:51,859 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:33:52,239 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 10:33:52,262 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:33:52,307 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 10:33:53,199 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1192 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:33:53,199 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:33:53,215 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1608804a: startup date [Mon Dec 11 10:33:53 CST 2017]; root of context hierarchy
2017-12-11 10:33:56,116 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:33:58,352 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:33:58,481 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5266 ms
2017-12-11 10:33:58,756 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:33:58,756 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:33:58,758 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:33:59,043 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:33:59,073 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:33:59,075 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:33:59,076 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:33:59,076 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:33:59,076 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:33:59,076 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:33:59,184 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54217.
2017-12-11 10:33:59,184 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:33:59,246 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:33:59,247 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:33:59,247 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:33:59,267 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-8d10be37-641b-41e9-a7a9-53054c391239
2017-12-11 10:33:59,270 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:33:59,274 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:33:59,315 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:33:59,315 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @388379ms
2017-12-11 10:33:59,315 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2b92a6c9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:33:59,315 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:33:59,315 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@175870eb{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,333 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@511eceff{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b8f74c8{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,335 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@208a1c8e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,336 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bdbada8{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,337 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e39c971{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@765cfbff{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76dbc962{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,340 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@235a4e0{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,341 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23890b10{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,342 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@268a4a8d{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,343 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c9e0445{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,344 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e5a33dd{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,345 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37aadc3a{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,346 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@143c0da1{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,348 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c0cff7f{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,352 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ba35f6a{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,353 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@184e502c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,353 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@464ffd6a{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,354 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a8f43ea{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1151bff2{/static,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,359 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5449dfef{/,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,383 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e351fe{/api,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,383 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19018dff{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,383 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63d6f1e6{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,383 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:33:59,494 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:33:59,515 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54234.
2017-12-11 10:33:59,515 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54234
2017-12-11 10:33:59,515 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:33:59,515 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54234, None)
2017-12-11 10:33:59,515 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54234 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54234, None)
2017-12-11 10:33:59,515 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54234, None)
2017-12-11 10:33:59,515 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54234, None)
2017-12-11 10:33:59,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@510828c3{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,531 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:33:59,531 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:33:59,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ce47c6b{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a282cee{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79d72cdc{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58d77b2a{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8ac69fb{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:33:59,587 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:34:00,046 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:34:00,046 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:34:00,046 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:34:00,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:34:00,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:34:00,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:34:00,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:34:00,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:34:00,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:34:00,242 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:34:00,242 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:34:00,448 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1608804a: startup date [Mon Dec 11 10:33:53 CST 2017]; root of context hierarchy
2017-12-11 10:34:00,456 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:34:00,486 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:34:00,486 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:34:01,059 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:34:01,257 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:34:01,266 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:34:01,266 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:34:01,267 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:34:01,304 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:34:01,631 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:01,885 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:02,169 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:02,228 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:34:02,253 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:34:02,258 INFO [restartedMain]                       com.Application : Started Application in 9.205 seconds (JVM running for 391.316)
2017-12-11 10:34:19,065 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1608804a: startup date [Mon Dec 11 10:33:53 CST 2017]; root of context hierarchy
2017-12-11 10:34:19,065 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:34:19,065 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:34:19,065 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2b92a6c9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:34:19,097 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:34:19,097 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:34:19,143 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:34:19,143 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:34:19,143 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:34:19,143 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:34:19,204 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:34:20,865 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1192 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:34:20,865 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:34:20,865 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3b861a5f: startup date [Mon Dec 11 10:34:20 CST 2017]; root of context hierarchy
2017-12-11 10:34:23,986 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:34:24,768 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:34:24,815 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3950 ms
2017-12-11 10:34:24,883 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:34:24,883 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:34:24,883 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:34:24,955 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:34:24,956 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:34:24,959 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:34:24,959 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:34:24,959 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:34:24,960 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:34:24,961 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:34:25,000 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54262.
2017-12-11 10:34:25,000 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:34:25,000 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:34:25,000 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:34:25,000 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:34:25,016 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-1c1ec19b-ad5a-4556-b94a-87ca24040092
2017-12-11 10:34:25,016 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:34:25,016 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:34:25,079 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:34:25,079 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @414150ms
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@7537a41d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:34:25,094 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63b8e033{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ce2b42b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3020372a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4830e85e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@279575d{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e9017f8{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@680fa9dd{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c956893{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f4a4cd8{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e79ca49{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b56b666{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d945c85{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2dc16e2e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70d470c3{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6516a623{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12462e96{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f1a418{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b3e148a{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37b889c7{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,110 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@199fcba3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7833b6d4{/static,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d63cb91{/,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40fafd6{/api,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a2a973a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a98c925{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,125 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:34:25,157 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:34:25,172 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54279.
2017-12-11 10:34:25,172 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54279
2017-12-11 10:34:25,172 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:34:25,172 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54279, None)
2017-12-11 10:34:25,172 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54279 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54279, None)
2017-12-11 10:34:25,172 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54279, None)
2017-12-11 10:34:25,172 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54279, None)
2017-12-11 10:34:25,172 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c347b58{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:34:25,188 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:34:25,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29086d5a{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f149963{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6980b190{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@296dd2ac{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11264010{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:34:25,188 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:34:25,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:34:25,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:34:25,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:34:25,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:34:25,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:34:25,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:34:25,504 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:34:25,504 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:34:25,555 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3b861a5f: startup date [Mon Dec 11 10:34:20 CST 2017]; root of context hierarchy
2017-12-11 10:34:25,560 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:34:25,579 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:34:25,584 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:34:26,066 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:34:26,372 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:34:26,378 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:34:26,378 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:34:26,379 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:34:26,385 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:34:26,897 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:27,140 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:27,427 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:34:27,541 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:34:27,665 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:34:27,669 INFO [restartedMain]                       com.Application : Started Application in 6.93 seconds (JVM running for 416.725)
2017-12-11 10:37:12,611 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:37:12,611 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 0 ms
2017-12-11 10:37:12,611 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:12,611 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:37:12,627 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:37:12,627 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:37:12,627 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:37:12,627 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:37:12,642 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * XML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:37:12,642 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:37:12,964 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:12,995 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:12,964 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:12,964 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,073 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,090 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,096 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:12,964 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,104 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,127 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,200 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,066 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,321 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,051 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,050 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,354 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bcss/jsplumb.css%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,026 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,368 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,026 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,391 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bcss/bootstrap.min.css%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,216 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,415 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,214 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,459 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,209 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,481 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bcss/bootstrap-treeview.min.css%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,516 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,522 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,546 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,550 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,584 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,588 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,613 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,615 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,649 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,650 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,906 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,910 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,925 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,926 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,942 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,944 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:13,955 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:13,958 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,617 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,715 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,716 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,717 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,717 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,718 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,717 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,722 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,722 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,722 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,722 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,722 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,754 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,754 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,754 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,754 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,754 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,754 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,754 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,754 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,754 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,754 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,872 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,873 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,915 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,917 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,947 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,949 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:46,990 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:46,991 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:47,025 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:47,028 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:47,123 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:47,124 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:47,149 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:47,151 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:47,209 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:47,210 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:37:47,241 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:37:47,242 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:38:19,977 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14232 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:38:19,977 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:38:21,195 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3513ee5c: startup date [Mon Dec 11 10:38:21 CST 2017]; root of context hierarchy
2017-12-11 10:38:21,521 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:38:26,681 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:38:28,888 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:38:29,516 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 8336 ms
2017-12-11 10:38:30,011 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:38:30,041 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:38:30,042 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:38:31,583 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:38:32,058 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:38:32,171 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$e4a0034e.CGLIB$getSparkContext$1(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$e4a0034e$$FastClassBySpringCGLIB$$8945cdba.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$e4a0034e.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:38:32,301 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:38:32,340 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:38:32,341 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:38:32,343 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:38:32,345 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:38:32,346 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:38:32,890 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54422.
2017-12-11 10:38:32,921 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:38:32,984 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:38:32,999 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:38:32,999 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:38:33,015 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-13bf583c-a4d2-4b93-ac97-233891981eaa
2017-12-11 10:38:33,074 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:38:33,395 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:38:34,058 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @19319ms
2017-12-11 10:38:34,243 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:38:34,274 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @19544ms
2017-12-11 10:38:34,322 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@421f4f0c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:38:34,322 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:38:34,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60758f3e{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,419 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39de7a22{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,421 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21cbebce{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,432 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5829b681{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,433 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b10cc3{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52d66682{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,438 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6be454d2{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ba067bb{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,450 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26274c8e{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,451 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@331bf0ee{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,452 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fe8108a{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,454 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ea7ea85{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,456 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2941a384{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@459cb933{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2359a442{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43851794{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,477 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29e15f2f{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,485 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22dced56{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,488 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62315b23{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,489 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1da4217a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@675c5ef3{/static,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@429c5ebb{/,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,519 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bd31690{/api,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,521 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f11847{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,523 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13e2f9fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:38:34,533 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:38:34,840 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:38:34,888 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54439.
2017-12-11 10:38:34,889 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54439
2017-12-11 10:38:34,892 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:38:34,894 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54439, None)
2017-12-11 10:38:34,899 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54439 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54439, None)
2017-12-11 10:38:34,905 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54439, None)
2017-12-11 10:38:34,906 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54439, None)
2017-12-11 10:38:34,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70b61e92{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:35,156 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:38:35,159 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:38:35,178 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b78f99{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:38:35,180 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@556e764a{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:35,182 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50c0e836{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:38:35,183 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b758188{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:38:35,186 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7753298e{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:38:36,331 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:38:36,668 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:38:37,824 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:38:37,826 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:38:37,827 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:38:37,830 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:38:37,830 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:38:37,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:38:37,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:38:37,832 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:38:37,832 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:38:37,832 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:38:37,834 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:38:37,851 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:38:37,852 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:38:37,855 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:38:37,877 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:38:37,877 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:38:38,274 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:38:38,274 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:38:38,451 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3513ee5c: startup date [Mon Dec 11 10:38:21 CST 2017]; root of context hierarchy
2017-12-11 10:38:38,470 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:38:38,582 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:38:38,610 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:38:41,808 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:38:42,008 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:38:42,023 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:38:42,023 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:38:42,080 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:38:42,127 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:38:43,224 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:38:43,491 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:38:44,255 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:38:44,467 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:38:44,705 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:38:44,709 INFO [restartedMain]                       com.Application : Started Application in 26.139 seconds (JVM running for 29.985)
2017-12-11 10:39:42,264 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:39:42,264 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:39:42,311 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms
2017-12-11 10:39:42,327 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,362 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:39:42,425 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:39:42,425 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:39:42,425 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:39:42,425 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:39:42,441 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * HTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:39:42,441 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:39:42,575 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,589 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,592 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,600 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,622 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,624 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,591 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,604 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,632 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,603 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,600 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,632 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,632 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,671 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,672 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,631 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,676 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,677 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,679 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,614 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,680 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,619 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:42,680 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,680 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,680 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:42,660 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,037 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,041 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,062 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,069 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,087 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,099 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,122 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,126 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,172 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,174 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,211 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,214 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,230 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,232 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,249 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,253 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:39:43,430 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:39:43,434 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:08,419 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3513ee5c: startup date [Mon Dec 11 10:38:21 CST 2017]; root of context hierarchy
2017-12-11 10:41:08,497 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:41:08,513 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:41:08,528 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@421f4f0c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:41:08,622 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:41:08,653 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:41:08,684 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:41:08,684 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:41:08,684 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:41:08,684 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:41:08,700 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:41:08,998 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 10:41:08,998 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:41:09,013 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 10:41:09,607 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14232 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:41:09,607 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:41:09,623 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7037b760: startup date [Mon Dec 11 10:41:09 CST 2017]; root of context hierarchy
2017-12-11 10:41:12,728 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:41:14,066 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:41:14,128 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4505 ms
2017-12-11 10:41:14,316 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:41:14,316 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:41:14,316 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:41:14,566 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:41:14,566 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:41:14,566 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:41:14,566 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:41:14,566 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:41:14,566 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:41:14,566 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:41:14,659 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54521.
2017-12-11 10:41:14,675 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:41:14,706 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:41:14,706 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:41:14,706 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:41:14,706 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-dedaba3e-c3e6-4564-8c44-09d32b0578c7
2017-12-11 10:41:14,706 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:41:14,706 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:41:14,737 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:41:14,753 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @180026ms
2017-12-11 10:41:14,769 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@1099777f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:41:14,769 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:41:14,769 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8b00d73{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,769 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@90ee0ff{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,769 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a241896{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fa8f84{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@121e60b7{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54deca7d{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c45c5ca{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@399bab67{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e504b11{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51c1f63a{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c4b862c{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a839e7d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20331866{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c5541bb{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48ad707e{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e47c1dc{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@10c3f669{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@402c3932{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e2be80a{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@157e8391{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6487b952{/static,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67101b36{/,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6085ef1e{/api,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,816 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60c2af96{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,816 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@749162e0{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,816 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:41:14,921 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:41:14,938 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54538.
2017-12-11 10:41:14,938 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54538
2017-12-11 10:41:14,938 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:41:14,938 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54538, None)
2017-12-11 10:41:14,938 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54538 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54538, None)
2017-12-11 10:41:14,938 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54538, None)
2017-12-11 10:41:14,938 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54538, None)
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e3b20ed{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,954 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:41:14,954 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4411136f{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25a404b0{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f75244d{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b112740{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e64539d{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:41:14,969 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:41:15,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:41:15,469 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:41:15,469 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:41:15,688 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7037b760: startup date [Mon Dec 11 10:41:09 CST 2017]; root of context hierarchy
2017-12-11 10:41:15,704 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:41:15,782 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:41:15,782 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:41:16,109 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:41:16,271 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:41:16,287 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:41:16,287 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:41:16,287 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:41:16,287 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:41:16,927 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:17,164 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:17,367 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:17,445 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:41:17,477 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:41:17,492 INFO [restartedMain]                       com.Application : Started Application in 8.041 seconds (JVM running for 182.762)
2017-12-11 10:41:42,427 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7037b760: startup date [Mon Dec 11 10:41:09 CST 2017]; root of context hierarchy
2017-12-11 10:41:42,440 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:41:42,440 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:41:42,444 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@1099777f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:41:42,457 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:41:42,457 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:41:42,519 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:41:42,519 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:41:42,519 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:41:42,519 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:41:42,519 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:41:44,108 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14232 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:41:44,108 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:41:44,124 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@59f873cc: startup date [Mon Dec 11 10:41:44 CST 2017]; root of context hierarchy
2017-12-11 10:41:46,778 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:41:48,319 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:41:48,396 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4272 ms
2017-12-11 10:41:48,543 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:41:48,543 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:41:48,543 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:41:48,652 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:41:48,652 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:41:48,652 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:41:48,652 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:41:48,652 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:41:48,652 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:41:48,652 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:41:48,699 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54578.
2017-12-11 10:41:48,715 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:41:48,715 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:41:48,715 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:41:48,715 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:41:48,715 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-3e7457d4-8120-4982-91d0-7dd3d5f7c990
2017-12-11 10:41:48,730 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:41:48,730 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:41:48,761 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:41:48,761 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @214036ms
2017-12-11 10:41:48,761 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2b928a20{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:41:48,761 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:41:48,761 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69ac05c4{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cf8bb57{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a0f52e3{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7977227d{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2df4dece{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6de5cac0{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,840 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b93141c{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,840 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e8abf9d{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1896cb6d{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5873a569{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dc2b00b{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f00e7b8{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a739e8d{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b065d0{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fb2a97c{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,855 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fe9a568{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,871 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32e7bc70{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,872 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48d5c1bf{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fa837a9{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cdd0bd9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,876 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ab2c9ff{/static,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,877 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bcb932a{/,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e07611e{/api,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,879 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2663283{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,879 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@940a241{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:41:48,880 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:41:48,953 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:41:49,000 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54595.
2017-12-11 10:41:49,000 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54595
2017-12-11 10:41:49,000 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:41:49,000 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54595, None)
2017-12-11 10:41:49,031 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54595 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54595, None)
2017-12-11 10:41:49,031 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54595, None)
2017-12-11 10:41:49,031 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54595, None)
2017-12-11 10:41:49,031 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40289961{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,031 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:41:49,031 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:41:49,031 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b77e7ce{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,031 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64108837{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,031 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4917eef4{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53735fee{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50f0e650{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:41:49,047 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:41:49,266 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:41:49,297 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:41:49,313 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:41:49,313 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:41:49,359 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:41:49,359 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:41:49,359 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/templates/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:41:49,359 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:41:49,469 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@59f873cc: startup date [Mon Dec 11 10:41:44 CST 2017]; root of context hierarchy
2017-12-11 10:41:49,484 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:41:49,982 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:41:49,987 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:41:50,364 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:41:50,552 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:41:50,552 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:41:50,552 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:41:50,567 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:41:50,583 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:41:50,958 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:51,083 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:51,283 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:41:51,402 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:41:51,465 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:41:51,465 INFO [restartedMain]                       com.Application : Started Application in 7.507 seconds (JVM running for 216.737)
2017-12-11 10:41:51,621 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:41:51,637 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 16 ms
2017-12-11 10:41:51,637 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:51,637 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * HTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:41:51,652 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:41:52,014 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,029 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,029 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,060 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,060 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,060 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,029 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,076 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,076 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,045 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,076 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,045 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,286 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,045 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,289 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,045 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,092 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,314 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,092 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,324 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,092 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,092 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,340 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,350 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,076 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,381 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,456 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,457 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,479 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,480 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,500 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,501 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,512 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,514 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,528 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,530 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,643 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,645 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,662 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,664 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:52,681 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:52,682 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,238 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,280 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,291 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,307 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,310 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,335 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,337 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,338 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,339 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,351 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,351 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,351 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,367 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,382 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,382 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,382 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,382 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,414 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,429 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,429 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,429 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,429 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,429 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,429 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,429 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,461 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,544 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,627 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,628 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,656 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,657 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,677 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,678 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,694 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,695 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,710 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,712 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,732 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,736 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,749 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,750 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,768 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,769 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:41:55,786 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:41:55,788 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,706 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,786 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,788 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,799 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,800 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,812 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,812 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,816 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,817 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,827 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,827 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,827 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,828 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,829 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,829 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,831 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,833 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,834 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,838 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,838 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,838 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,838 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,838 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,854 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,875 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,879 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,880 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,912 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,918 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:17,964 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:17,966 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,015 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,016 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,043 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,044 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,057 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,058 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,085 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,086 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,107 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,108 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:18,124 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:18,125 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,234 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,276 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,277 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,277 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,282 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,283 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,288 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,282 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,290 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,299 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,300 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,307 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,308 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,309 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,309 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,309 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,312 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,312 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,312 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,313 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,313 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,313 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,314 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,317 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,318 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,324 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,355 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,373 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,373 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,383 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,384 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,405 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,406 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,418 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,420 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:21,513 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:21,514 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,415 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,477 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,478 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,481 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,481 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,488 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,489 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,489 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,490 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,491 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,493 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,503 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,504 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,504 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,505 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,505 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,505 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,511 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,511 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,513 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,525 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,520 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,529 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,517 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,530 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,554 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,556 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,580 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,580 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,601 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,602 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,629 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,630 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,658 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,659 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,690 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,691 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,701 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,702 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,710 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,711 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,719 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,720 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:23,729 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:23,730 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,683 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,736 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,737 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,739 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,739 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,740 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,741 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,742 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,743 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-1.11.1.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,746 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,747 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,749 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,751 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,754 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,754 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,755 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,752 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,754 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,757 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,757 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,757 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,757 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,757 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,757 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,757 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,761 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,762 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,792 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,793 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery-ui-1.9.2.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,801 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,802 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/d3.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,808 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,809 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,819 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,820 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/bootstrap-treeview.min.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,829 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,830 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/json2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,840 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,840 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jquery.jsPlumb-1.7.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,851 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,851 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/biltong-0.2.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,859 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,859 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Blibs/jsBezier-0.6.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:42:25,873 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:42:25,874 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/@%7Bmain.js%7D] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:43:07,064 INFO [Thread-43] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@59f873cc: startup date [Mon Dec 11 10:41:44 CST 2017]; root of context hierarchy
2017-12-11 10:43:07,079 INFO [Thread-43] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:43:07,095 INFO [Thread-43] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:43:07,095 INFO [Thread-43] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2b928a20{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:43:07,111 INFO [Thread-43]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:43:07,111 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:43:07,126 INFO [Thread-43] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:43:07,126 INFO [Thread-43] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:43:07,126 INFO [Thread-43] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:43:07,126 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:43:07,126 INFO [Thread-43]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:43:07,767 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14232 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:43:07,767 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:43:07,767 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55260e80: startup date [Mon Dec 11 10:43:07 CST 2017]; root of context hierarchy
2017-12-11 10:43:10,658 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:43:11,722 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:43:11,784 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4017 ms
2017-12-11 10:43:11,878 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:43:11,878 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:43:11,878 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:43:11,940 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:43:11,940 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:43:11,940 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:43:11,940 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:43:11,940 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:43:11,940 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:43:11,940 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:43:11,972 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54672.
2017-12-11 10:43:11,987 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:43:11,987 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:43:11,987 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:43:11,987 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:43:11,987 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e1f1980e-38a2-41ee-84a2-b6171d2f42f3
2017-12-11 10:43:11,987 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:43:11,987 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:43:12,034 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:43:12,034 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @297311ms
2017-12-11 10:43:12,034 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@22722b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:43:12,034 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:43:12,034 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@674d51fb{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27790afc{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3df2358d{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a5cb21{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70f61145{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@119e8841{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d923f1f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d0041a1{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fd83829{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20e05a19{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29e23aa9{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14557608{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@615a881a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56dd05fe{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14e7a5bb{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7da42bea{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@327725c9{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c9ead59{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58ece88d{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@389fd28e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2221445e{/static,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@579192a6{/,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51ddbea2{/api,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f7b4a57{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2993a6f5{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,065 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:43:12,128 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:43:12,190 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54689.
2017-12-11 10:43:12,190 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54689
2017-12-11 10:43:12,190 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:43:12,190 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54689, None)
2017-12-11 10:43:12,206 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54689 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54689, None)
2017-12-11 10:43:12,206 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54689, None)
2017-12-11 10:43:12,206 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54689, None)
2017-12-11 10:43:12,206 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30e1b2a8{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,206 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:43:12,206 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:43:12,206 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39b43f93{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,206 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cd2d341{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,222 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e49ed1{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,222 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e667a95{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,222 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b2ec318{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:43:12,222 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:43:12,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:43:12,565 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:43:12,643 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55260e80: startup date [Mon Dec 11 10:43:07 CST 2017]; root of context hierarchy
2017-12-11 10:43:12,659 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:43:12,690 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:43:12,720 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:43:13,064 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:43:13,205 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:43:13,205 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:43:13,205 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:43:13,220 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:43:13,220 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:43:13,736 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:43:13,877 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:43:14,283 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:43:14,361 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:43:14,439 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:43:14,439 INFO [restartedMain]                       com.Application : Started Application in 6.781 seconds (JVM running for 299.721)
2017-12-11 10:44:36,396 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:44:36,412 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 16 ms
2017-12-11 10:44:36,412 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * HTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:44:36,428 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:44:36,617 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,633 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,633 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,648 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,648 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,648 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,664 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,617 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,677 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,617 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,692 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,648 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,648 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,699 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,648 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,707 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,648 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,633 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,711 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,633 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,633 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,747 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,748 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,761 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,761 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,772 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,773 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,782 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,782 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,793 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,793 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,805 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,805 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,829 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,830 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,841 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,842 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:36,861 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:36,865 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,194 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,276 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,277 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,282 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,284 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,295 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,299 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,324 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,324 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,325 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,320 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,321 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,346 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,352 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,354 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,362 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,363 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,363 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,363 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,369 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,371 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,372 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,372 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,376 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,377 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,386 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,389 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,388 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,390 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,449 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,453 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,464 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,464 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,478 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,478 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,502 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,503 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,519 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,521 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,538 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,539 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:39,803 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:39,805 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,399 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,439 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,439 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,453 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,453 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,453 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,453 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,457 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,457 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,460 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,470 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,470 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,469 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,480 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,480 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,469 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,481 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,468 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,485 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,468 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,488 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,467 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,462 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,489 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,487 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,480 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,489 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,512 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,513 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,522 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,523 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,530 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,530 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,540 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,541 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,547 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,548 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:44:42,561 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:44:42,561 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:04,779 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:45:04,795 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:45:06,123 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:45:06 CST 2017]; root of context hierarchy
2017-12-11 10:45:06,342 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:45:10,827 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:45:12,399 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:45:12,945 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6837 ms
2017-12-11 10:45:13,430 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:45:13,445 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:45:13,445 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:45:14,883 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:45:15,506 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:45:15,631 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$490bb164.CGLIB$getSparkContext$6(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$490bb164$$FastClassBySpringCGLIB$$5ee5332c.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$490bb164.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:45:15,740 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:45:15,771 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:45:15,771 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:45:15,771 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:45:15,787 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:45:15,787 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:45:16,349 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54788.
2017-12-11 10:45:16,381 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:45:16,412 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:45:16,412 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:45:16,412 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:45:16,459 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-048f2d81-39ba-4718-bd25-0e01521e0546
2017-12-11 10:45:16,553 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:45:16,693 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:45:16,818 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @16401ms
2017-12-11 10:45:16,896 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:45:16,912 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @16510ms
2017-12-11 10:45:16,943 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@6c060e26{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:45:16,943 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:45:16,990 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7457c682{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:45:16,990 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2450b55b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:16,990 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d36b28d{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:45:16,990 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2179522b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fd7162a{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f0a0a91{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@384a631a{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@725b9057{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5308e71f{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7781010f{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,006 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73a45666{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62101c0d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@579e08c7{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f3ec678{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d94bf30{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b2e1bfc{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5314ca64{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,037 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a80aeaf{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,037 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@685c8ba2{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,037 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@434c80ad{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@236ff82d{/static,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b4aadd5{/,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7027f91f{/api,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43a2ffad{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b898126{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,068 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:45:17,315 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:45:17,362 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54805.
2017-12-11 10:45:17,362 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54805
2017-12-11 10:45:17,362 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:45:17,362 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54805, None)
2017-12-11 10:45:17,378 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54805 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54805, None)
2017-12-11 10:45:17,393 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54805, None)
2017-12-11 10:45:17,393 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54805, None)
2017-12-11 10:45:17,440 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37677597{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,612 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:45:17,628 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:45:17,628 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6dc97f03{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,628 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dcb2313{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,643 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ce98935{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,643 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b9f9330{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:45:17,643 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@66eb2153{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:45:18,518 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:45:18,925 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:45:19,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:45:19,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:45:19,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:45:19,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:45:19,846 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:45:19,846 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:45:20,098 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:45:20,098 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/templates/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:45:20,098 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:45:20,238 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:45:06 CST 2017]; root of context hierarchy
2017-12-11 10:45:20,254 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:45:20,363 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:45:20,395 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:45:24,278 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:45:24,387 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:45:24,403 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:45:24,403 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:45:24,450 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:45:24,481 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:45:25,719 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:45:25,875 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:45:26,303 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:45:26,413 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:45:26,553 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:45:26,585 INFO [restartedMain]                       com.Application : Started Application in 22.918 seconds (JVM running for 26.179)
2017-12-11 10:45:39,390 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:45:39,390 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:45:39,437 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms
2017-12-11 10:45:39,453 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,515 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:45:39,609 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:45:39,609 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:45:39,609 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:45:39,609 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:45:39,625 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:45:39,625 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:45:39,756 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,759 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,763 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,763 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,779 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,781 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,782 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,783 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,786 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,786 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,790 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,787 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,793 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,794 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,796 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,797 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,798 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,802 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,808 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,810 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,811 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,812 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:39,814 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,814 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,814 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,814 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:39,997 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,000 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,017 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,022 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,048 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,050 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,066 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,068 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,088 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,090 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,111 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,114 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,146 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,149 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,166 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,173 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:40,199 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:45:40,206 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:45:54,576 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:46:17,443 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:46:17,567 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:46:17,582 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.map] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:46:46,207 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:45:06 CST 2017]; root of context hierarchy
2017-12-11 10:46:46,301 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:46:46,301 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:46:46,317 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@6c060e26{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:46:46,395 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:46:46,410 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:46:46,535 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:46:46,535 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:46:46,535 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:46:46,551 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:46:46,551 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:46:47,270 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 10:46:47,285 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:46:47,317 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 10:46:48,161 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:46:48,161 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:46:48,176 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6fc19d72: startup date [Mon Dec 11 10:46:48 CST 2017]; root of context hierarchy
2017-12-11 10:46:52,772 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:46:54,104 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:46:54,167 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5991 ms
2017-12-11 10:46:54,323 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:46:54,323 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:46:54,354 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:46:54,511 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:46:54,511 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:46:54,511 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:46:54,511 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:46:54,511 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:46:54,511 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:46:54,511 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:46:54,557 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54897.
2017-12-11 10:46:54,573 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:46:54,636 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:46:54,636 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:46:54,636 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:46:54,636 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-6f4da1fe-f6dd-4a16-90d4-3334a1c26240
2017-12-11 10:46:54,636 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:46:54,636 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:46:54,682 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:46:54,682 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @114275ms
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@26ecd712{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:46:54,714 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37a2ae6a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62c3e24{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64cb0ae7{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2eed4dfe{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@151fabf8{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24441591{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d02cb75{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68abb225{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41832249{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26cc58dd{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c9edb11{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@744fd9df{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@632c09f4{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52b077af{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7815ddd1{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f967a00{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a5af412{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bdc0305{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2042cfbd{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d311b12{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c59d955{/static,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@288d9084{/,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56a44fc4{/api,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d4e6285{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1477c990{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:46:54,745 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:46:54,933 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:46:55,011 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54914.
2017-12-11 10:46:55,011 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54914
2017-12-11 10:46:55,011 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:46:55,011 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54914, None)
2017-12-11 10:46:55,011 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54914 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54914, None)
2017-12-11 10:46:55,011 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54914, None)
2017-12-11 10:46:55,011 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54914, None)
2017-12-11 10:46:55,011 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@222e9420{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,026 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:46:55,026 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:46:55,026 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67ed0b7a{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,026 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@581f46e8{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,026 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20a8ac43{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,026 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@160a1546{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,026 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@398e8b7b{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:46:55,073 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:46:55,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:46:55,573 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:46:55,573 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:46:55,573 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:46:55,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:46:55,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:46:55,823 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6fc19d72: startup date [Mon Dec 11 10:46:48 CST 2017]; root of context hierarchy
2017-12-11 10:46:55,823 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:46:55,870 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:46:55,901 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:46:56,339 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:46:56,495 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:46:56,495 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:46:56,495 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:46:56,511 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:46:56,511 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:46:57,151 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:46:57,308 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:46:57,901 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:46:58,573 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:46:58,761 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:46:58,776 INFO [restartedMain]                       com.Application : Started Application in 10.834 seconds (JVM running for 118.361)
2017-12-11 10:47:02,681 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6fc19d72: startup date [Mon Dec 11 10:46:48 CST 2017]; root of context hierarchy
2017-12-11 10:47:02,681 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:47:02,681 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:47:02,697 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@26ecd712{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:47:02,697 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:47:02,697 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:47:02,712 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:47:02,712 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:47:02,712 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:47:02,712 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:47:02,728 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:47:03,775 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:47:03,775 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:47:03,775 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3b6d6115: startup date [Mon Dec 11 10:47:03 CST 2017]; root of context hierarchy
2017-12-11 10:47:06,275 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:47:07,494 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:47:07,588 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3813 ms
2017-12-11 10:47:07,713 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:47:07,713 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:47:07,713 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:47:07,838 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:47:07,838 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:47:07,838 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:47:07,838 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:47:07,838 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:47:07,838 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:47:07,838 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:47:07,869 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 54941.
2017-12-11 10:47:07,869 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:47:07,885 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:47:07,885 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:47:07,885 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:47:07,900 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-ecb0aca6-6611-4c3b-94cb-c863f41f6f43
2017-12-11 10:47:07,900 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:47:07,916 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:47:08,010 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:47:08,010 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @127601ms
2017-12-11 10:47:08,010 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@27fa87bf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:47:08,010 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:47:08,010 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@223accc0{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d9c5af5{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a006c5f{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@367562c0{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@613e47f{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cec91e8{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a688dfe{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7727bc45{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@273e8072{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@524e9bc0{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@472f6a33{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77066b33{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55350668{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,103 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@431ec82a{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,103 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b7b668f{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,103 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72183592{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,103 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55d36928{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36a04c55{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cfca78d{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@777ca2f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ce947f1{/static,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19ecebe0{/,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@489b72d5{/api,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@443ead8d{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50cbaeb1{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,166 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:47:08,291 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:47:08,353 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54958.
2017-12-11 10:47:08,353 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:54958
2017-12-11 10:47:08,353 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:47:08,353 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 54958, None)
2017-12-11 10:47:08,353 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:54958 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 54958, None)
2017-12-11 10:47:08,353 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 54958, None)
2017-12-11 10:47:08,353 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 54958, None)
2017-12-11 10:47:08,369 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c833e24{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,400 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:47:08,416 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:47:08,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19975c58{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e126815{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@201b8f8c{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5edf06a{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cf683c4{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:47:08,447 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:47:09,338 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:47:09,353 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:47:09,463 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3b6d6115: startup date [Mon Dec 11 10:47:03 CST 2017]; root of context hierarchy
2017-12-11 10:47:09,463 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:47:09,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:47:09,494 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:47:09,806 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:47:09,908 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:47:09,908 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:47:09,908 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:47:09,908 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:47:09,924 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:47:10,252 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:47:10,362 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:47:10,643 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:47:10,752 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:47:10,815 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:47:10,815 INFO [restartedMain]                       com.Application : Started Application in 7.118 seconds (JVM running for 130.402)
2017-12-11 10:48:50,624 INFO [Thread-38] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3b6d6115: startup date [Mon Dec 11 10:47:03 CST 2017]; root of context hierarchy
2017-12-11 10:48:50,624 INFO [Thread-38] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:48:50,624 INFO [Thread-38] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:48:50,624 INFO [Thread-38] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@27fa87bf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:48:50,640 INFO [Thread-38]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:48:50,640 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:48:50,687 INFO [Thread-38] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:48:50,687 INFO [Thread-38] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:48:50,687 INFO [Thread-38] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:48:50,687 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:48:50,687 INFO [Thread-38]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:48:52,289 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:48:52,289 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:48:52,305 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5577db56: startup date [Mon Dec 11 10:48:52 CST 2017]; root of context hierarchy
2017-12-11 10:48:54,823 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:48:55,573 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:48:55,620 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3315 ms
2017-12-11 10:48:55,698 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:48:55,698 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:48:55,698 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:48:55,776 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:48:55,776 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:48:55,776 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:48:55,776 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:48:55,776 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:48:55,776 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:48:55,776 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:48:55,791 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55020.
2017-12-11 10:48:55,791 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:48:55,791 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:48:55,791 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:48:55,791 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:48:55,807 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-b0af99f3-272b-4c9e-9c9d-4bee2f3aab5e
2017-12-11 10:48:55,807 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:48:55,807 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:48:55,823 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:48:55,823 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @235418ms
2017-12-11 10:48:55,823 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@64789cc9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:48:55,838 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@516d41ea{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ec31c17{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a421e6{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35e7a21f{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@456f946f{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6feee2b2{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@368e3985{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4309cf17{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53e7eac7{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5795f7b1{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a756b0f{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@578d9972{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5099618e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a22c2f9{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a5f34c9{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b99f3ed{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,838 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@641da5f7{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11a943e9{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@666e998e{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36c2ab62{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6639ba09{/static,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50605ffa{/,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@406f3290{/api,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@98f55bb{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@331bc4b8{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,854 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:48:55,932 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:48:55,979 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55037.
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55037
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55037, None)
2017-12-11 10:48:55,979 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55037 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55037, None)
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55037, None)
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55037, None)
2017-12-11 10:48:55,979 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2127e401{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,979 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:48:55,995 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:48:55,995 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5052c7df{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,995 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@766acf6f{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,995 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@377ad408{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,995 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fe5326c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,995 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39cc8e45{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:48:55,995 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:48:56,838 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:48:56,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:48:56,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:48:57,042 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:48:57,042 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:48:57,042 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/templates/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:48:57,042 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:48:57,370 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5577db56: startup date [Mon Dec 11 10:48:52 CST 2017]; root of context hierarchy
2017-12-11 10:48:57,417 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:48:57,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:48:57,745 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:48:58,417 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:48:58,698 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:49:00,448 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:49:00,448 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:49:00,448 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:49:00,448 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:49:01,620 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:01,776 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:02,026 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:02,120 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:49:02,167 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:49:02,167 INFO [Thread-59] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5577db56: startup date [Mon Dec 11 10:48:52 CST 2017]; root of context hierarchy
2017-12-11 10:49:02,167 INFO [restartedMain]                       com.Application : Started Application in 10.034 seconds (JVM running for 241.764)
2017-12-11 10:49:02,167 INFO [Thread-59] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:49:02,167 INFO [Thread-59] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:49:02,182 INFO [Thread-59] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@64789cc9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:49:02,198 INFO [Thread-59]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:49:02,198 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:49:02,229 INFO [Thread-59] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:49:02,229 INFO [Thread-59] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:49:02,229 INFO [Thread-59] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:49:02,229 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:49:02,245 INFO [Thread-59]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:49:03,448 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:49:03,448 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:49:03,448 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5db384b6: startup date [Mon Dec 11 10:49:03 CST 2017]; root of context hierarchy
2017-12-11 10:49:05,489 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:49:06,493 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:49:06,571 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3123 ms
2017-12-11 10:49:06,712 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:49:06,712 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:49:06,712 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:49:06,790 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:49:06,790 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:49:06,790 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:49:06,790 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:49:06,790 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:49:06,790 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:49:06,790 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:49:06,806 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55061.
2017-12-11 10:49:06,806 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:49:06,806 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:49:06,806 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:49:06,806 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:49:06,822 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-5024ab7f-9e28-4cba-964b-b8516929348e
2017-12-11 10:49:06,822 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:49:06,822 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @246428ms
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@4d3613ab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:49:06,837 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29636293{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36da650b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79c90738{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71e87341{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f93576a{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3432356a{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c2a98f3{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e97ac5e{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,837 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2254d3ab{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60d13350{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17068716{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21ed448c{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fcc8afa{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@311f000b{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7aecf8e4{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26a5c516{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b642c90{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@709c13f0{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a0f7b50{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d16a4b6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d276aa{/static,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e23866d{/,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e0174ca{/api,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c5620ca{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39a83f51{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,853 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:49:06,900 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:49:06,915 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55078.
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55078
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55078, None)
2017-12-11 10:49:06,915 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55078 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55078, None)
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55078, None)
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55078, None)
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37368e68{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d27abf4{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@346f5b66{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5aba7117{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2530dc56{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47079acb{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:49:06,915 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:49:07,259 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:49:07,259 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:49:07,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:49:07,290 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:49:07,384 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5db384b6: startup date [Mon Dec 11 10:49:03 CST 2017]; root of context hierarchy
2017-12-11 10:49:07,384 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:49:07,415 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:49:07,415 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:49:07,743 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:49:07,884 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:49:07,898 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:49:07,898 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:49:07,899 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:49:07,899 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:49:08,196 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:08,305 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:08,712 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:08,790 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:49:08,915 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:49:08,915 INFO [restartedMain]                       com.Application : Started Application in 5.623 seconds (JVM running for 248.507)
2017-12-11 10:49:16,692 INFO [Thread-73] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5db384b6: startup date [Mon Dec 11 10:49:03 CST 2017]; root of context hierarchy
2017-12-11 10:49:16,692 INFO [Thread-73] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:49:16,692 INFO [Thread-73] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:49:16,724 INFO [Thread-73] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@4d3613ab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:49:17,958 INFO [Thread-73]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:49:17,958 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:49:18,067 INFO [Thread-73] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:49:18,067 INFO [Thread-73] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:49:18,083 INFO [Thread-73] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:49:18,083 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:49:18,083 INFO [Thread-73]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:49:19,489 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:49:19,489 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:49:19,505 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5ca92b56: startup date [Mon Dec 11 10:49:19 CST 2017]; root of context hierarchy
2017-12-11 10:49:22,310 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:49:23,159 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:49:23,191 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3686 ms
2017-12-11 10:49:23,264 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:49:23,264 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:49:23,264 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:49:23,310 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:49:23,310 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:49:23,310 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:49:23,310 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:49:23,310 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:49:23,310 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:49:23,310 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:49:23,326 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55110.
2017-12-11 10:49:23,326 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:49:23,326 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:49:23,326 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:49:23,326 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:49:23,342 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-fbdd3150-c28f-4c5d-bc37-152c0da7f375
2017-12-11 10:49:23,342 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:49:23,342 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @262948ms
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3766418a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:49:23,357 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cec2138{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28e5165b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@501269b4{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31d27ebc{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cfca343{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@306a3d93{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17adc3dc{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18fc53a6{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@bf1f2f0{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@532ee5a9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ebc11e1{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cbabad9{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48924403{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51a46097{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@267f81d6{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7164e9f{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a6db9a1{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b699882{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b05ca2a{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7036c87c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f2a4875{/static,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59b9ecdb{/,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fc9f8d{/api,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@170840cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e0f2ac4{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,373 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:49:23,451 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:49:23,467 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55127.
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55127
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55127, None)
2017-12-11 10:49:23,467 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55127 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55127, None)
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55127, None)
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55127, None)
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@158e21b5{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:49:23,467 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2df29593{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d1cda6d{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a3cf757{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f17ae16{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12474ba1{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:49:23,482 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:49:23,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:49:23,717 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:49:23,717 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:49:23,779 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5ca92b56: startup date [Mon Dec 11 10:49:19 CST 2017]; root of context hierarchy
2017-12-11 10:49:23,779 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:49:23,810 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:49:23,810 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:49:24,045 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:49:24,092 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:49:24,107 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:49:24,107 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:49:24,107 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:49:24,107 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:49:24,357 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:24,451 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:24,560 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:49:24,623 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:49:24,639 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:49:24,639 INFO [restartedMain]                       com.Application : Started Application in 5.29 seconds (JVM running for 264.233)
2017-12-11 10:49:35,448 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:49:35,451 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 10:49:35,452 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:49:35,455 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:49:35,588 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,595 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,605 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,621 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,653 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,653 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,668 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,684 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,702 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,606 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,722 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,700 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,826 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,828 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,843 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,845 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,862 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,864 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,877 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,878 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,890 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,891 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,908 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,913 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:35,934 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:35,935 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:36,062 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:36,063 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:49:36,087 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:49:36,090 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:41,648 INFO [Thread-92] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5ca92b56: startup date [Mon Dec 11 10:49:19 CST 2017]; root of context hierarchy
2017-12-11 10:52:41,648 INFO [Thread-92] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:52:41,648 INFO [Thread-92] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:52:41,648 INFO [Thread-92] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3766418a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:52:41,648 INFO [Thread-92]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:52:41,648 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:52:41,664 INFO [Thread-92] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:52:41,664 INFO [Thread-92] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:52:41,664 INFO [Thread-92] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:52:41,664 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:52:41,664 INFO [Thread-92]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:52:42,388 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 12788 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:52:42,388 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:52:42,388 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@436cb713: startup date [Mon Dec 11 10:52:42 CST 2017]; root of context hierarchy
2017-12-11 10:52:43,762 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:52:44,750 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:52:44,865 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2477 ms
2017-12-11 10:52:45,100 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:52:45,100 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:52:45,100 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:52:45,212 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:52:45,212 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:52:45,212 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:52:45,212 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:52:45,212 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:52:45,212 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:52:45,212 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:52:45,306 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55284.
2017-12-11 10:52:45,306 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:52:45,322 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:52:45,337 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:52:45,337 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:52:45,337 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-bc9747f6-bfcc-4438-9ea0-ef2fd5fea8b0
2017-12-11 10:52:45,337 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:52:45,337 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @464962ms
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2dc16df9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:52:45,368 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c2c9f67{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@34eab759{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a8dd804{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,368 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40beda92{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@386b36a{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b87c2b5{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@626ff115{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35bfd587{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cdd2c69{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3656ad67{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e579d58{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@728d6356{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19768573{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f88165f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52117b6d{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39a6cd5e{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16059055{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1722c980{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5072f181{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40b22941{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1749157f{/static,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,384 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ba1ab8a{/,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,400 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@647cde5d{/api,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,400 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c76fb8b{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,400 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@727d608e{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,400 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:52:45,462 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:52:45,478 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55301.
2017-12-11 10:52:45,478 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55301
2017-12-11 10:52:45,478 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:52:45,478 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55301, None)
2017-12-11 10:52:45,478 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55301 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55301, None)
2017-12-11 10:52:45,478 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55301, None)
2017-12-11 10:52:45,478 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55301, None)
2017-12-11 10:52:45,493 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11f1adb8{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,509 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:52:45,509 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:52:45,509 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@342916fe{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,509 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55d5d230{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,509 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@119074f6{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,525 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d8c8d7d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,525 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9b9501c{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:52:45,525 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:52:46,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:52:46,172 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:52:46,172 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:52:46,173 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:52:46,173 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:52:46,173 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:52:46,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:52:46,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:52:46,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:52:46,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:52:46,175 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:52:46,181 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:52:46,181 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:52:46,181 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:52:46,236 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:52:46,236 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:52:46,323 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:52:46,324 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:52:46,384 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@436cb713: startup date [Mon Dec 11 10:52:42 CST 2017]; root of context hierarchy
2017-12-11 10:52:46,390 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:52:46,416 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:52:46,423 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:52:46,839 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:52:47,122 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:52:47,132 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:52:47,132 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:52:47,133 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:52:47,182 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:52:47,523 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:52:47,652 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:52:47,934 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:52:48,013 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:52:48,055 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:52:48,058 INFO [restartedMain]                       com.Application : Started Application in 5.78 seconds (JVM running for 467.642)
2017-12-11 10:52:48,157 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:52:48,161 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 10:52:48,161 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,164 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:52:48,169 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:52:48,170 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:52:48,170 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:52:48,170 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:52:48,170 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XHTML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:52:48,171 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:52:48,278 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,285 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,286 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,286 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,288 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,288 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,289 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,289 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,289 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,296 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,317 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,290 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,319 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,290 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,324 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,374 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,379 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,380 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,382 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,386 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,388 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,383 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,400 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,400 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,399 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,412 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,413 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,413 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,428 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,429 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,446 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,447 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,456 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,457 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,467 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,470 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,486 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,486 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,534 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,536 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,553 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,554 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:48,570 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:48,572 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,327 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,361 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,362 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,369 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,370 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,386 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,386 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,386 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,386 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,390 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,391 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,392 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,393 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,395 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,397 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,398 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,398 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,413 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,414 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,427 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,429 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,433 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,434 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,440 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,440 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,441 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,441 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,462 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,462 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,469 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,470 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,503 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,503 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,516 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,517 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,525 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,526 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,534 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,534 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:54,544 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:54,545 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,072 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,116 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,116 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,116 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,116 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,128 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,128 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,128 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,144 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,144 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,144 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,179 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,179 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,179 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,179 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,179 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,182 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,183 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,183 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,184 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,184 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,184 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,185 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,186 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,187 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,183 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,193 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,204 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,207 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,218 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,219 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,228 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,229 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,238 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,239 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,249 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,250 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:58,260 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:58,260 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,136 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,192 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,193 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,193 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,194 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,194 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,198 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,199 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,200 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,202 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,203 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,198 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,205 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,208 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,209 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,211 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,211 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,213 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,214 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,216 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,216 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,216 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,216 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,216 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,222 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,202 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,226 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,254 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,254 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,263 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,263 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,272 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,274 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,282 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,283 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,288 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,289 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,299 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,299 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,307 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,308 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:52:59,408 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:52:59,409 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,582 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,634 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,640 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,645 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,646 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,647 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,647 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,650 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,650 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,654 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,654 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,655 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,655 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,656 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,661 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,661 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,661 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,662 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,662 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,655 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,665 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,665 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,666 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,667 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,662 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,675 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,676 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,699 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,735 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,752 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,753 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,762 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,763 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,770 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,771 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,779 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,779 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,788 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,789 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:00,803 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:00,804 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,612 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,647 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,648 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,652 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,655 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,657 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,657 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,659 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,660 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,662 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,662 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,670 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,671 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,672 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,673 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,675 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,676 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,678 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,678 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,679 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,679 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,679 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,681 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,681 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,679 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,681 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,687 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,730 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,731 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,748 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,749 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,761 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,761 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,771 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,772 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,781 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,781 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,793 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,794 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,801 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,802 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,811 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,811 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:01,819 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:01,820 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,311 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,353 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,355 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,358 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,359 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,365 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,366 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,367 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,367 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,367 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,367 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,369 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,371 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,372 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,372 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,374 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,375 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,378 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,379 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,390 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,392 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,400 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,401 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,405 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,405 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,369 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,412 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,437 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,466 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,478 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,479 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,487 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,489 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,497 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,498 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,505 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,506 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,516 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,517 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,551 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,552 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,560 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,560 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:02,572 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:02,573 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,087 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,126 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,126 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,129 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,129 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,141 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,141 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,141 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,142 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,142 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,142 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,147 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,147 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,148 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,148 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,149 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,153 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,154 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,142 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,160 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,162 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,155 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,165 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,154 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,148 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,178 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,180 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,190 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,190 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,200 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,200 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,208 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,209 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,215 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,215 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,225 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,225 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,231 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,231 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,240 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,241 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,247 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,248 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:53:03,320 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:53:03,321 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,121 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,166 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,166 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,168 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,168 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,171 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,171 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,171 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,171 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,171 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,171 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,171 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,171 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,171 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,171 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,189 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,189 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,188 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,194 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,208 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,208 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,209 INFO [http-nio-8080-exec-20]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,210 WARN [http-nio-8080-exec-20] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,216 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,218 WARN [http-nio-8080-exec-19] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,218 INFO [http-nio-8080-exec-21]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,219 INFO [http-nio-8080-exec-22]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,221 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,220 WARN [http-nio-8080-exec-21] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,222 WARN [http-nio-8080-exec-22] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,222 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,233 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,234 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,240 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,240 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,248 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,250 WARN [http-nio-8080-exec-17] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,256 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,256 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,264 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,265 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:39,272 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:39,273 WARN [http-nio-8080-exec-16] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,412 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,452 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,453 WARN [http-nio-8080-exec-18] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,460 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,460 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,477 INFO [http-nio-8080-exec-20]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,477 INFO [http-nio-8080-exec-22]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,477 WARN [http-nio-8080-exec-20] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,478 WARN [http-nio-8080-exec-22] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,483 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,484 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,484 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,484 WARN [http-nio-8080-exec-19] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,489 INFO [http-nio-8080-exec-22]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,490 WARN [http-nio-8080-exec-22] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,514 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,514 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,516 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,516 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,521 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,522 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,523 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,523 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,528 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,529 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,529 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,530 WARN [http-nio-8080-exec-17] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,560 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,568 WARN [http-nio-8080-exec-15] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,589 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,590 WARN [http-nio-8080-exec-18] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,603 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,604 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,616 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,616 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,625 INFO [http-nio-8080-exec-21]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,626 WARN [http-nio-8080-exec-21] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,634 INFO [http-nio-8080-exec-20]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,634 WARN [http-nio-8080-exec-20] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,644 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,645 WARN [http-nio-8080-exec-19] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,652 INFO [http-nio-8080-exec-22]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,652 WARN [http-nio-8080-exec-22] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:55:41,662 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:55:41,663 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:00,206 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:56:00,206 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:56:01,503 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:56:01 CST 2017]; root of context hierarchy
2017-12-11 10:56:01,940 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 10:56:06,644 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:56:08,378 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:56:08,941 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7438 ms
2017-12-11 10:56:09,425 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:56:09,441 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:56:09,441 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:56:11,597 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:56:12,019 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 10:56:12,144 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$684b3e80.CGLIB$getSparkContext$3(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$684b3e80$$FastClassBySpringCGLIB$$801a22.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$684b3e80.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 10:56:12,300 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:56:12,363 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:56:12,363 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:56:12,363 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:56:12,363 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:56:12,363 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:56:12,910 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55451.
2017-12-11 10:56:12,925 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:56:12,972 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:56:12,972 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:56:12,972 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:56:12,988 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-7790ac54-43b9-4edb-82c1-7112e0e9a740
2017-12-11 10:56:13,035 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:56:13,128 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:56:13,456 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @18075ms
2017-12-11 10:56:13,956 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:56:14,019 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @18657ms
2017-12-11 10:56:14,269 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@43c358c0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:56:14,269 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:56:14,316 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@265690b6{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f0a0a91{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@384a631a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@196272d2{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5bc97b02{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59f6fb4e{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67806596{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@658790c{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dac5db4{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a6b5c8a{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@624a0ccb{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ba1891f{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@618ab899{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dee3591{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ca6b840{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fe267e8{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ae230b8{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51ed7fcf{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56a3cdb4{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@654a9165{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a7e4a26{/static,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@685d938c{/,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17e83597{/api,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bcb990f{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,378 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b513b81{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:56:14,378 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:56:14,613 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:56:14,675 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55468.
2017-12-11 10:56:14,675 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55468
2017-12-11 10:56:14,675 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:56:14,675 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55468, None)
2017-12-11 10:56:14,691 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55468 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55468, None)
2017-12-11 10:56:14,706 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55468, None)
2017-12-11 10:56:14,722 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55468, None)
2017-12-11 10:56:14,785 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cceb396{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,065 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:56:15,065 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:56:15,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b9f9330{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f9a82b4{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38ea10be{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@280c22ec{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36b66d9e{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:56:15,815 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 10:56:16,127 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:56:17,518 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:56:17,518 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:56:17,518 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:56:17,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:56:17,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:56:17,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:56:17,565 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:56:17,596 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:56:17,596 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:56:18,112 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:56:18,127 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 10:56:18,409 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:56:01 CST 2017]; root of context hierarchy
2017-12-11 10:56:18,440 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:56:18,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:56:18,674 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:56:21,268 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:56:21,409 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:56:21,440 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:56:21,440 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:56:21,487 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:56:21,534 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:56:22,815 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:56:23,018 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:56:23,378 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:56:23,487 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:56:23,643 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:56:23,659 INFO [restartedMain]                       com.Application : Started Application in 24.844 seconds (JVM running for 28.303)
2017-12-11 10:56:47,735 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:56:47,735 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:56:47,798 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 63 ms
2017-12-11 10:56:47,813 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:47,891 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:56:47,985 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:56:48,193 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,193 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,193 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,208 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,193 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,224 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,193 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,208 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,208 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,208 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,240 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,240 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,255 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,255 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,224 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,271 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,271 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,224 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,271 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,255 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,563 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,726 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,775 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,778 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,818 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,823 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,843 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,845 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,936 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,939 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,955 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,959 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:48,974 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:48,976 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:56:49,010 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:56:49,012 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:57:47,349 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43db7073: startup date [Mon Dec 11 10:56:01 CST 2017]; root of context hierarchy
2017-12-11 10:57:47,364 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:57:47,364 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:57:47,396 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@43c358c0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:57:47,489 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:57:47,583 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:57:47,661 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:57:47,661 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:57:47,661 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:57:47,677 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:57:47,677 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:57:48,177 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 10:57:48,208 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 10:57:48,271 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:40)
2017-12-11 10:57:49,052 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:57:49,052 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:57:49,068 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42226c3c: startup date [Mon Dec 11 10:57:49 CST 2017]; root of context hierarchy
2017-12-11 10:57:52,677 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:57:54,202 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:57:54,342 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5274 ms
2017-12-11 10:57:54,498 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:57:54,498 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:57:54,498 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:57:54,655 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:57:54,670 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:57:54,670 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:57:54,670 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:57:54,670 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:57:54,670 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:57:54,686 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:57:54,764 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55527.
2017-12-11 10:57:54,827 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:57:54,873 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:57:54,873 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:57:54,873 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:57:54,873 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-40715034-ea80-4d2a-accf-4d2fe36d4568
2017-12-11 10:57:54,873 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:57:54,889 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:57:54,952 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:57:54,983 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @119627ms
2017-12-11 10:57:55,061 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@749f0508{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:57:55,077 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31740641{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4918d47e{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54747ffb{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@647076d{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2dbc440e{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d02f71{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1002e752{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ece846a{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,077 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cd1f02d{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b45ddaa{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7615f12c{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54df155{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7853540d{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@349b0d27{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45e36734{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43e6bc78{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fc55640{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35d6e89b{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bb23669{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26a73288{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,092 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3287d741{/static,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,108 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35a1aba3{/,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,108 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@346be382{/api,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,108 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a81b34b{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,108 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5056f268{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,108 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:57:55,311 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:57:55,374 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55544.
2017-12-11 10:57:55,374 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55544
2017-12-11 10:57:55,374 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:57:55,374 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55544, None)
2017-12-11 10:57:55,374 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55544 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55544, None)
2017-12-11 10:57:55,374 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55544, None)
2017-12-11 10:57:55,374 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55544, None)
2017-12-11 10:57:55,374 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d3dc476{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,389 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:57:55,389 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:57:55,389 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@85613ba{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,389 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a2185db{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,389 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47f3b7fc{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,389 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25cbdc62{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,389 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cf5b0c7{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:57:55,405 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:57:55,733 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:57:55,733 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:57:55,733 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:57:55,733 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:57:55,733 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:57:55,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:57:55,983 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42226c3c: startup date [Mon Dec 11 10:57:49 CST 2017]; root of context hierarchy
2017-12-11 10:57:55,999 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:57:56,061 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:57:56,311 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:57:57,077 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:57:57,217 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:57:57,217 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:57:57,217 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:57:57,233 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:57:57,233 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:57:57,827 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:57:58,045 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:57:58,264 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:57:58,342 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:57:58,374 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:57:58,405 INFO [restartedMain]                       com.Application : Started Application in 9.509 seconds (JVM running for 123.047)
2017-12-11 10:58:04,350 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42226c3c: startup date [Mon Dec 11 10:57:49 CST 2017]; root of context hierarchy
2017-12-11 10:58:04,366 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 10:58:04,366 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 10:58:04,382 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@749f0508{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:58:04,382 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 10:58:04,382 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 10:58:04,413 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 10:58:04,413 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 10:58:04,413 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 10:58:04,413 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 10:58:04,428 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 10:58:05,491 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 10:58:05,491 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 10:58:05,491 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42e8db4e: startup date [Mon Dec 11 10:58:05 CST 2017]; root of context hierarchy
2017-12-11 10:58:08,757 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 10:58:11,070 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 10:58:11,160 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5669 ms
2017-12-11 10:58:11,369 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 10:58:11,370 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 10:58:11,371 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 10:58:11,524 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 10:58:11,527 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 10:58:11,528 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 10:58:11,528 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 10:58:11,528 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 10:58:11,528 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 10:58:11,528 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 10:58:11,556 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55574.
2017-12-11 10:58:11,579 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 10:58:11,593 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 10:58:11,596 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 10:58:11,596 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 10:58:11,681 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-37dccb9b-beae-4271-86be-2081157963c7
2017-12-11 10:58:11,685 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 10:58:11,688 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 10:58:11,772 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 10:58:11,774 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @136414ms
2017-12-11 10:58:11,790 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3d7a501f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 10:58:11,790 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 10:58:11,791 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32ad5b66{/jobs,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,844 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@459f2513{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,845 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7224675b{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,907 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d5d3687{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,908 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65192d92{/stages,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,910 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d23eb2{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,912 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d0a0d8b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,912 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6615f1e7{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ee1b7e{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,920 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28cbd9cf{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,921 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c138380{/storage,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,923 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f6b0b9b{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,924 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25dcf268{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,929 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e4e5f78{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,930 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2268c2c4{/environment,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,931 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2233dbec{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,933 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f9d10cd{/executors,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,936 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7aa8e0f8{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,941 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a885bf4{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,943 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@749a7803{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,944 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70521ba4{/static,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,945 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@595ef1cd{/,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,946 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c6ce7bb{/api,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,947 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f68fe97{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,948 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@234ceb58{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 10:58:11,950 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 10:58:12,134 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 10:58:12,302 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55591.
2017-12-11 10:58:12,302 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55591
2017-12-11 10:58:12,302 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 10:58:12,303 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55591, None)
2017-12-11 10:58:12,304 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55591 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55591, None)
2017-12-11 10:58:12,304 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55591, None)
2017-12-11 10:58:12,305 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55591, None)
2017-12-11 10:58:12,307 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26f9ce2a{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,312 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 10:58:12,337 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 10:58:12,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46a5bba6{/SQL,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,344 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8d42aed{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,345 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bb01660{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,346 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69fe30a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,348 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a260835{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 10:58:12,361 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 10:58:12,844 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 10:58:12,851 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 10:58:12,851 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 10:58:12,852 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 10:58:12,853 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 10:58:12,853 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 10:58:12,853 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 10:58:12,853 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 10:58:12,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 10:58:12,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 10:58:12,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 10:58:12,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 10:58:12,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 10:58:12,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 10:58:12,916 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 10:58:12,917 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 10:58:13,161 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42e8db4e: startup date [Mon Dec 11 10:58:05 CST 2017]; root of context hierarchy
2017-12-11 10:58:13,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:58:13,204 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 10:58:13,214 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 10:58:13,580 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 10:58:13,717 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 10:58:13,723 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 10:58:13,723 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 10:58:13,726 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 10:58:13,747 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 10:58:14,078 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:58:14,197 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:58:14,522 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 10:58:14,624 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 10:58:14,655 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 10:58:14,659 INFO [restartedMain]                       com.Application : Started Application in 9.276 seconds (JVM running for 139.298)
2017-12-11 10:58:17,792 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 10:58:17,792 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 0 ms
2017-12-11 10:58:17,792 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 10:58:17,808 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 10:58:17,918 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:17,927 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,004 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,015 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,011 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,044 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,044 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,056 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,011 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,075 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,011 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,099 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,009 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,104 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,008 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,125 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,005 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,139 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,066 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,150 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,025 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,157 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,024 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,020 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,169 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,170 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,194 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,195 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,215 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,217 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,232 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,235 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,256 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,258 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,275 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,276 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,356 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,357 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,367 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,368 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,383 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,384 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,397 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,399 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 10:58:18,779 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 10:58:18,822 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:02,823 INFO [Thread-39] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42e8db4e: startup date [Mon Dec 11 10:58:05 CST 2017]; root of context hierarchy
2017-12-11 11:12:02,836 INFO [Thread-39] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:12:02,839 INFO [Thread-39] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:12:02,844 INFO [Thread-39] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3d7a501f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:02,886 INFO [Thread-39]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:12:02,888 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:12:02,949 INFO [Thread-39] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:12:02,949 INFO [Thread-39] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:12:02,951 INFO [Thread-39] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:12:02,954 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:12:02,998 INFO [Thread-39]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:12:04,279 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:12:04,279 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:12:04,284 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@417361e: startup date [Mon Dec 11 11:12:04 CST 2017]; root of context hierarchy
2017-12-11 11:12:08,802 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:12:10,032 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:12:10,111 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5827 ms
2017-12-11 11:12:10,298 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:12:10,299 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:12:10,299 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:12:10,371 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:12:10,373 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:12:10,374 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:12:10,374 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:12:10,374 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:12:10,375 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:12:10,375 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:12:10,399 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55929.
2017-12-11 11:12:10,402 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:12:10,408 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:12:10,408 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:12:10,408 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:12:10,414 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-2f6c8f8d-923a-4422-893e-8d9721e3c07b
2017-12-11 11:12:10,415 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:12:10,417 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:12:10,467 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:12:10,469 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @975108ms
2017-12-11 11:12:10,476 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@218f7432{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:10,476 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:12:10,482 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bfcf529{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,482 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68afbdf3{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,483 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e0294ff{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,483 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6151111e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,484 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@223db56b{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,484 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c8c6b96{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,487 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4893d39b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,488 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20f9b5cd{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,489 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24ff3efa{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,489 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23d231b7{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,490 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dc39c21{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,491 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ded2f9{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,491 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76a9974b{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,492 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a1ff872{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,493 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@164225c0{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,493 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e9636fc{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,494 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a03481b{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,495 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52d9e9fd{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,495 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f6d0101{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,496 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@775f0b6e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39413651{/static,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,498 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78de5b9f{/,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,499 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c960829{/api,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,499 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72fc7e59{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,500 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3de0aa57{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,500 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:12:10,700 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:12:10,758 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55946.
2017-12-11 11:12:10,759 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55946
2017-12-11 11:12:10,759 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:12:10,759 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55946, None)
2017-12-11 11:12:10,761 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55946 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55946, None)
2017-12-11 11:12:10,762 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55946, None)
2017-12-11 11:12:10,762 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55946, None)
2017-12-11 11:12:10,764 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b2981bf{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,772 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:12:10,772 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:12:10,773 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e3fa3f5{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,775 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22e2a8b2{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,776 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1884321c{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,782 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7368b68e{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,790 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7962c566{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:12:10,797 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:12:11,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:12:11,243 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:12:11,243 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:12:11,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:12:11,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:12:11,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:12:11,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:12:11,260 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:12:11,260 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:12:11,261 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:12:11,261 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:11,272 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:12:11,274 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:12:11,275 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:12:11,277 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:11,278 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:12:11,374 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@417361e: startup date [Mon Dec 11 11:12:04 CST 2017]; root of context hierarchy
2017-12-11 11:12:11,378 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:11,395 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:11,399 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:12:11,698 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:12:11,792 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:12:11,805 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:12:11,805 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:12:11,807 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:12:11,815 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:12:12,148 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:12,266 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:12,580 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:12,669 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:12:12,696 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:12:12,699 INFO [restartedMain]                       com.Application : Started Application in 8.551 seconds (JVM running for 977.338)
2017-12-11 11:12:19,499 INFO [Thread-60] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@417361e: startup date [Mon Dec 11 11:12:04 CST 2017]; root of context hierarchy
2017-12-11 11:12:19,502 INFO [Thread-60] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:12:19,503 INFO [Thread-60] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:12:19,506 INFO [Thread-60] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@218f7432{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:19,552 INFO [Thread-60]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:12:19,554 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:12:19,640 INFO [Thread-60] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:12:19,640 INFO [Thread-60] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:12:19,641 INFO [Thread-60] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:12:19,641 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:12:19,647 INFO [Thread-60]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:12:20,643 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:12:20,644 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:12:20,647 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@713f3077: startup date [Mon Dec 11 11:12:20 CST 2017]; root of context hierarchy
2017-12-11 11:12:23,000 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:12:23,870 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:12:23,914 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3267 ms
2017-12-11 11:12:23,982 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:12:23,983 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:12:23,983 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:12:24,044 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:12:24,049 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:12:24,050 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:12:24,050 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:12:24,051 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:12:24,051 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:12:24,051 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:12:24,080 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 55975.
2017-12-11 11:12:24,086 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:12:24,091 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:12:24,091 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:12:24,091 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:12:24,099 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-ec591d18-060a-48f4-8cf1-0c51479546c4
2017-12-11 11:12:24,101 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:12:24,106 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:12:24,133 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:12:24,135 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @988774ms
2017-12-11 11:12:24,138 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@17bc0c50{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:24,138 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:12:24,139 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13250f8a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,145 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3823e2f{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,156 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f4964d3{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,157 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bdc0dc4{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,160 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30d7a0f0{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,161 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b0fbb78{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,161 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7391322d{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,185 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4440c56b{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,186 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@260754d2{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,186 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@652c49dc{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,187 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d713ba9{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40c5c127{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37f614f4{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,190 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e262ed0{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,191 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c4142c6{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,194 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63c2ff5c{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,195 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53157ada{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,197 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3051187{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,199 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c33f925{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,199 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@92786a0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,200 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a107b25{/static,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,201 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14abab7c{/,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,203 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e6ece27{/api,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,204 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7aa9a19a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,205 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ed33dae{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:24,205 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:12:24,892 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:12:25,355 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55992.
2017-12-11 11:12:25,356 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:55992
2017-12-11 11:12:25,356 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:12:25,356 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 55992, None)
2017-12-11 11:12:25,357 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:55992 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 55992, None)
2017-12-11 11:12:25,357 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 55992, None)
2017-12-11 11:12:25,358 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 55992, None)
2017-12-11 11:12:25,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54e53b71{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,366 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:12:25,366 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:12:25,367 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@571a63e0{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,368 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f4030bd{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,369 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a5026a8{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,369 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65507727{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,383 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@529f248b{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:12:25,387 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:12:25,914 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:12:25,914 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:12:25,914 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:12:25,915 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:12:25,915 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:12:25,915 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:12:25,916 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:12:25,916 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:12:25,916 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:12:25,916 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:12:25,917 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:25,920 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:12:25,920 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:12:25,920 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:12:25,928 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:25,928 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:12:26,116 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@713f3077: startup date [Mon Dec 11 11:12:20 CST 2017]; root of context hierarchy
2017-12-11 11:12:26,120 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:26,194 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:26,197 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:12:26,656 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:12:26,774 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:12:26,779 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:12:26,779 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:12:26,780 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:12:26,788 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:12:27,138 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:27,305 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:27,528 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:27,661 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:12:27,692 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:12:27,696 INFO [restartedMain]                       com.Application : Started Application in 7.151 seconds (JVM running for 992.335)
2017-12-11 11:12:32,842 INFO [Thread-81] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@713f3077: startup date [Mon Dec 11 11:12:20 CST 2017]; root of context hierarchy
2017-12-11 11:12:32,844 INFO [Thread-81] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:12:32,845 INFO [Thread-81] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:12:32,847 INFO [Thread-81] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@17bc0c50{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:32,849 INFO [Thread-81]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:12:32,851 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:12:32,857 INFO [Thread-81] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:12:32,857 INFO [Thread-81] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:12:32,857 INFO [Thread-81] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:12:32,857 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:12:32,863 INFO [Thread-81]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:12:34,047 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:12:34,048 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:12:34,058 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2646867: startup date [Mon Dec 11 11:12:34 CST 2017]; root of context hierarchy
2017-12-11 11:12:37,579 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:12:38,629 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:12:38,672 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4614 ms
2017-12-11 11:12:38,732 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:12:38,733 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:12:38,733 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:12:38,798 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:12:38,800 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:12:38,803 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:12:38,803 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:12:38,803 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:12:38,803 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:12:38,803 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:12:38,818 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56022.
2017-12-11 11:12:38,824 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:12:38,826 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:12:38,827 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:12:38,827 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:12:38,836 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-4d502909-0494-4d26-8066-ddc6e8528ac7
2017-12-11 11:12:38,837 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:12:38,840 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:12:38,860 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:12:38,861 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1003501ms
2017-12-11 11:12:38,866 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@54ad0337{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:12:38,866 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:12:38,867 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46311450{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,868 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e5502{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,869 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72cb5adb{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,870 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@508bf542{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,871 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76728b6d{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,871 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23dbfbb4{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@274efaf2{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e10c4f6{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,879 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@627621ff{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,880 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cef51da{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,880 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53172212{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71529653{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,883 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@777f0842{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,883 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ee4275a{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,884 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79becd63{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,884 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33184613{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,885 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d68d94e{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,886 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b9eb9c1{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,887 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24bc5638{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,888 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ae7eae2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,889 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@399de597{/static,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,890 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@402564ae{/,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,891 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a5620cc{/api,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,893 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c1dbad6{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,894 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f5e8c03{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:12:38,895 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:12:39,000 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:12:39,023 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56039.
2017-12-11 11:12:39,023 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56039
2017-12-11 11:12:39,023 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:12:39,023 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56039, None)
2017-12-11 11:12:39,025 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56039 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56039, None)
2017-12-11 11:12:39,025 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56039, None)
2017-12-11 11:12:39,025 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56039, None)
2017-12-11 11:12:39,027 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bb41b0a{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,032 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:12:39,032 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:12:39,033 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5850d457{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,035 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@257a6b79{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,049 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e8a3fa{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b0a3448{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,052 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dbc6b7a{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:12:39,058 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:12:39,306 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:12:39,307 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:12:39,307 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:12:39,308 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:12:39,309 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:12:39,309 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:12:39,310 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:12:39,310 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:12:39,311 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:12:39,311 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:12:39,312 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:39,322 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:12:39,323 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:12:39,324 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:12:39,328 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:12:39,329 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:12:39,421 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2646867: startup date [Mon Dec 11 11:12:34 CST 2017]; root of context hierarchy
2017-12-11 11:12:39,428 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:39,451 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:12:39,460 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:12:39,775 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:12:39,877 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:12:39,883 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:12:39,883 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:12:39,884 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:12:39,900 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:12:40,135 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:40,200 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:40,388 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:12:40,451 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:12:40,482 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:12:40,485 INFO [restartedMain]                       com.Application : Started Application in 6.59 seconds (JVM running for 1005.124)
2017-12-11 11:12:44,548 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:12:44,562 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 13 ms
2017-12-11 11:12:44,562 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:44,566 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:12:44,575 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:12:44,575 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:12:44,575 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:12:44,575 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:12:44,576 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:12:44,577 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:12:44,967 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:44,977 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:44,980 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:44,979 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:44,990 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,991 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,983 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,985 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,027 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,983 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,015 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,045 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,011 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,063 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,009 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,073 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,007 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,078 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,002 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,090 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,998 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,109 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,109 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,109 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:44,995 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,128 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,129 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,136 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,149 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,149 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,160 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,161 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,172 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,173 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,194 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,195 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,214 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,216 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,258 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,259 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,433 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,437 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:45,455 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:45,456 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,200 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,240 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,241 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,245 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,246 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,263 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,264 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,268 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,269 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,280 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,282 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,282 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,283 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,287 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,291 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,291 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,292 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,303 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,304 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,314 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,315 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,316 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,317 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,317 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,304 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,336 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,315 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,397 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,398 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,409 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,410 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,420 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,422 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,433 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,433 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,448 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,449 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,460 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,461 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,474 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,475 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,518 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,522 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:12:47,535 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:12:47,536 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:15:47,448 INFO [Thread-101] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2646867: startup date [Mon Dec 11 11:12:34 CST 2017]; root of context hierarchy
2017-12-11 11:15:47,451 INFO [Thread-101] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:15:47,452 INFO [Thread-101] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:15:47,457 INFO [Thread-101] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@54ad0337{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:15:47,489 INFO [Thread-101]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:15:47,492 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:15:47,515 INFO [Thread-101] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:15:47,515 INFO [Thread-101] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:15:47,516 INFO [Thread-101] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:15:47,516 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:15:47,525 INFO [Thread-101]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:15:48,855 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:15:48,856 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:15:48,860 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@17db657f: startup date [Mon Dec 11 11:15:48 CST 2017]; root of context hierarchy
2017-12-11 11:15:51,037 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:15:52,417 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:15:52,476 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3616 ms
2017-12-11 11:15:52,573 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:15:52,574 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:15:52,574 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:15:52,630 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:15:52,632 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:15:52,633 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:15:52,633 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:15:52,634 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:15:52,634 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:15:52,634 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:15:52,665 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56354.
2017-12-11 11:15:52,670 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:15:52,675 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:15:52,677 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:15:52,677 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:15:52,683 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-d0cf64f9-2e71-4cc2-a7ca-26d5bcda2ae1
2017-12-11 11:15:52,684 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:15:52,686 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:15:52,705 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:15:52,707 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1197346ms
2017-12-11 11:15:52,710 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3607621b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:15:52,710 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:15:52,713 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57577e20{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29240214{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,715 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48746658{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,715 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b482d52{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1de0f28{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,718 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64017670{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,718 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60c5458f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,719 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e42dabc{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,719 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18008da7{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,720 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d4db64a{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,720 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49cd855c{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,721 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c9e7cd4{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,721 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e68f4ed{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,724 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@66ae424d{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,725 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5787b2f3{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,725 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@658b2925{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,726 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e939080{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e29f74b{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,731 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@152a5ca9{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,732 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f158d9f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,733 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11e1f71a{/static,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,734 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61baa7a3{/,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,734 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60b8f66a{/api,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6609cc1e{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b2057ce{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,735 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:15:52,792 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:15:52,809 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56371.
2017-12-11 11:15:52,809 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56371
2017-12-11 11:15:52,810 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:15:52,810 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56371, None)
2017-12-11 11:15:52,811 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56371 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56371, None)
2017-12-11 11:15:52,812 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56371, None)
2017-12-11 11:15:52,812 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56371, None)
2017-12-11 11:15:52,814 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5737bb0b{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,818 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:15:52,819 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:15:52,820 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cf96b57{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,820 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f7ed7a1{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,823 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d7e3c4d{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,823 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@461ddfee{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ae396bf{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:15:52,832 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:15:53,217 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:15:53,218 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:15:53,218 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:15:53,219 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:15:53,219 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:15:53,219 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:15:53,220 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:15:53,220 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:15:53,220 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:15:53,220 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:15:53,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:15:53,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:15:53,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:15:53,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:15:53,235 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:15:53,236 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:15:53,484 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@17db657f: startup date [Mon Dec 11 11:15:48 CST 2017]; root of context hierarchy
2017-12-11 11:15:53,489 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:15:53,503 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:15:53,509 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:15:53,681 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:15:53,763 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:15:53,768 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:15:53,769 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:15:53,770 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:15:53,783 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:15:53,995 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:15:54,131 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:15:54,319 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:15:54,387 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:15:54,430 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:15:54,432 INFO [restartedMain]                       com.Application : Started Application in 5.76 seconds (JVM running for 1199.071)
2017-12-11 11:16:53,757 INFO [Thread-122] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@17db657f: startup date [Mon Dec 11 11:15:48 CST 2017]; root of context hierarchy
2017-12-11 11:16:53,760 INFO [Thread-122] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:16:53,760 INFO [Thread-122] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:16:53,763 INFO [Thread-122] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3607621b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:16:53,823 INFO [Thread-122]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:16:53,824 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:16:53,835 INFO [Thread-122] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:16:53,835 INFO [Thread-122] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:16:53,835 INFO [Thread-122] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:16:53,835 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:16:53,841 INFO [Thread-122]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:16:54,665 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:16:54,665 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:16:54,668 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@29f0284f: startup date [Mon Dec 11 11:16:54 CST 2017]; root of context hierarchy
2017-12-11 11:16:57,140 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:16:58,507 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:16:58,676 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4008 ms
2017-12-11 11:16:58,951 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:16:58,957 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:16:58,958 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:16:59,601 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:16:59,603 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:16:59,603 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:16:59,604 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:16:59,604 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:16:59,604 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:16:59,604 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:16:59,744 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56417.
2017-12-11 11:16:59,748 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:16:59,841 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:16:59,842 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:16:59,842 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:16:59,850 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-8f29228f-6f7c-4541-994b-bb8cf03b3785
2017-12-11 11:16:59,851 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:16:59,852 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:16:59,868 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:16:59,869 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1264509ms
2017-12-11 11:16:59,872 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3c7e7aab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:16:59,872 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:16:59,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f44d55f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63835f22{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,874 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@15301c25{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,875 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e02be3b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,875 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@965eaa7{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,876 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@695ae903{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,876 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b1855c2{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,877 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@477bab2{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,965 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@159e8eb3{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,966 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cceb72f{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,966 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a97623e{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,967 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f58450a{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,968 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79c23979{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,968 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@357178d4{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,969 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c8213e9{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,970 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a09e7f5{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,971 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dbf6d43{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,971 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68ffd750{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,972 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ecc122b{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,973 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40f14ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,974 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b30018b{/static,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,976 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@352b1cd0{/,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,978 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23e03dcd{/api,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,979 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dcbb737{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,980 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62ee8e41{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:16:59,980 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:17:00,033 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:17:00,088 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56434.
2017-12-11 11:17:00,088 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56434
2017-12-11 11:17:00,089 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:17:00,089 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56434, None)
2017-12-11 11:17:00,091 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56434 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56434, None)
2017-12-11 11:17:00,111 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56434, None)
2017-12-11 11:17:00,112 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56434, None)
2017-12-11 11:17:00,113 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6621b2b9{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,120 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:17:00,120 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:17:00,121 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b6cbfb3{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,122 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@674bad8d{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a0193ec{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a65b3a2{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,136 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11bec5a7{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:17:00,142 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:17:00,575 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:17:00,575 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:17:00,579 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:17:00,581 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:17:00,585 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:17:00,585 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:17:00,585 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:17:00,585 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:17:00,585 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:17:00,586 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:17:00,586 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:00,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:17:00,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:17:00,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:17:00,592 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:00,592 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:17:00,670 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/mystatic/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:17:00,825 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@29f0284f: startup date [Mon Dec 11 11:16:54 CST 2017]; root of context hierarchy
2017-12-11 11:17:00,836 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:00,891 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:00,895 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:17:01,198 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:17:01,313 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:17:01,336 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:17:01,336 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:17:01,337 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:17:01,498 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:17:01,804 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:01,877 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:02,089 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:02,174 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:17:02,195 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:17:02,199 INFO [restartedMain]                       com.Application : Started Application in 7.643 seconds (JVM running for 1266.839)
2017-12-11 11:17:06,129 INFO [Thread-143] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@29f0284f: startup date [Mon Dec 11 11:16:54 CST 2017]; root of context hierarchy
2017-12-11 11:17:06,131 INFO [Thread-143] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:17:06,131 INFO [Thread-143] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:17:06,135 INFO [Thread-143] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3c7e7aab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:17:06,149 INFO [Thread-143]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:17:06,150 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:17:06,159 INFO [Thread-143] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:17:06,159 INFO [Thread-143] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:17:06,159 INFO [Thread-143] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:17:06,161 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:17:06,166 INFO [Thread-143]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:17:07,234 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:17:07,235 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:17:07,238 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7fbb5cd2: startup date [Mon Dec 11 11:17:07 CST 2017]; root of context hierarchy
2017-12-11 11:17:09,353 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:17:10,624 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:17:10,684 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3446 ms
2017-12-11 11:17:10,739 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:17:10,740 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:17:10,740 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:17:10,792 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:17:10,794 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:17:10,795 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:17:10,795 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:17:10,795 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:17:10,795 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:17:10,795 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:17:10,810 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56493.
2017-12-11 11:17:10,814 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:17:10,815 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:17:10,818 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:17:10,818 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:17:10,826 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-ef6fb519-53ae-40a7-ae75-a46abd95116a
2017-12-11 11:17:10,827 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:17:10,830 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:17:10,853 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:17:10,855 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1275494ms
2017-12-11 11:17:10,860 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3b0d6fd8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:17:10,860 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:17:10,861 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d84df25{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,863 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@798ec192{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,864 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27b9d33{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,866 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6652fb54{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,867 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79e4ed2b{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@187f1bd1{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,876 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2297ce8e{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1da06b79{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a0c8c12{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,879 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@334be145{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,879 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55fd8f92{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,880 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61c7afda{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,880 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c533191{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,881 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cb7df21{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3173f318{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43411f9a{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,883 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4598076c{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,883 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@534c09c6{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,883 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53a323ea{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,884 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ba7a7af{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,885 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18c46ec0{/static,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,885 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22085d75{/,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,886 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5eac20f2{/api,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,886 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f37720a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,887 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2732d9b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,887 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:17:10,930 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:17:10,947 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56511.
2017-12-11 11:17:10,947 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56511
2017-12-11 11:17:10,947 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:17:10,947 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56511, None)
2017-12-11 11:17:10,948 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56511 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56511, None)
2017-12-11 11:17:10,948 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56511, None)
2017-12-11 11:17:10,948 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56511, None)
2017-12-11 11:17:10,950 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a98eb70{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,956 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:17:10,956 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:17:10,957 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58b3c5db{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,958 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a8c2bc0{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,959 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4dedf913{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,959 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bb69dfd{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,960 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@484f57c6{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:17:10,963 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:17:11,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:17:11,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:17:11,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:17:11,163 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:17:11,164 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:17:11,165 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:17:11,168 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:17:11,168 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:17:11,168 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:17:11,168 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:17:11,169 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:11,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:17:11,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:17:11,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:17:11,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:11,175 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:17:11,210 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:17:11,247 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7fbb5cd2: startup date [Mon Dec 11 11:17:07 CST 2017]; root of context hierarchy
2017-12-11 11:17:11,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:11,267 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:11,270 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:17:11,460 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:17:11,509 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:17:11,512 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:17:11,512 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:17:11,512 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:17:11,518 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:17:11,635 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:11,667 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:11,854 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:11,908 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:17:11,927 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:17:11,929 INFO [restartedMain]                       com.Application : Started Application in 4.78 seconds (JVM running for 1276.567)
2017-12-11 11:17:16,613 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:17:16,616 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 11:17:16,616 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,617 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:17:16,620 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:17:16,694 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,696 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,698 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,699 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,698 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,700 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,699 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,701 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,701 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,702 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,704 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,705 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,710 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,712 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,712 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,712 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,713 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,713 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,713 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,714 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,725 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,726 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,730 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,732 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,732 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,732 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,766 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,766 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,780 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,782 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,793 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,793 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,800 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,801 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,809 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,809 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,816 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,817 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,832 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,833 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,844 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,844 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:16,853 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:17:16,854 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:17:37,092 INFO [Thread-164] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7fbb5cd2: startup date [Mon Dec 11 11:17:07 CST 2017]; root of context hierarchy
2017-12-11 11:17:37,094 INFO [Thread-164] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:17:37,094 INFO [Thread-164] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:17:37,096 INFO [Thread-164] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3b0d6fd8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:17:37,097 INFO [Thread-164]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:17:37,099 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:17:37,105 INFO [Thread-164] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:17:37,106 INFO [Thread-164] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:17:37,106 INFO [Thread-164] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:17:37,106 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:17:37,113 INFO [Thread-164]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:17:38,302 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:17:38,302 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:17:38,307 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55a3ff73: startup date [Mon Dec 11 11:17:38 CST 2017]; root of context hierarchy
2017-12-11 11:17:41,402 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:17:42,297 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:17:42,413 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4106 ms
2017-12-11 11:17:42,543 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:17:42,544 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:17:42,544 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:17:42,601 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:17:42,603 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:17:42,606 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:17:42,606 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:17:42,606 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:17:42,607 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:17:42,607 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:17:42,620 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56552.
2017-12-11 11:17:42,624 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:17:42,626 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:17:42,626 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:17:42,626 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:17:42,632 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-db60c847-64ba-4529-9136-3fd351916de1
2017-12-11 11:17:42,633 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:17:42,635 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:17:42,651 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:17:42,652 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1307291ms
2017-12-11 11:17:42,657 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@44b18234{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:17:42,657 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:17:42,658 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f27f92d{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,659 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bbda5e1{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,659 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c6755f0{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,660 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ab5f57b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59f94446{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,661 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ebc483f{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3812826e{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54946c4c{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,662 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2580bab{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,663 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49b1ece{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,663 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47c77749{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,664 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f1f2f8b{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,664 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4792ccc4{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,665 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@138926f1{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,665 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65d67eff{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,666 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b6ff9eb{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,666 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72469298{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,667 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@80bcecf{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,667 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6388e849{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,668 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@377e5cc5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,669 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55abbf27{/static,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,669 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5db2e883{/,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,670 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a2d47d6{/api,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,670 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e8c2373{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,671 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5443db62{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,671 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:17:42,715 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:17:42,729 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56569.
2017-12-11 11:17:42,729 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56569
2017-12-11 11:17:42,729 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:17:42,729 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56569, None)
2017-12-11 11:17:42,730 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56569 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56569, None)
2017-12-11 11:17:42,730 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56569, None)
2017-12-11 11:17:42,730 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56569, None)
2017-12-11 11:17:42,732 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e5d4920{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,736 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:17:42,736 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:17:42,737 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@452cc6ba{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,737 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55d8a8ff{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,740 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6db9700b{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,740 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a87b3cd{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,742 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38c5b795{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:17:42,747 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:17:42,958 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:17:42,958 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:17:42,958 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:17:42,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:17:42,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:17:42,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:17:42,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:17:42,963 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:17:42,972 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:17:42,974 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:17:42,974 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:42,976 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:17:42,977 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:17:42,977 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:17:43,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:17:43,028 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:17:43,138 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55a3ff73: startup date [Mon Dec 11 11:17:38 CST 2017]; root of context hierarchy
2017-12-11 11:17:43,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:43,156 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:17:43,160 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:17:43,360 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:17:43,442 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:17:43,447 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:17:43,447 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:17:43,448 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:17:43,475 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:17:43,681 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:43,738 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:43,865 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:17:43,916 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:17:43,942 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:17:43,945 INFO [restartedMain]                       com.Application : Started Application in 5.887 seconds (JVM running for 1308.583)
2017-12-11 11:18:37,123 INFO [Thread-181] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55a3ff73: startup date [Mon Dec 11 11:17:38 CST 2017]; root of context hierarchy
2017-12-11 11:18:37,124 INFO [Thread-181] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:18:37,124 INFO [Thread-181] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:18:37,127 INFO [Thread-181] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@44b18234{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:18:37,131 INFO [Thread-181]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:18:37,137 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:18:37,149 INFO [Thread-181] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:18:37,149 INFO [Thread-181] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:18:37,150 INFO [Thread-181] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:18:37,150 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:18:37,156 INFO [Thread-181]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:18:38,174 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:18:38,174 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:18:38,183 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1d69bfd5: startup date [Mon Dec 11 11:18:38 CST 2017]; root of context hierarchy
2017-12-11 11:18:40,187 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:18:41,297 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:18:41,370 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3187 ms
2017-12-11 11:18:41,606 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:18:41,607 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:18:41,607 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:18:41,755 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:18:41,756 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:18:41,758 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:18:41,758 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:18:41,758 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:18:41,758 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:18:41,759 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:18:41,985 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56607.
2017-12-11 11:18:41,999 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:18:42,003 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:18:42,004 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:18:42,004 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:18:42,014 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-b4233aeb-5a91-4549-be70-c980f2108528
2017-12-11 11:18:42,014 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:18:42,016 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:18:42,035 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:18:42,038 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1366677ms
2017-12-11 11:18:42,040 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2e2a4fb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:18:42,040 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:18:42,041 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45ff9bf3{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e0af8ec{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40c17071{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,043 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e58943b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ed78874{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3574e11c{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33ca6d1f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@342a00a3{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,048 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13485d32{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,048 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72892c87{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,071 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f5c48c{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e280903{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,072 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c3f5dcf{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,073 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60acc52b{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,076 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e762755{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,076 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2373ecb3{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,079 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a02b188{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14ff1a96{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@152610ee{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,081 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7add1bdb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,082 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e296b5c{/static,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,083 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ea1500b{/,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,083 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d6187b2{/api,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,084 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33daf5d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,084 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e0fc995{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,084 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:18:42,495 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:18:42,561 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56624.
2017-12-11 11:18:42,564 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56624
2017-12-11 11:18:42,564 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:18:42,565 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56624, None)
2017-12-11 11:18:42,568 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56624 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56624, None)
2017-12-11 11:18:42,569 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56624, None)
2017-12-11 11:18:42,569 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56624, None)
2017-12-11 11:18:42,573 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d06b958{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,578 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:18:42,578 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:18:42,580 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f527508{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,581 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c1bd5de{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,581 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ebb6bf6{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,583 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@532a1837{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,584 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4dd9bc2f{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:18:42,589 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:18:42,955 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:18:42,955 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:18:42,955 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:18:42,956 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:18:42,956 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:18:42,956 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:18:42,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:18:42,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:18:42,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:18:42,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:18:42,961 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:18:42,963 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:18:42,963 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:18:42,964 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:18:42,966 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:18:42,966 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:18:43,006 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:18:43,086 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1d69bfd5: startup date [Mon Dec 11 11:18:38 CST 2017]; root of context hierarchy
2017-12-11 11:18:43,091 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:18:43,123 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:18:43,152 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:18:43,516 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:18:43,630 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:18:43,639 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:18:43,639 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:18:43,649 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:18:43,658 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:18:43,942 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:44,052 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:44,349 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:44,422 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:18:44,501 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:18:44,504 INFO [restartedMain]                       com.Application : Started Application in 6.474 seconds (JVM running for 1369.143)
2017-12-11 11:18:46,665 INFO [Thread-200] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1d69bfd5: startup date [Mon Dec 11 11:18:38 CST 2017]; root of context hierarchy
2017-12-11 11:18:46,667 INFO [Thread-200] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:18:46,668 INFO [Thread-200] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:18:46,670 INFO [Thread-200] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2e2a4fb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:18:46,672 INFO [Thread-200]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:18:46,674 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:18:46,682 INFO [Thread-200] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:18:46,682 INFO [Thread-200] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:18:46,683 INFO [Thread-200] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:18:46,683 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:18:46,689 INFO [Thread-200]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:18:47,621 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13836 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:18:47,621 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:18:47,630 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@618c60c1: startup date [Mon Dec 11 11:18:47 CST 2017]; root of context hierarchy
2017-12-11 11:18:49,460 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:18:50,082 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:18:50,133 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2503 ms
2017-12-11 11:18:50,266 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:18:50,266 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:18:50,267 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:18:50,370 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:18:50,371 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:18:50,372 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:18:50,372 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:18:50,372 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:18:50,372 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:18:50,372 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:18:50,407 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56651.
2017-12-11 11:18:50,412 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:18:50,445 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:18:50,446 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:18:50,446 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:18:50,453 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-b4396cb3-ebd4-403a-ab0e-b4a9bdfdd20a
2017-12-11 11:18:50,454 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:18:50,459 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:18:50,472 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:18:50,474 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @1375113ms
2017-12-11 11:18:50,482 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@31525988{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:18:50,482 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:18:50,483 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5142f3e4{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,483 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c7699f2{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,484 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69d00433{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,484 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5bb7bdf0{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,485 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45ec8d3d{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,485 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@703c2699{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,486 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5acf0e32{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,486 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f5c07b1{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,487 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4987994b{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,496 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@172df64d{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,496 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@549cc706{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c433d4a{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d0fb867{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d52982b{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,498 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d5444fa{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,498 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ed22b86{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,501 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ca6c9ca{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,502 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@171fe07e{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,502 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f439125{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,503 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ce55fb7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,504 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35a1da5a{/static,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,504 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7daae480{/,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,505 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b1d4f6{/api,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c0bb419{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,508 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@153b24b7{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,509 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:18:50,605 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:18:50,685 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56668.
2017-12-11 11:18:50,689 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56668
2017-12-11 11:18:50,690 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:18:50,693 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56668, None)
2017-12-11 11:18:50,696 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56668 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56668, None)
2017-12-11 11:18:50,699 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56668, None)
2017-12-11 11:18:50,699 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56668, None)
2017-12-11 11:18:50,700 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@310d9f9b{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,704 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:18:50,704 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:18:50,705 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5654aedb{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,705 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@203defa8{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,711 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49e20ec3{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73247c5c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,717 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bdefe1b{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:18:50,728 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:18:51,041 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:18:51,042 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:18:51,042 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:18:51,043 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:18:51,043 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:18:51,043 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:18:51,043 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:18:51,044 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:18:51,046 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:18:51,051 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:18:51,054 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:18:51,056 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:18:51,057 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:18:51,057 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:18:51,060 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:18:51,063 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:18:51,115 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:18:51,213 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@618c60c1: startup date [Mon Dec 11 11:18:47 CST 2017]; root of context hierarchy
2017-12-11 11:18:51,217 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:18:51,299 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:18:51,307 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:18:51,935 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:18:52,046 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:18:52,068 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:18:52,068 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:18:52,071 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:18:52,084 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:18:52,370 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:52,481 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:52,683 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:18:52,732 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:18:52,761 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:18:52,764 INFO [restartedMain]                       com.Application : Started Application in 5.257 seconds (JVM running for 1377.404)
2017-12-11 11:18:56,051 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:18:56,053 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 2 ms
2017-12-11 11:18:56,053 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,055 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:18:56,057 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:18:56,057 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:18:56,057 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:18:56,057 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:18:56,058 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:18:56,058 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:18:56,118 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,128 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,131 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,131 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,135 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,135 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,135 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,135 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,122 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,121 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,137 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,137 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,121 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,134 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,138 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,133 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,141 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,132 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,150 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,151 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,214 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,215 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,222 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,223 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,233 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,234 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,245 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,247 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,268 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,271 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,303 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,308 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,321 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,322 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,334 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,335 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,346 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,347 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:18:56,456 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:18:56,459 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,648 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,771 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,773 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,776 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,776 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,777 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,781 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,782 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,779 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,784 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,779 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,790 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,791 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,778 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,798 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,778 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,799 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,800 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,803 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,803 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,804 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,805 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,809 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,821 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,822 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:18,822 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:18,854 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,020 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,020 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,043 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,043 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,071 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,071 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,091 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,091 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,147 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,148 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,166 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,167 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,207 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,209 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,226 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,227 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:19,259 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:19,259 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,393 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,456 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,456 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,457 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,459 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,463 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,464 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,465 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,466 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,466 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,466 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,468 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,469 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,470 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,470 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,471 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,471 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,472 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,473 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,473 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,473 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,474 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,475 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,475 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,478 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,475 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,483 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,521 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,554 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,567 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,567 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,587 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,588 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,608 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,610 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,625 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,626 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,639 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,639 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:20,657 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:20,657 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,534 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,596 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,597 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,601 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,603 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,623 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,624 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,626 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,627 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,628 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,630 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,631 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,631 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,635 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,636 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,638 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,638 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,644 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,645 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,648 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,649 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,650 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,651 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,652 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,653 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,655 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,656 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,739 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,740 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,794 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,795 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,839 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,840 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,866 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,866 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,905 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,905 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,922 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,924 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,950 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,951 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:22,968 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:22,969 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:19:23,055 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:19:23,056 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:21:17,064 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:21:17,068 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:21:18,291 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@420f2815: startup date [Mon Dec 11 11:21:18 CST 2017]; root of context hierarchy
2017-12-11 11:21:18,569 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 11:21:23,238 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:21:26,583 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:21:27,935 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 9652 ms
2017-12-11 11:21:28,523 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:21:28,532 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:21:28,532 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:21:29,472 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:21:29,840 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 11:21:30,039 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$611ae048.CGLIB$getSparkContext$5(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$611ae048$$FastClassBySpringCGLIB$$891dcd22.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$611ae048.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 11:21:30,246 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:21:30,712 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:21:30,714 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:21:30,715 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:21:30,716 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:21:30,717 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:21:34,644 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56760.
2017-12-11 11:21:34,704 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:21:34,796 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:21:34,809 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:21:34,810 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:21:34,841 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-af8390cd-48dc-4002-b8aa-5364dc451283
2017-12-11 11:21:34,922 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:21:35,101 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:21:35,748 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @24893ms
2017-12-11 11:21:36,114 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:21:36,154 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @25301ms
2017-12-11 11:21:36,209 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@6a350655{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:21:36,209 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:21:36,270 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c92511b{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57eaed73{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,272 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ad2bea0{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,276 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f45ddd5{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,278 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@531d1f34{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,279 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5eddc596{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,280 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f2cf434{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,284 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49dd5a45{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,286 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@753f1a56{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,288 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53960c34{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,290 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a64ea3{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,291 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40539c8c{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,293 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f0e2f09{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,294 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e24989e{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,296 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30296114{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,299 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36cd8f31{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,301 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@487e42ae{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,303 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36116cf3{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,305 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ad26f6e{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,306 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35e6906e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,330 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5eb17fa{/static,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b09cdb5{/,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,337 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c53d364{/api,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,339 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a787a95{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,343 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2908ea7a{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:21:36,353 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:21:36,877 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:21:36,939 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56777.
2017-12-11 11:21:36,940 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56777
2017-12-11 11:21:36,944 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:21:36,948 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56777, None)
2017-12-11 11:21:36,958 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56777 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56777, None)
2017-12-11 11:21:36,971 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56777, None)
2017-12-11 11:21:36,973 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56777, None)
2017-12-11 11:21:37,219 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2cc4917b{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:37,491 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:21:37,493 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:21:37,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@142f7d8d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:21:37,508 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a5e7395{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:37,511 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f32279f{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:21:37,512 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ed0206c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:21:37,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e6aec3a{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:21:39,694 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 11:21:41,022 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:21:43,632 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:21:43,634 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:21:43,634 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:21:43,637 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:21:43,638 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:21:43,638 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:21:43,639 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:21:43,639 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:21:43,640 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:21:43,640 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:21:43,641 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:21:43,659 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:21:43,660 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:21:43,662 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:21:43,683 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:21:43,683 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:21:44,110 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:21:44,284 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@420f2815: startup date [Mon Dec 11 11:21:18 CST 2017]; root of context hierarchy
2017-12-11 11:21:44,345 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:21:44,768 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:21:44,837 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:21:49,846 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:21:50,222 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:21:50,326 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:21:50,327 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:21:50,481 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:21:50,607 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:21:53,197 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:21:53,641 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:21:54,259 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:21:54,375 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:21:54,540 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:21:54,557 INFO [restartedMain]                       com.Application : Started Application in 39.418 seconds (JVM running for 43.705)
2017-12-11 11:22:15,468 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:22:15,468 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:22:15,510 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 42 ms
2017-12-11 11:22:15,518 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,559 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:22:15,615 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:22:15,615 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:22:15,615 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:22:15,615 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:22:15,620 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:22:15,620 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:22:15,752 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,755 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,756 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,764 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,761 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,777 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,778 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,783 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,766 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,771 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,791 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,792 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,770 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,769 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,767 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,795 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,798 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,799 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,793 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,801 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,788 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,811 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,801 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:15,818 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,822 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:15,834 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,001 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,007 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,036 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,037 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,058 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,060 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,073 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,076 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,086 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,088 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,102 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,103 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,121 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,122 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,133 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,134 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,176 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,177 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:16,346 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:16,365 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,293 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,383 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,384 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,409 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,412 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,432 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,433 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,434 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,440 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,448 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,449 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,450 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,451 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,477 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,480 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,487 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,488 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,489 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,489 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,503 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,507 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,510 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,513 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,530 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,534 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,551 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,553 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,623 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,626 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,669 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,670 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,686 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,687 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,704 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,705 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,719 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,720 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,731 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,732 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,744 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,746 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,760 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,761 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:17,772 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:17,773 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:22:23,904 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:37,823 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:37,925 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:22:37,928 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.map] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:23:36,513 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@420f2815: startup date [Mon Dec 11 11:21:18 CST 2017]; root of context hierarchy
2017-12-11 11:23:36,524 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:23:36,526 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:23:36,545 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@6a350655{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:23:36,559 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:23:36,578 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:23:36,601 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:23:36,602 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:23:36,603 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:23:36,611 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:23:36,648 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:23:37,019 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 11:23:37,057 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:23:37,094 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 11:23:37,794 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:23:37,801 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:23:37,822 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6488c8f2: startup date [Mon Dec 11 11:23:37 CST 2017]; root of context hierarchy
2017-12-11 11:23:41,276 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:23:42,936 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:23:42,972 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5150 ms
2017-12-11 11:23:43,071 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:23:43,072 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:23:43,073 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:23:43,153 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:23:43,155 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:23:43,157 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:23:43,159 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:23:43,159 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:23:43,159 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:23:43,159 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:23:43,184 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 56873.
2017-12-11 11:23:43,193 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:23:43,201 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:23:43,208 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:23:43,209 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:23:43,220 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-3f7487b3-25f8-4b97-bde1-68e1ed2c606b
2017-12-11 11:23:43,227 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:23:43,232 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:23:43,274 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:23:43,276 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @152424ms
2017-12-11 11:23:43,287 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@5389e950{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:23:43,288 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:23:43,289 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b1611c8{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,289 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22878fc6{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,290 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57beffd{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,291 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@535567c{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,292 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2041c695{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,293 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4aa4533{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,293 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ebb2a47{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,297 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4859cd8e{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,298 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3eabea77{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,299 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@426b7c23{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,301 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42e60718{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,303 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@584a6187{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,304 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@748deffe{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,305 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72ab5829{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,306 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60ddfc40{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,307 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3743fdf{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,307 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57dd0361{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,308 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cdeaf9c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,309 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65221c2d{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,310 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cc7935{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,316 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74f5ef5b{/static,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,317 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32fa348d{/,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,320 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72370530{/api,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,321 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@749f6534{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,322 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f564f62{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,322 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:23:43,416 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:23:43,432 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56890.
2017-12-11 11:23:43,433 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:56890
2017-12-11 11:23:43,433 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:23:43,433 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 56890, None)
2017-12-11 11:23:43,434 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:56890 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 56890, None)
2017-12-11 11:23:43,435 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 56890, None)
2017-12-11 11:23:43,435 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 56890, None)
2017-12-11 11:23:43,441 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27e7be64{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,454 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:23:43,454 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:23:43,456 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46c4118d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,457 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e943004{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,459 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35775fa8{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,460 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d6e00ba{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,463 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e063893{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:23:43,473 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:23:43,804 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:23:43,804 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:23:43,805 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:23:43,807 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:23:43,807 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:23:43,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:23:43,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:23:43,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:23:43,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:23:43,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:23:43,809 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:23:43,817 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:23:43,818 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:23:43,818 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:23:43,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:23:43,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:23:43,912 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:23:43,978 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6488c8f2: startup date [Mon Dec 11 11:23:37 CST 2017]; root of context hierarchy
2017-12-11 11:23:43,986 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:23:44,044 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:23:44,072 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:23:44,386 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:23:44,539 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:23:44,550 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:23:44,550 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:23:44,551 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:23:44,569 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:23:45,007 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:23:45,136 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:23:45,601 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:23:45,743 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:23:45,774 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:23:45,782 INFO [restartedMain]                       com.Application : Started Application in 8.152 seconds (JVM running for 154.93)
2017-12-11 11:25:20,777 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6488c8f2: startup date [Mon Dec 11 11:23:37 CST 2017]; root of context hierarchy
2017-12-11 11:25:20,778 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:25:20,778 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:25:20,781 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@5389e950{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:20,782 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:25:20,784 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:25:20,793 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:25:20,793 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:25:20,793 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:25:20,793 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:25:20,800 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:25:22,312 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:25:22,313 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:25:22,326 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@53505af6: startup date [Mon Dec 11 11:25:22 CST 2017]; root of context hierarchy
2017-12-11 11:25:25,008 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:25:26,201 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:25:26,307 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3981 ms
2017-12-11 11:25:26,468 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:25:26,469 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:25:26,469 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:25:26,609 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:25:26,611 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:25:26,617 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:25:26,618 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:25:26,618 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:25:26,618 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:25:26,643 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:25:26,666 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57013.
2017-12-11 11:25:26,671 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:25:26,677 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:25:26,678 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:25:26,678 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:25:26,684 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-f827f152-cf5d-49ba-b99e-fff93763c99d
2017-12-11 11:25:26,690 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:25:26,696 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:25:26,802 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:25:26,805 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @255953ms
2017-12-11 11:25:26,809 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2ae8e651{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:26,809 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:25:26,810 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32f2b79e{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,901 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@da0df61{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,902 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47fe6f31{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,903 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24b18056{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,903 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b190133{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,904 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@448cc6d1{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,905 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b69fe8b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,905 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f71a611{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,906 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58abea{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,907 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@653cc7dd{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,907 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@815b1c6{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,908 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c11caf{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,909 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53fc40d9{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,910 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@591ad1f7{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,911 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cd5ab84{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,912 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f4d6ffb{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,914 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c37718{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d05a2d2{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,916 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cf82735{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,917 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c0da493{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c1fb762{/static,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,920 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5566e04f{/,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,921 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4af1d529{/api,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,921 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2181013{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,928 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5724baa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:26,928 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:25:26,985 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:25:27,111 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57030.
2017-12-11 11:25:27,119 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57030
2017-12-11 11:25:27,124 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:25:27,124 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57030, None)
2017-12-11 11:25:27,126 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57030 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57030, None)
2017-12-11 11:25:27,127 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57030, None)
2017-12-11 11:25:27,127 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57030, None)
2017-12-11 11:25:27,130 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b452c84{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,135 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:25:27,180 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:25:27,183 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f5a031e{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,185 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5315daea{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,188 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@140c8e73{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,191 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ca85116{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,198 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18b90cf5{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:25:27,204 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:25:27,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:25:27,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:25:27,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:25:27,810 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:25:27,810 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:25:27,810 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:25:27,812 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:25:27,812 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:25:27,813 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:25:27,813 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:25:27,814 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:27,819 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:25:27,820 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:25:27,820 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:25:27,823 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:27,827 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:25:27,870 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:25:28,024 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@53505af6: startup date [Mon Dec 11 11:25:22 CST 2017]; root of context hierarchy
2017-12-11 11:25:28,036 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:28,109 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:28,120 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:25:28,689 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:25:29,033 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:25:29,039 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:25:29,039 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:25:29,041 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:25:29,059 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:25:29,635 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:29,740 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:29,948 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:30,055 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:25:30,142 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:25:30,149 INFO [restartedMain]                       com.Application : Started Application in 8.093 seconds (JVM running for 259.297)
2017-12-11 11:25:33,635 INFO [Thread-38] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@53505af6: startup date [Mon Dec 11 11:25:22 CST 2017]; root of context hierarchy
2017-12-11 11:25:33,637 INFO [Thread-38] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:25:33,638 INFO [Thread-38] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:25:33,641 INFO [Thread-38] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2ae8e651{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:33,642 INFO [Thread-38]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:25:33,644 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:25:33,652 INFO [Thread-38] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:25:33,652 INFO [Thread-38] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:25:33,652 INFO [Thread-38] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:25:33,652 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:25:33,658 INFO [Thread-38]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:25:34,546 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:25:34,548 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:25:34,555 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@58c543d7: startup date [Mon Dec 11 11:25:34 CST 2017]; root of context hierarchy
2017-12-11 11:25:38,011 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:25:39,646 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:25:39,914 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5359 ms
2017-12-11 11:25:40,180 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:25:40,182 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:25:40,182 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:25:40,473 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:25:40,474 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:25:40,475 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:25:40,475 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:25:40,475 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:25:40,477 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:25:40,477 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:25:40,622 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57069.
2017-12-11 11:25:40,688 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:25:40,707 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:25:40,707 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:25:40,707 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:25:40,716 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-32f2d177-6179-4f3d-90d8-d007fa2a677a
2017-12-11 11:25:40,717 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:25:40,720 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:25:40,752 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:25:40,754 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @269901ms
2017-12-11 11:25:40,767 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@636e5a17{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:40,767 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:25:40,768 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dc165fb{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:25:40,769 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f3a8c1c{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:40,770 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@588d819a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:25:40,771 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a020172{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:40,772 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e1acb15{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:25:40,772 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cfb5dd7{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,278 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26b8ab35{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,279 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@402cd98b{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,280 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@199a4511{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,281 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60b7b6a9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,281 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14aa8d75{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,282 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1375570{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,283 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16f5199{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,284 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@232c9448{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,284 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c81f4a7{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,285 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6df264ae{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,286 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@551540d9{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,287 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@582feee7{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,288 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c1ae40{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,289 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@34e329d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,292 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f35528b{/static,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,293 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74f3cd9d{/,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,294 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d595452{/api,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,295 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21fe96fd{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,296 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@66f2c4fb{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,296 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:25:41,652 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:25:41,782 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57086.
2017-12-11 11:25:41,782 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57086
2017-12-11 11:25:41,783 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:25:41,783 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57086, None)
2017-12-11 11:25:41,785 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57086 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57086, None)
2017-12-11 11:25:41,786 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57086, None)
2017-12-11 11:25:41,786 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57086, None)
2017-12-11 11:25:41,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41d3ec84{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,794 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:25:41,794 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:25:41,796 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d6b1f3e{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,797 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38df6509{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39c8e1ee{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,799 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a710f1{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,803 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78e43844{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:25:41,810 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:25:42,152 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:25:42,153 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:25:42,155 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:25:42,158 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:25:42,158 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:25:42,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:25:42,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:25:42,162 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:25:42,163 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:25:42,163 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:25:42,164 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:42,170 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:25:42,172 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:25:42,173 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:25:42,176 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:42,178 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:25:42,785 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:25:42,867 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@58c543d7: startup date [Mon Dec 11 11:25:34 CST 2017]; root of context hierarchy
2017-12-11 11:25:42,872 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:42,893 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:42,896 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:25:43,232 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:25:43,405 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:25:43,418 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:25:43,418 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:25:43,430 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:25:43,459 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:25:44,349 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:44,970 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:45,504 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:45,714 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:25:46,116 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:25:46,121 INFO [restartedMain]                       com.Application : Started Application in 11.789 seconds (JVM running for 275.268)
2017-12-11 11:25:46,122 INFO [Thread-59] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@58c543d7: startup date [Mon Dec 11 11:25:34 CST 2017]; root of context hierarchy
2017-12-11 11:25:46,124 INFO [Thread-59] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:25:46,124 INFO [Thread-59] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:25:46,138 INFO [Thread-59] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@636e5a17{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:46,241 INFO [Thread-59]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:25:46,247 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:25:46,266 INFO [Thread-59] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:25:46,266 INFO [Thread-59] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:25:46,268 INFO [Thread-59] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:25:46,269 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:25:46,278 INFO [Thread-59]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:25:47,543 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:25:47,543 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:25:47,548 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@489d6bc7: startup date [Mon Dec 11 11:25:47 CST 2017]; root of context hierarchy
2017-12-11 11:25:50,142 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:25:51,100 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:25:51,211 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3663 ms
2017-12-11 11:25:51,414 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:25:51,415 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:25:51,415 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:25:51,545 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:25:51,560 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:25:51,563 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:25:51,563 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:25:51,563 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:25:51,563 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:25:51,563 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:25:51,614 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57114.
2017-12-11 11:25:51,623 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:25:51,630 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:25:51,631 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:25:51,631 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:25:51,651 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-5818bd27-e855-44cd-80af-6844788868f1
2017-12-11 11:25:51,653 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:25:51,659 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:25:51,692 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:25:51,695 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @280842ms
2017-12-11 11:25:51,704 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@45b05b91{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:51,705 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:25:51,706 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b6d50dd{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@494dde9b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,710 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e07815f{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,712 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a66d438{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,712 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79bb549e{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,713 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b961c4c{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,713 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26ae97f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,714 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@504d6a6e{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,715 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16cf03bf{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,716 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75494cde{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,719 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1091b68{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,722 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12d2138d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,723 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dc4265a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,725 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2659416c{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,726 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33ca11bc{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,727 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@506e563a{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,728 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c427676{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,744 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23c53552{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@654a446c{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,746 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2db3eca5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,747 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73c4764c{/static,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,748 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57f5d7ad{/,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,748 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12c0a8c9{/api,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,749 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63c591b6{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,750 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1543e76b{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,752 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:25:51,870 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:25:51,912 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57131.
2017-12-11 11:25:51,912 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57131
2017-12-11 11:25:51,912 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:25:51,912 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57131, None)
2017-12-11 11:25:51,914 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57131 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57131, None)
2017-12-11 11:25:51,931 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57131, None)
2017-12-11 11:25:51,931 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57131, None)
2017-12-11 11:25:51,938 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73ee43d8{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,954 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:25:51,954 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:25:51,957 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d428989{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,958 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e1d31{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,960 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35733faf{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,960 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48fff31e{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,962 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22b07c78{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:25:51,972 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:25:52,440 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:25:52,441 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:25:52,441 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:25:52,442 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:25:52,443 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:25:52,443 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:25:52,443 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:25:52,443 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:25:52,444 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:25:52,444 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:25:52,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:52,457 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:25:52,458 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:25:52,458 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:25:52,468 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:25:52,469 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:25:52,569 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:25:52,696 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@489d6bc7: startup date [Mon Dec 11 11:25:47 CST 2017]; root of context hierarchy
2017-12-11 11:25:52,702 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:52,725 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:25:52,762 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:25:53,028 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:25:53,130 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:25:53,136 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:25:53,137 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:25:53,138 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:25:53,151 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:25:53,631 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:53,787 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:54,088 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:25:54,159 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:25:54,199 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:25:54,203 INFO [restartedMain]                       com.Application : Started Application in 6.846 seconds (JVM running for 283.35)
2017-12-11 11:25:56,853 INFO [Thread-77] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@489d6bc7: startup date [Mon Dec 11 11:25:47 CST 2017]; root of context hierarchy
2017-12-11 11:25:56,855 INFO [Thread-77] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:25:56,856 INFO [Thread-77] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:25:56,858 INFO [Thread-77] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@45b05b91{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:25:56,859 INFO [Thread-77]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:25:56,861 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:25:56,873 INFO [Thread-77] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:25:56,873 INFO [Thread-77] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:25:56,874 INFO [Thread-77] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:25:56,874 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:25:56,880 INFO [Thread-77]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:25:57,615 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:25:57,615 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:25:57,621 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6a5aab: startup date [Mon Dec 11 11:25:57 CST 2017]; root of context hierarchy
2017-12-11 11:25:59,167 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:26:00,975 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:26:01,118 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3497 ms
2017-12-11 11:26:01,270 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:26:01,270 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:26:01,270 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:26:01,557 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:26:01,561 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:26:01,564 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:26:01,565 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:26:01,565 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:26:01,565 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:26:01,565 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:26:01,843 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57164.
2017-12-11 11:26:01,848 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:26:02,356 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:26:02,371 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:26:02,371 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:26:02,378 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-88b61c20-2eed-4ec8-8482-599535fa57fc
2017-12-11 11:26:02,379 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:26:02,381 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:26:02,400 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:26:02,402 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @291549ms
2017-12-11 11:26:02,405 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@1b6562ab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:26:02,405 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:26:02,406 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3126e8e8{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,407 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25a18c7b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,407 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@138609a2{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,408 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@232fb905{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,408 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1baf29bf{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,409 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e0ad304{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,433 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@baa5b9e{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,433 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e8293cc{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,434 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d9380a6{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,435 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@167bfade{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,435 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@313e4973{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c70c8b8{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@543f089c{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,437 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@384c943c{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,437 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ebe2505{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,438 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d2d9b54{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,439 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d13e748{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,440 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dd9a053{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,440 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ec9badc{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,441 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69478009{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,441 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77964f1{/static,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,442 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68bfd26d{/,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,443 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49aa3602{/api,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,443 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@516438d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,444 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13b404e1{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,445 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:26:02,594 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:26:02,687 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57181.
2017-12-11 11:26:02,687 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57181
2017-12-11 11:26:02,687 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:26:02,687 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57181, None)
2017-12-11 11:26:02,689 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57181 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57181, None)
2017-12-11 11:26:02,689 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57181, None)
2017-12-11 11:26:02,689 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57181, None)
2017-12-11 11:26:02,691 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f1a2554{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,697 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:26:02,697 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:26:02,698 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fd54a42{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,699 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1449476f{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,700 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a5136d5{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,701 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d0ed01d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,704 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a3032f{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:26:02,713 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:26:03,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:26:03,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:26:03,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:26:03,072 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:26:03,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:26:03,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:26:03,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:26:03,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:26:03,074 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:26:03,074 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:26:03,075 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:26:03,080 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:26:03,081 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:26:03,081 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:26:03,088 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:26:03,089 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:26:03,201 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:26:03,268 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6a5aab: startup date [Mon Dec 11 11:25:57 CST 2017]; root of context hierarchy
2017-12-11 11:26:03,273 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:26:03,293 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:26:03,317 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:26:03,582 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:26:03,711 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:26:03,720 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:26:03,720 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:26:03,722 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:26:03,733 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:26:04,185 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:04,309 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:04,489 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:04,564 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:26:04,990 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:26:04,994 INFO [restartedMain]                       com.Application : Started Application in 7.474 seconds (JVM running for 294.142)
2017-12-11 11:26:08,032 INFO [Thread-98] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6a5aab: startup date [Mon Dec 11 11:25:57 CST 2017]; root of context hierarchy
2017-12-11 11:26:08,034 INFO [Thread-98] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:26:08,034 INFO [Thread-98] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:26:08,037 INFO [Thread-98] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@1b6562ab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:26:08,037 INFO [Thread-98]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:26:08,039 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:26:08,046 INFO [Thread-98] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:26:08,046 INFO [Thread-98] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:26:08,046 INFO [Thread-98] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:26:08,047 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:26:08,053 INFO [Thread-98]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:26:09,008 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:26:09,009 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:26:09,012 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33f350b4: startup date [Mon Dec 11 11:26:09 CST 2017]; root of context hierarchy
2017-12-11 11:26:11,308 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:26:13,032 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:26:13,168 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4156 ms
2017-12-11 11:26:13,310 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:26:13,310 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:26:13,310 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:26:13,374 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:26:13,376 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:26:13,377 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:26:13,377 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:26:13,377 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:26:13,378 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:26:13,378 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:26:13,391 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57209.
2017-12-11 11:26:13,394 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:26:13,396 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:26:13,396 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:26:13,397 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:26:13,401 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-3c7676f6-d416-4714-a1b7-0eee8aa0534e
2017-12-11 11:26:13,402 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:26:13,404 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:26:13,417 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:26:13,419 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @302567ms
2017-12-11 11:26:13,423 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@633f813{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:26:13,423 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:26:13,424 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d736635{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,424 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21f5865e{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,425 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7973f4c9{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,426 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@aab03e8{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,426 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7885eccd{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,427 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@209938c7{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,427 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d02b943{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,427 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@384e58e1{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,428 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c3e55fe{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,428 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17fc4ba3{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,429 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cfcdfb2{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,429 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@87b7afc{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,430 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fd33aff{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,430 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dbf514d{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7de6ae9c{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@574eead2{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,432 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1746a818{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,433 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@603081b4{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,434 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ecd2a51{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,435 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dc3e520{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cc9e190{/static,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,437 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30a113c5{/,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,438 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@669b9b8f{/api,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,439 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@421ff457{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,439 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42a3de71{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,439 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:26:13,529 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:26:13,561 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57226.
2017-12-11 11:26:13,562 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57226
2017-12-11 11:26:13,562 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:26:13,563 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57226, None)
2017-12-11 11:26:13,564 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57226 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57226, None)
2017-12-11 11:26:13,565 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57226, None)
2017-12-11 11:26:13,565 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57226, None)
2017-12-11 11:26:13,567 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@783ff84a{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,578 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:26:13,578 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:26:13,579 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@582c8ae4{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,579 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41d42c30{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,580 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50b204c2{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,580 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30e3570d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,582 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8583b3c{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:26:13,588 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:26:13,798 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:26:13,802 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:26:13,804 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:26:13,861 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:26:13,862 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:26:13,862 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:26:13,863 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:26:13,863 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:26:13,863 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:26:13,864 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:26:13,864 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:26:13,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:26:13,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:26:13,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:26:13,904 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:26:14,016 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:26:14,063 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:26:14,131 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33f350b4: startup date [Mon Dec 11 11:26:09 CST 2017]; root of context hierarchy
2017-12-11 11:26:14,137 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:26:14,170 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:26:14,177 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:26:14,344 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:26:14,408 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:26:14,413 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:26:14,413 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:26:14,415 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:26:14,432 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:26:14,651 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:14,706 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:14,819 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:26:14,881 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:26:14,901 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:26:14,904 INFO [restartedMain]                       com.Application : Started Application in 5.99 seconds (JVM running for 304.051)
2017-12-11 11:27:08,170 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:27:08,173 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 11:27:08,174 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:08,175 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:27:08,178 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:27:08,179 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:27:08,179 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:27:08,179 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:27:08,179 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:27:08,179 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:27:08,207 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:08,209 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:09,182 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:09,217 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:09,220 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:12,137 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:12,171 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:12,173 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:14,103 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:14,134 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:14,135 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:14,213 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:14,215 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:15,031 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:15,053 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:15,054 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:15,726 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:15,746 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:15,747 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:16,270 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:16,294 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:16,296 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:17,309 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:17,331 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:17,333 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:17,403 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:17,403 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:18,264 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:18,286 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:18,288 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:20,031 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:20,053 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:20,053 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:42,291 INFO [Thread-117] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33f350b4: startup date [Mon Dec 11 11:26:09 CST 2017]; root of context hierarchy
2017-12-11 11:27:42,299 INFO [Thread-117] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:27:42,300 INFO [Thread-117] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:27:42,304 INFO [Thread-117] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@633f813{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:27:42,306 INFO [Thread-117]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:27:42,308 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:27:42,336 INFO [Thread-117] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:27:42,336 INFO [Thread-117] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:27:42,337 INFO [Thread-117] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:27:42,338 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:27:42,343 INFO [Thread-117]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:27:43,530 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:27:43,530 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:27:43,534 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@bb872e9: startup date [Mon Dec 11 11:27:43 CST 2017]; root of context hierarchy
2017-12-11 11:27:44,985 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:27:46,061 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:27:46,099 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2565 ms
2017-12-11 11:27:46,201 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:27:46,202 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:27:46,202 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:27:46,337 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:27:46,348 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:27:46,349 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:27:46,349 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:27:46,349 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:27:46,349 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:27:46,349 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:27:46,367 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57294.
2017-12-11 11:27:46,371 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:27:46,377 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:27:46,378 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:27:46,378 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:27:46,384 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-18fdd358-0022-4b77-a2d4-1f715f444f54
2017-12-11 11:27:46,385 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:27:46,387 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:27:46,406 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:27:46,407 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @395555ms
2017-12-11 11:27:46,410 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@30a5bc73{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:27:46,410 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:27:46,411 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61d0cfb8{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,412 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@659d30f0{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,412 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f0ce3ab{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,413 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7406453e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,413 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4613be8b{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,413 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f962801{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,414 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4aa4674a{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,414 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40aa46c1{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b370931{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7299f2fd{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26635db3{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@427d8a3d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,417 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e74161a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,417 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bba1716{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,418 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65af910a{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,418 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59061206{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,419 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@472fe21b{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,419 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@118fbe3f{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,420 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fb7d754{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,420 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b050581{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,428 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b6cc157{/static,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,429 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1647e0e4{/,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,430 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3452952b{/api,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,430 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73258a75{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16276fbd{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,431 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:27:46,480 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:27:46,507 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57311.
2017-12-11 11:27:46,507 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57311
2017-12-11 11:27:46,507 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:27:46,507 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57311, None)
2017-12-11 11:27:46,508 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57311 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57311, None)
2017-12-11 11:27:46,508 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57311, None)
2017-12-11 11:27:46,508 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57311, None)
2017-12-11 11:27:46,510 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2281ed7d{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,518 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:27:46,518 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:27:46,519 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@804676e{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,519 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23b9d4c7{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,523 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5eb091a7{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,524 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@499a3d75{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,526 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4be936db{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:27:46,530 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:27:46,725 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:27:46,726 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:27:46,726 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:27:46,727 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:27:46,727 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:27:46,727 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:27:46,728 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:27:46,728 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:27:46,728 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:27:46,728 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:27:46,729 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:27:46,731 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:27:46,731 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:27:46,731 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:27:46,734 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:27:46,734 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:27:46,773 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:27:46,817 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@bb872e9: startup date [Mon Dec 11 11:27:43 CST 2017]; root of context hierarchy
2017-12-11 11:27:46,822 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:27:46,841 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:27:46,845 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:27:46,966 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:27:47,011 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:27:47,015 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:27:47,016 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:27:47,047 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:27:47,062 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:27:47,294 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:27:47,340 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:27:47,452 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:27:47,518 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:27:47,565 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:27:47,568 INFO [restartedMain]                       com.Application : Started Application in 4.174 seconds (JVM running for 396.716)
2017-12-11 11:27:48,569 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:27:48,583 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 11 ms
2017-12-11 11:27:48,584 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:48,586 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:27:48,595 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:27:48,596 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:27:48,596 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:27:48,596 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:27:48,597 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:27:48,598 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:27:48,736 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:48,742 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:49,593 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:49,682 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:49,683 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:49,905 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:49,910 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:50,837 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:50,872 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:50,874 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:54,711 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,693 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,744 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,745 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,753 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,755 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,776 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,776 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,776 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,776 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,777 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,778 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,779 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,780 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,780 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,781 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,780 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,785 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,788 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,781 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,789 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,790 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,797 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,823 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,818 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,812 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,831 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,832 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,829 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,843 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,853 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,855 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,879 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,879 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,889 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,891 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,899 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,899 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,912 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,912 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,933 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,934 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,946 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,947 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:27:59,958 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:27:59,959 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:21,708 INFO [Thread-134] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@bb872e9: startup date [Mon Dec 11 11:27:43 CST 2017]; root of context hierarchy
2017-12-11 11:28:21,709 INFO [Thread-134] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:28:21,710 INFO [Thread-134] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:28:21,713 INFO [Thread-134] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@30a5bc73{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:28:21,714 INFO [Thread-134]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:28:21,715 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:28:21,721 INFO [Thread-134] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:28:21,721 INFO [Thread-134] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:28:21,722 INFO [Thread-134] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:28:21,722 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:28:21,727 INFO [Thread-134]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:28:22,658 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:28:22,658 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:28:22,662 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@13d25497: startup date [Mon Dec 11 11:28:22 CST 2017]; root of context hierarchy
2017-12-11 11:28:24,121 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:28:25,379 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:28:25,474 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2813 ms
2017-12-11 11:28:25,576 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:28:25,577 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:28:25,577 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:28:25,714 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:28:25,715 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:28:25,719 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:28:25,719 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:28:25,720 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:28:25,720 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:28:25,720 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:28:25,767 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57380.
2017-12-11 11:28:25,771 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:28:25,799 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:28:25,799 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:28:25,799 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:28:25,805 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-821e67ba-79f1-4f9e-b4ac-81de2d353a71
2017-12-11 11:28:25,806 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:28:25,807 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:28:25,822 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:28:25,824 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @434971ms
2017-12-11 11:28:25,827 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@704a9835{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:28:25,827 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:28:25,828 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a35310a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,828 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@260c8eec{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,829 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51cdfd07{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,829 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21eb4734{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,830 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c1efd9{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,830 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a3ddad2{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,831 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bfbcf2a{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,831 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59bf9031{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,833 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76832cab{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,834 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f24d3c4{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,834 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62b05bd9{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,835 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1eacf255{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,835 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d9dab09{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,836 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ea3f0b9{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,836 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@790d6700{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,840 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b3fefe1{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,842 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@424d92b9{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,843 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b6d0d36{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,843 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23a1e193{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,844 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42b364c0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,845 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58c5559c{/static,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,845 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@611faeb{/,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,846 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24e1e85e{/api,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,847 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36c1388f{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,847 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@444dec68{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,847 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:28:25,912 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:28:25,944 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57397.
2017-12-11 11:28:25,944 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57397
2017-12-11 11:28:25,944 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:28:25,945 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57397, None)
2017-12-11 11:28:25,945 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57397 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57397, None)
2017-12-11 11:28:25,946 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57397, None)
2017-12-11 11:28:25,946 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57397, None)
2017-12-11 11:28:25,948 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e849524{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,956 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:28:25,956 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:28:25,963 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@760746a0{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,963 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@785b68da{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,964 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77fc76ab{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,964 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37b51060{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,966 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@727cbef3{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:28:25,972 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:28:26,301 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:28:26,301 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:28:26,301 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:28:26,302 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:28:26,303 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:28:26,303 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:28:26,306 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:28:26,306 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:28:26,306 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:28:26,307 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:28:26,308 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:28:26,311 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:28:26,311 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:28:26,311 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:28:26,317 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:28:26,317 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:28:26,361 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:28:26,398 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@13d25497: startup date [Mon Dec 11 11:28:22 CST 2017]; root of context hierarchy
2017-12-11 11:28:26,402 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:28:26,416 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:28:26,419 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:28:26,593 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:28:26,698 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:28:26,703 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:28:26,703 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:28:26,704 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:28:26,715 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:28:26,903 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:28:26,964 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:28:27,122 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:28:27,173 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:28:27,194 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:28:27,197 INFO [restartedMain]                       com.Application : Started Application in 4.617 seconds (JVM running for 436.345)
2017-12-11 11:28:31,114 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:28:31,117 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 11:28:31,118 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,119 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:28:31,122 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:28:31,123 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:28:31,123 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:28:31,123 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:28:31,123 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:28:31,123 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:28:31,179 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,192 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,190 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,199 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,192 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,211 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,198 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,212 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,213 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,197 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,217 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,217 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,217 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,218 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,218 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,192 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,220 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,222 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,214 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,214 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,223 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,222 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,224 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,226 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,227 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,227 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,254 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,255 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,265 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,265 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,273 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,274 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,283 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,284 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,295 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,296 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,303 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,303 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,317 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,317 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,334 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,334 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:28:31,351 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:28:31,352 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:03,694 INFO [Thread-154] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@13d25497: startup date [Mon Dec 11 11:28:22 CST 2017]; root of context hierarchy
2017-12-11 11:29:03,696 INFO [Thread-154] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:29:03,697 INFO [Thread-154] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:29:03,698 INFO [Thread-154] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@704a9835{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:29:03,699 INFO [Thread-154]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:29:03,700 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:29:03,705 INFO [Thread-154] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:29:03,706 INFO [Thread-154] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:29:03,706 INFO [Thread-154] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:29:03,706 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:29:03,712 INFO [Thread-154]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:29:04,495 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:29:04,495 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:29:04,498 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@d110992: startup date [Mon Dec 11 11:29:04 CST 2017]; root of context hierarchy
2017-12-11 11:29:06,176 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:29:07,485 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:29:07,535 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3037 ms
2017-12-11 11:29:07,697 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:29:07,698 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:29:07,698 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:29:07,911 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:29:07,913 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:29:07,916 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:29:07,916 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:29:07,918 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:29:07,918 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:29:07,918 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:29:08,082 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57439.
2017-12-11 11:29:08,090 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:29:08,091 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:29:08,109 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:29:08,109 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:29:08,114 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-9d6a88e5-e3f9-4e41-8a07-3b398b31bf49
2017-12-11 11:29:08,117 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:29:08,119 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:29:08,163 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:29:08,164 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @477312ms
2017-12-11 11:29:08,168 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@46458bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:29:08,168 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:29:08,178 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69ab02{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,231 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@793bb599{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,232 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5eb622b5{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,234 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a162eeb{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,234 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@130514e8{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,235 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28c401b4{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,235 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2633e829{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,236 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d9d44ff{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,237 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@958c16a{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,238 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a2f31c9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,239 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d27c7dc{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,242 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@125a5927{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,243 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b5ac9f4{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,243 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ec96791{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,244 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c9ed4e6{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,247 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31e4bf6{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,247 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d1d9437{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,248 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@382dbd16{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,248 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c658a96{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,249 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78b874d2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,251 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55258c92{/static,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,253 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68bc110{/,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,254 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e1ab7fa{/api,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,255 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17f9eed{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,256 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7527bae{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,256 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:29:08,422 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:29:08,529 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57456.
2017-12-11 11:29:08,529 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57456
2017-12-11 11:29:08,529 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:29:08,530 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57456, None)
2017-12-11 11:29:08,530 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57456 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57456, None)
2017-12-11 11:29:08,531 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57456, None)
2017-12-11 11:29:08,531 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57456, None)
2017-12-11 11:29:08,532 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38fc697e{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,538 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:29:08,538 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:29:08,539 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11a4161f{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,539 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4db0d72c{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,540 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2eab4192{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,541 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e9d8d5c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,542 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@489c97ba{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:29:08,546 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:29:08,841 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:29:08,842 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:29:08,842 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:29:08,845 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:29:08,846 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:29:08,846 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:29:08,849 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:29:08,850 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:29:08,850 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:29:08,850 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:29:08,851 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:29:08,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:29:08,855 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:29:08,855 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:29:08,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:29:08,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:29:08,908 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/resources/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:29:08,951 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@d110992: startup date [Mon Dec 11 11:29:04 CST 2017]; root of context hierarchy
2017-12-11 11:29:08,962 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:29:08,988 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:29:08,993 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:29:09,339 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:29:09,443 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:29:09,448 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:29:09,449 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:29:09,450 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:29:09,459 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:29:09,753 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:29:09,981 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:29:10,100 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:29:10,196 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:29:10,223 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:29:10,226 INFO [restartedMain]                       com.Application : Started Application in 5.839 seconds (JVM running for 479.374)
2017-12-11 11:29:18,165 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:29:18,171 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 5 ms
2017-12-11 11:29:18,172 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:18,211 WARN [http-nio-8080-exec-1]         org.apache.spark.SparkContext : Requesting executors is only supported in coarse-grained mode
2017-12-11 11:29:27,711 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,715 INFO [http-nio-8080-exec-2]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:29:27,718 INFO [http-nio-8080-exec-2]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:29:27,769 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,775 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,784 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,786 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,788 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,787 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,808 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,810 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,813 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,814 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,807 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,825 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,832 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,837 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,806 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,803 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,846 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,801 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,798 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,848 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,842 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,824 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,865 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,813 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,879 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,880 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,885 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,912 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,918 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,919 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,932 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,933 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,943 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,944 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,954 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,956 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,976 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,977 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:27,993 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:27,994 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:28,006 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:28,007 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:29:28,022 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:29:28,022 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:30:14,222 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:30:14,223 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swaggerui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:30:22,988 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:30:22,988 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:30:45,784 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:30:45,785 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:30:58,194 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:30:58,195 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:31:09,133 INFO [Thread-175] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@d110992: startup date [Mon Dec 11 11:29:04 CST 2017]; root of context hierarchy
2017-12-11 11:31:09,135 INFO [Thread-175] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:31:09,135 INFO [Thread-175] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:31:09,141 INFO [Thread-175] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@46458bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:31:09,142 INFO [Thread-175]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:31:09,149 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:31:09,163 INFO [Thread-175] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:31:09,164 INFO [Thread-175] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:31:09,164 INFO [Thread-175] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:31:09,164 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:31:09,170 INFO [Thread-175]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:31:10,465 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:31:10,465 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:31:10,469 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a01b218: startup date [Mon Dec 11 11:31:10 CST 2017]; root of context hierarchy
2017-12-11 11:31:13,996 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:31:15,369 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:31:15,419 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4951 ms
2017-12-11 11:31:15,518 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:31:15,518 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:31:15,519 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:31:15,606 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:31:15,607 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:31:15,609 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:31:15,609 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:31:15,609 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:31:15,609 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:31:15,609 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:31:15,627 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57649.
2017-12-11 11:31:15,631 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:31:15,636 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:31:15,636 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:31:15,638 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:31:15,650 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-82b5c5f2-0089-4b56-b08d-7b1a4adc5556
2017-12-11 11:31:15,651 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:31:15,653 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:31:15,666 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:31:15,667 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @604815ms
2017-12-11 11:31:15,670 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@740f1de{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:31:15,670 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:31:15,671 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@867466c{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,671 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1993bf9b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,671 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b3b1207{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,672 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69e3f63c{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,672 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@680f7cf2{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,673 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@34125595{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,675 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ef3178{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@577cc469{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cfc7f20{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78ea6a26{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,678 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76b08176{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,679 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@314f46dc{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,679 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1dc227a9{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,688 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31ef6037{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,688 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f2525e1{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,693 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@524b5c61{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,694 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@422dcce4{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,694 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29cdee5b{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,695 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6efcde36{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,695 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61130f34{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,697 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@789eff38{/static,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,697 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72816954{/,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,698 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@514da6ae{/api,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,698 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b25beb0{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,699 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12a59975{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,699 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:31:15,751 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:31:15,770 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57667.
2017-12-11 11:31:15,770 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57667
2017-12-11 11:31:15,770 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:31:15,771 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57667, None)
2017-12-11 11:31:15,771 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57667 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57667, None)
2017-12-11 11:31:15,771 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57667, None)
2017-12-11 11:31:15,772 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57667, None)
2017-12-11 11:31:15,773 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fde1109{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,777 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:31:15,777 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:31:15,777 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4200d44e{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,778 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4678e572{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,780 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d3c3f43{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,781 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e7a42e5{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,782 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@152a59a3{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:31:15,791 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:31:16,024 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:31:16,025 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:31:16,025 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:31:16,027 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:31:16,028 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:31:16,028 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:31:16,038 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:31:16,039 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:31:16,041 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:31:16,043 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:31:16,045 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:31:16,126 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a01b218: startup date [Mon Dec 11 11:31:10 CST 2017]; root of context hierarchy
2017-12-11 11:31:16,131 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:31:16,148 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:31:16,154 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:31:16,394 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:31:16,473 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:31:16,482 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:31:16,482 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:31:16,483 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:31:16,506 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:31:16,718 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:16,771 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:16,882 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:16,922 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:31:16,988 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:31:16,992 INFO [restartedMain]                       com.Application : Started Application in 6.662 seconds (JVM running for 606.139)
2017-12-11 11:31:20,792 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:31:20,794 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 2 ms
2017-12-11 11:31:20,794 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:31:20,795 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:31:23,508 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:31:23,509 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:31:43,725 INFO [Thread-195] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4a01b218: startup date [Mon Dec 11 11:31:10 CST 2017]; root of context hierarchy
2017-12-11 11:31:43,726 INFO [Thread-195] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:31:43,727 INFO [Thread-195] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:31:43,729 INFO [Thread-195] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@740f1de{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:31:43,737 INFO [Thread-195]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:31:43,738 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:31:43,748 INFO [Thread-195] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:31:43,748 INFO [Thread-195] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:31:43,749 INFO [Thread-195] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:31:43,750 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:31:43,755 INFO [Thread-195]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:31:45,168 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:31:45,168 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:31:45,172 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d1b389b: startup date [Mon Dec 11 11:31:45 CST 2017]; root of context hierarchy
2017-12-11 11:31:47,101 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:31:48,047 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:31:48,084 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2912 ms
2017-12-11 11:31:48,155 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:31:48,155 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:31:48,155 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:31:48,214 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:31:48,215 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:31:48,220 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:31:48,220 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:31:48,220 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:31:48,221 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:31:48,221 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:31:48,246 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57702.
2017-12-11 11:31:48,249 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:31:48,251 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:31:48,302 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:31:48,302 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:31:48,322 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-f0decb47-d00f-420f-9c24-d4ad8cfb3a0d
2017-12-11 11:31:48,323 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:31:48,326 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:31:48,349 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:31:48,351 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @637499ms
2017-12-11 11:31:48,356 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@e648bdc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:31:48,356 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:31:48,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@443ec4a0{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,358 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e340eb9{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@168d8528{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bf397b7{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37793a56{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@659a705e{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c8f42cf{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70b4c7f2{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,363 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27aa8dcc{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,364 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65c6493f{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,364 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e8c46dc{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,364 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36bf3a8d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,365 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c763b5e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,365 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6aad5ff1{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,365 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@365416c2{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,367 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58f599bf{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,369 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e95d5ae{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,370 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a22e40d{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,371 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bc91bcc{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,372 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d23286f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@593c4777{/static,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3886bef4{/,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,376 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@687d81e9{/api,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,379 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21460051{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,380 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f5b89e2{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,380 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:31:48,448 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:31:48,480 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57719.
2017-12-11 11:31:48,480 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57719
2017-12-11 11:31:48,480 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:31:48,480 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57719, None)
2017-12-11 11:31:48,481 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57719 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57719, None)
2017-12-11 11:31:48,481 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57719, None)
2017-12-11 11:31:48,481 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57719, None)
2017-12-11 11:31:48,483 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e7f2bbc{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,488 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:31:48,488 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:31:48,491 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d811c54{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,492 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61da0432{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,493 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@44fd5028{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,493 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@655c1b8c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,495 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4052dc59{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:31:48,504 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:31:48,743 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:31:48,743 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:31:48,743 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:31:48,744 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:31:48,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:31:48,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:31:48,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:31:48,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:31:48,745 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:31:48,746 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:31:48,746 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:31:48,749 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:31:48,750 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:31:48,750 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:31:48,752 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:31:48,753 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:31:48,841 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d1b389b: startup date [Mon Dec 11 11:31:45 CST 2017]; root of context hierarchy
2017-12-11 11:31:48,844 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:31:48,858 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:31:48,860 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:31:49,084 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:31:49,179 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:31:49,183 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:31:49,183 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:31:49,184 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:31:49,193 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:31:49,380 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:49,433 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:49,537 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:31:49,580 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:31:49,598 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:31:49,601 INFO [restartedMain]                       com.Application : Started Application in 4.576 seconds (JVM running for 638.749)
2017-12-11 11:31:49,716 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:31:49,721 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 4 ms
2017-12-11 11:31:49,721 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:31:49,722 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:17,062 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:17,080 WARN [http-nio-8080-exec-5]         org.apache.spark.SparkContext : Requesting executors is only supported in coarse-grained mode
2017-12-11 11:32:23,458 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,460 INFO [http-nio-8080-exec-6]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:32:23,463 INFO [http-nio-8080-exec-6] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:32:23,463 INFO [http-nio-8080-exec-6] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:32:23,463 INFO [http-nio-8080-exec-6] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:32:23,463 INFO [http-nio-8080-exec-6] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:32:23,464 INFO [http-nio-8080-exec-6]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:32:23,464 INFO [http-nio-8080-exec-6]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:32:23,502 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,506 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,505 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,507 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,505 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,505 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,509 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,512 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,513 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,505 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,519 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,520 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,518 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,515 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,515 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,515 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,527 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,515 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,529 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,514 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,530 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,525 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,521 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,540 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,521 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,546 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,553 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,554 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,561 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,562 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,568 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,568 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,573 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,574 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,582 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,582 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,588 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,589 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,594 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,595 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,601 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,601 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:23,605 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:23,606 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:27,267 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:27,268 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:27,268 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:27,268 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:27,267 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:32:27,269 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:32:35,096 INFO [Thread-216] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d1b389b: startup date [Mon Dec 11 11:31:45 CST 2017]; root of context hierarchy
2017-12-11 11:32:35,103 INFO [Thread-216] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:32:35,103 INFO [Thread-216] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:32:35,111 INFO [Thread-216] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@e648bdc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:32:35,116 INFO [Thread-216]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:32:35,123 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:32:35,135 INFO [Thread-216] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:32:35,135 INFO [Thread-216] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:32:35,136 INFO [Thread-216] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:32:35,136 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:32:35,142 INFO [Thread-216]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:32:36,360 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:32:36,361 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:32:36,370 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@ee25bf3: startup date [Mon Dec 11 11:32:36 CST 2017]; root of context hierarchy
2017-12-11 11:32:38,089 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:32:39,086 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:32:39,212 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2842 ms
2017-12-11 11:32:39,869 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:32:39,879 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:32:39,901 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-12-11 11:32:39,917 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-12-11 11:32:39,917 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'requestContextFilter' to: [/*]
2017-12-11 11:32:40,456 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@ee25bf3: startup date [Mon Dec 11 11:32:36 CST 2017]; root of context hierarchy
2017-12-11 11:32:40,461 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:32:40,468 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:32:40,468 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:32:40,478 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:32:40,478 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:32:40,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:32:40,552 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:32:41,511 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:32:41,781 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:32:42,133 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:32:42,135 INFO [restartedMain]                       com.Application : Started Application in 5.889 seconds (JVM running for 691.282)
2017-12-11 11:32:45,195 INFO [Thread-237] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@ee25bf3: startup date [Mon Dec 11 11:32:36 CST 2017]; root of context hierarchy
2017-12-11 11:32:45,196 INFO [Thread-237] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:32:47,705 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1308 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:32:47,706 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:32:47,716 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@66393252: startup date [Mon Dec 11 11:32:47 CST 2017]; root of context hierarchy
2017-12-11 11:32:50,223 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:32:52,051 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:32:52,108 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4392 ms
2017-12-11 11:32:52,193 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:32:52,195 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:32:52,242 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:32:52,242 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:32:52,336 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@66393252: startup date [Mon Dec 11 11:32:47 CST 2017]; root of context hierarchy
2017-12-11 11:32:52,340 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:32:52,383 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:32:52,400 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:32:52,401 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:32:52,404 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:32:52,404 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:32:52,405 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:32:52,405 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:32:52,405 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:32:52,460 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57799.
2017-12-11 11:32:52,464 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:32:52,473 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:32:52,473 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:32:52,473 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:32:52,482 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-eb9ccf81-fcf7-4c2e-b6e5-3f0eb8b329ad
2017-12-11 11:32:52,483 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:32:52,486 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:32:52,507 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:32:52,517 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @701665ms
2017-12-11 11:32:52,521 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3f759db8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:32:52,521 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:32:52,522 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fed730f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,524 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5008b551{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,525 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7320cc1{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,526 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@377fba43{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,526 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@783265e0{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,528 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51f53492{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,529 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c528776{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,530 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ea3012a{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,533 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76fef0a2{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,534 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@411fe1ad{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,534 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b09dd4{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,535 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52510d1b{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,535 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a66686{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,536 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d652167{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,536 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11efabc7{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,537 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54a8335e{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,537 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@568f1370{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,537 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71a9b76b{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,538 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@745902d9{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,538 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ebc5291{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,539 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2419f180{/static,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,539 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f728ee8{/,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,540 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f1132e3{/api,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,540 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cbe592a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,541 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41bb8b23{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,541 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:32:52,600 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:32:52,620 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57816.
2017-12-11 11:32:52,620 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57816
2017-12-11 11:32:52,620 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:32:52,620 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57816, None)
2017-12-11 11:32:52,621 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57816 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57816, None)
2017-12-11 11:32:52,621 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57816, None)
2017-12-11 11:32:52,621 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57816, None)
2017-12-11 11:32:52,622 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cdfa46a{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,626 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:32:52,626 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:32:52,627 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@325f7738{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,627 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1364d51f{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,629 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b4a066d{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,629 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@694f37ea{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,630 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6daf4c9e{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:32:52,634 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:32:52,635 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:32:52,842 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:32:52,909 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:32:52,920 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:32:52,922 INFO [restartedMain]                       com.Application : Started Application in 5.492 seconds (JVM running for 702.071)
2017-12-11 11:33:40,818 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 8852 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:33:40,823 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:33:41,859 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@604d571d: startup date [Mon Dec 11 11:33:41 CST 2017]; root of context hierarchy
2017-12-11 11:33:42,000 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 11:33:45,630 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:33:48,379 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:33:48,908 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7053 ms
2017-12-11 11:33:49,260 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:33:49,270 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:33:49,271 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:33:50,329 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:33:50,707 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 11:33:50,822 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$973a9a.CGLIB$getSparkContext$3(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$973a9a$$FastClassBySpringCGLIB$$c1eed09c.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$973a9a.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 11:33:50,957 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:33:51,007 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:33:51,008 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:33:51,009 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:33:51,010 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:33:51,011 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:33:51,642 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 57858.
2017-12-11 11:33:51,679 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:33:51,714 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:33:51,722 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:33:51,722 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:33:51,740 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-1cc7166e-6b12-4692-9560-b36c203b9fdf
2017-12-11 11:33:51,800 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:33:51,945 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:33:52,106 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @16832ms
2017-12-11 11:33:52,256 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:33:52,283 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @17012ms
2017-12-11 11:33:52,338 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@40932cec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:33:52,338 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:33:52,411 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@130b74a0{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b7717fa{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3db11c38{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,418 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@bc73cbe{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,419 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cf88e58{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,420 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47300ced{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,421 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24f24718{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,423 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f81d514{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,426 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@99db591{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,427 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5da08c49{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,429 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53885566{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@501c5640{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,434 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cd7f81a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1df0b72f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,437 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1efc8338{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,439 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bda5cd8{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,440 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4928432e{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,441 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d89739b{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a9135da{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ec67261{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35e6c018{/static,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,473 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@734fbf13{/,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,482 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a312c4a{/api,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,489 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48cf0971{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,490 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5afd907b{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:33:52,495 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:33:52,778 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:33:52,895 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57875.
2017-12-11 11:33:52,897 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:57875
2017-12-11 11:33:52,900 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:33:52,904 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 57875, None)
2017-12-11 11:33:52,926 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:57875 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 57875, None)
2017-12-11 11:33:52,937 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 57875, None)
2017-12-11 11:33:52,939 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 57875, None)
2017-12-11 11:33:53,024 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ec073bc{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:53,547 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:33:53,549 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:33:53,563 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2396994a{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:33:53,564 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7853bdb1{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:53,566 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62118e83{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:33:53,567 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cff786b{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:33:53,598 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@416c6282{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:33:55,402 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 11:33:55,890 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:33:58,795 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:33:58,800 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:33:58,800 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:33:58,808 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:33:58,811 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:33:58,811 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:33:58,811 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:33:58,814 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:33:58,814 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:33:58,815 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:33:58,822 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:33:58,861 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:33:58,865 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:33:58,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:33:58,903 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:33:58,905 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:33:59,543 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:33:59,543 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:34:00,194 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@604d571d: startup date [Mon Dec 11 11:33:41 CST 2017]; root of context hierarchy
2017-12-11 11:34:00,791 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:34:01,397 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:34:01,479 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:34:05,796 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:34:06,167 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:34:06,227 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:34:06,228 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:34:06,387 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:34:06,465 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:34:08,538 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:34:08,857 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:34:09,380 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:34:09,670 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:34:10,546 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:34:10,598 INFO [restartedMain]                       com.Application : Started Application in 31.37 seconds (JVM running for 35.327)
2017-12-11 11:34:13,577 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:34:13,577 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:34:13,871 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 294 ms
2017-12-11 11:34:13,900 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:14,348 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:34:14,748 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:34:14,749 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:34:14,750 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:34:14,750 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:34:14,767 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * VALIDXML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:34:14,768 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:34:15,427 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,446 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,449 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,445 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,443 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,477 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,442 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,496 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,441 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,491 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,486 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,481 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,472 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,513 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,471 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,520 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,470 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,546 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,464 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,458 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,450 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,448 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,446 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,576 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,573 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,573 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,861 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,864 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,883 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,885 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,911 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,912 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,938 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,939 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:15,965 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:15,967 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:16,012 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:16,013 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:16,043 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:16,045 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:34:16,107 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:34:16,111 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:08,433 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:41:08,436 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:41:09,498 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@56880ba0: startup date [Mon Dec 11 11:41:09 CST 2017]; root of context hierarchy
2017-12-11 11:41:09,747 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 11:41:16,548 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:41:18,258 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:41:18,874 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 9393 ms
2017-12-11 11:41:19,281 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:41:19,291 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:41:19,291 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:41:20,153 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:41:20,585 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 11:41:20,721 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$fc2d48a9.CGLIB$getSparkContext$5(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$fc2d48a9$$FastClassBySpringCGLIB$$5a16c613.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$fc2d48a9.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 11:41:21,153 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:41:21,216 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:41:21,217 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:41:21,218 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:41:21,220 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:41:21,222 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:41:22,507 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58383.
2017-12-11 11:41:22,539 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:41:22,566 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:41:22,570 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:41:22,570 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:41:22,587 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-a15a0790-38b4-4250-9926-34ff9d48a20b
2017-12-11 11:41:22,612 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:41:22,703 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:41:22,880 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @19896ms
2017-12-11 11:41:22,980 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:41:23,002 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @20019ms
2017-12-11 11:41:23,032 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@294d704a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:41:23,032 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:41:23,078 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28a11b30{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16b5e3ae{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,080 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35d4b65a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,082 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76273999{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,089 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@15407026{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,095 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1986008d{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,098 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60d45945{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,100 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@259a1847{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,102 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53b6a13f{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,103 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7255ea79{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,104 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@307f3bb9{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,106 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e0872fc{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,109 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79d3e2d{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,116 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3930b01{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,118 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@102fc35a{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,119 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6da5a833{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,121 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12f54069{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,132 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f8e1bb8{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,134 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38ac46c0{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,138 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e0163fb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,171 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1173ca36{/static,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,172 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62fda814{/,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,177 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63bc62b3{/api,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,181 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38b18e57{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,183 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@726a4632{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,194 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:41:23,443 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:41:23,482 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58401.
2017-12-11 11:41:23,482 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58401
2017-12-11 11:41:23,484 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:41:23,487 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58401, None)
2017-12-11 11:41:23,491 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58401 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58401, None)
2017-12-11 11:41:23,498 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58401, None)
2017-12-11 11:41:23,501 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58401, None)
2017-12-11 11:41:23,526 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78b8f3a5{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,681 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:41:23,682 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:41:23,702 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@80ed63a{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,704 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19fc59c{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,708 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3332a8bc{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,710 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f70d508{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:41:23,730 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14a6820b{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:41:24,680 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 11:41:24,970 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:41:26,168 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:41:26,169 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:41:26,170 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:41:26,172 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:41:26,173 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:41:26,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:41:26,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:41:26,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:41:26,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:41:26,174 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:41:26,175 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:41:26,185 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:41:26,186 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:41:26,187 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:41:26,210 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:41:26,211 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:41:26,517 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:41:26,629 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@56880ba0: startup date [Mon Dec 11 11:41:09 CST 2017]; root of context hierarchy
2017-12-11 11:41:26,649 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:41:26,797 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:41:26,838 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:41:30,909 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:41:31,039 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:41:31,056 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:41:31,056 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:41:31,109 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:41:31,150 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:41:32,174 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:41:32,443 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:41:33,101 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:41:33,216 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:41:33,414 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:41:33,424 INFO [restartedMain]                       com.Application : Started Application in 26.466 seconds (JVM running for 30.442)
2017-12-11 11:41:38,285 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:41:38,285 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:41:38,361 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 75 ms
2017-12-11 11:41:38,380 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,461 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:41:38,595 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:41:38,595 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:41:38,595 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:41:38,595 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:41:38,610 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:41:38,610 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:41:38,865 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,896 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,890 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,889 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,914 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,886 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,881 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,880 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,960 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,860 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,963 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,874 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,966 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,864 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,874 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,992 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,871 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,994 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,862 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:38,973 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,952 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,926 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:38,914 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,300 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,303 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,321 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,324 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,426 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,427 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,458 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,462 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,479 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,481 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,513 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,515 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,527 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,528 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,543 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,544 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,555 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,556 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:39,788 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:39,808 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:41:43,671 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:43,677 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:41:43,680 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:46,919 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:46,993 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:46,996 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,004 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,013 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,017 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,046 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,046 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,056 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,059 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,063 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,113 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,117 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,123 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,126 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:42:47,977 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:47,978 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:42:56,036 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,088 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,088 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,091 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,099 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,103 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,107 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,108 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,110 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,118 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,119 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,124 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,144 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,151 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,593 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:42:56,795 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,013 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,041 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,042 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,068 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,069 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,072 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,075 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,082 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,082 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,086 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,087 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,095 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,095 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,096 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,479 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:09,595 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,555 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,591 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,633 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,649 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,653 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,670 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,700 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,701 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,726 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,727 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,733 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,736 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,740 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:34,795 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:35,247 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:35,361 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:35,519 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:35,522 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:43:42,194 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,231 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,236 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,244 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,248 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,251 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,254 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,257 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,258 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,261 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,263 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,265 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,267 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,267 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,597 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:42,655 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,003 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,027 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,028 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,048 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,050 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,050 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,052 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,057 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,061 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,071 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,071 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,076 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,078 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,079 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,503 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:43:45,626 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,676 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,712 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,714 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,716 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,717 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,719 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,719 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,719 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,722 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,714 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,719 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,728 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,729 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:03,716 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:04,035 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:04,098 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:45,530 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:44:45,531 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/swagger-ui.html] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:46:20,798 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@56880ba0: startup date [Mon Dec 11 11:41:09 CST 2017]; root of context hierarchy
2017-12-11 11:46:20,804 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:46:20,807 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:46:20,827 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@294d704a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:46:20,927 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:46:21,046 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:46:21,114 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:46:21,116 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:46:21,118 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:46:21,126 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:46:21,134 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:46:21,966 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 11:46:22,215 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:46:22,316 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 11:46:23,635 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:46:23,635 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:46:23,669 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a022b54: startup date [Mon Dec 11 11:46:23 CST 2017]; root of context hierarchy
2017-12-11 11:46:26,761 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:46:28,529 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:46:28,681 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5012 ms
2017-12-11 11:46:29,072 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:46:29,073 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:46:29,073 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:46:29,263 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:46:29,265 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:46:29,266 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:46:29,267 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:46:29,267 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:46:29,268 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:46:29,268 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:46:29,566 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58659.
2017-12-11 11:46:29,570 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:46:29,676 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:46:29,677 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:46:29,677 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:46:29,693 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-2338ccf2-cc71-4771-bd90-e70f8cfc9b0b
2017-12-11 11:46:29,694 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:46:29,698 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:46:29,729 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:46:29,741 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @326749ms
2017-12-11 11:46:29,773 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@52176738{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:46:29,773 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:46:29,778 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f032fb0{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,779 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d1d9743{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,780 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e2d2fb{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,780 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@388f0757{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,781 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@387b98b8{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4852e8ed{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,785 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57ffaf8b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,786 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fbde86d{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,787 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c507511{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,788 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75a6e87{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6697b79b{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@453acb0e{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,790 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@723c7f58{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,792 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75166208{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,793 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c313cf2{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,793 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3176f0e6{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,794 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b79f274{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,795 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c28b656{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,796 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6289a10f{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,797 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d124363{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,798 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cfaa5f5{/static,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,799 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@795a9dff{/,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,803 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@243c0a72{/api,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16d91376{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,805 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ddadbff{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:46:29,805 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:46:29,999 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:46:30,142 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58676.
2017-12-11 11:46:30,142 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58676
2017-12-11 11:46:30,142 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:46:30,142 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58676, None)
2017-12-11 11:46:30,144 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58676 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58676, None)
2017-12-11 11:46:30,146 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58676, None)
2017-12-11 11:46:30,146 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58676, None)
2017-12-11 11:46:30,149 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a92668{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,155 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:46:30,155 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:46:30,158 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b7856a2{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,158 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16b9c51d{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,160 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5cb45309{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,161 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4250492f{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,162 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e7e5c82{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:46:30,208 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:46:30,545 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:46:30,546 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:46:30,546 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:46:30,548 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:46:30,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:46:30,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:46:30,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:46:30,550 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:46:30,551 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:46:30,551 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:46:30,552 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:46:30,555 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:46:30,556 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:46:30,557 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:46:30,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:46:30,566 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:46:30,748 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a022b54: startup date [Mon Dec 11 11:46:23 CST 2017]; root of context hierarchy
2017-12-11 11:46:30,774 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:46:30,897 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:46:30,901 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:46:31,384 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:46:31,731 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:46:31,748 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:46:31,748 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:46:31,749 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:46:31,759 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:46:32,758 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:33,030 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:33,517 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:33,689 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:46:33,721 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:46:33,753 INFO [restartedMain]                       com.Application : Started Application in 10.403 seconds (JVM running for 330.771)
2017-12-11 11:46:42,073 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a022b54: startup date [Mon Dec 11 11:46:23 CST 2017]; root of context hierarchy
2017-12-11 11:46:42,075 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:46:42,076 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:46:42,078 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@52176738{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:46:42,080 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:46:42,082 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:46:42,088 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:46:42,088 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:46:42,088 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:46:42,088 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:46:42,094 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:46:43,069 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:46:43,070 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:46:43,082 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@57f8854: startup date [Mon Dec 11 11:46:43 CST 2017]; root of context hierarchy
2017-12-11 11:46:46,221 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:46:47,772 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:46:48,024 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4942 ms
2017-12-11 11:46:48,185 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:46:48,186 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:46:48,186 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:46:48,339 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:46:48,341 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:46:48,346 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:46:48,347 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:46:48,347 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:46:48,349 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:46:48,349 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:46:48,435 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58707.
2017-12-11 11:46:48,443 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:46:48,471 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:46:48,471 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:46:48,472 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:46:48,482 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-0d0c2f06-8543-4677-965f-617f648684e4
2017-12-11 11:46:48,487 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:46:48,490 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:46:48,524 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:46:48,543 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @345561ms
2017-12-11 11:46:48,550 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@6b8229dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:46:48,551 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:46:48,594 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@389d61b0{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,609 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bb5dde1{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,613 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5240aefa{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,616 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41cf3259{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,617 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9cf002d{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,618 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20040dd9{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,619 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7523b151{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,620 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60762f85{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,620 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c73ac5d{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,623 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39d41596{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,625 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5df62130{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,628 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54a0642d{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,629 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27379b5e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,637 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30655a49{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,638 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46bf04e6{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,639 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2584faba{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,642 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a318f79{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,649 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dfe6ba6{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,651 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@760124ea{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,652 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f688abb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,654 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@95b679a{/static,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,655 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68b139dc{/,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,656 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d3fa249{/api,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,658 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39ca099a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,659 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2dd40ea8{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:46:48,659 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:46:48,875 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:46:49,000 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58725.
2017-12-11 11:46:49,000 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58725
2017-12-11 11:46:49,000 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:46:49,001 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58725, None)
2017-12-11 11:46:49,002 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58725 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58725, None)
2017-12-11 11:46:49,002 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58725, None)
2017-12-11 11:46:49,004 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58725, None)
2017-12-11 11:46:49,007 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d1c3702{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,013 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:46:49,038 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:46:49,051 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5047bd85{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,052 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16736c48{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c237833{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,054 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d6a16c9{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,057 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@559bf239{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:46:49,063 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:46:49,587 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:46:49,587 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:46:49,587 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:46:49,588 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:46:49,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:46:49,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:46:49,589 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:46:49,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:46:49,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:46:49,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:46:49,592 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:46:49,595 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:46:49,597 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:46:49,600 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:46:49,604 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:46:49,604 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:46:49,713 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:46:49,713 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/swagger-ui.html] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:46:49,713 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:46:49,814 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@57f8854: startup date [Mon Dec 11 11:46:43 CST 2017]; root of context hierarchy
2017-12-11 11:46:49,820 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:46:49,854 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:46:49,859 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:46:50,066 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:46:51,775 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:46:51,779 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:46:51,779 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:46:51,780 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:46:51,789 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:46:52,876 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:53,115 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:53,411 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:46:53,556 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:46:53,585 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:46:53,589 INFO [restartedMain]                       com.Application : Started Application in 10.626 seconds (JVM running for 350.607)
2017-12-11 11:46:55,010 INFO [Thread-39] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@57f8854: startup date [Mon Dec 11 11:46:43 CST 2017]; root of context hierarchy
2017-12-11 11:46:55,012 INFO [Thread-39] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:46:55,012 INFO [Thread-39] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:46:55,015 INFO [Thread-39] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@6b8229dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:46:55,021 INFO [Thread-39]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:46:55,024 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:46:55,043 INFO [Thread-39] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:46:55,043 INFO [Thread-39] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:46:55,043 INFO [Thread-39] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:46:55,044 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:46:55,050 INFO [Thread-39]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:46:56,278 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:46:56,279 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:46:56,285 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7352452a: startup date [Mon Dec 11 11:46:56 CST 2017]; root of context hierarchy
2017-12-11 11:46:59,024 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:47:00,238 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:47:00,288 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4003 ms
2017-12-11 11:47:00,406 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:47:00,408 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:47:00,408 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:47:00,467 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:47:00,468 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:47:00,469 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:47:00,469 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:47:00,470 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:47:00,470 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:47:00,470 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:47:00,500 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58782.
2017-12-11 11:47:00,504 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:47:00,506 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:47:00,507 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:47:00,507 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:47:00,515 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-422e41fc-d0ec-4422-86e5-606fc9656371
2017-12-11 11:47:00,517 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:47:00,520 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:47:00,555 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:47:00,557 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @357574ms
2017-12-11 11:47:00,563 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@5da31609{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:47:00,563 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:47:00,565 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@312dbe1f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,565 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39081134{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,566 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a48d56c{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,566 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59ae271f{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,567 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9733800{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,568 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3117ba58{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,568 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fd3cad{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,569 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d4ebd65{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,570 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@512fddf5{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,570 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@100f94f7{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,571 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cfd7f5d{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,572 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d8e7f3c{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,573 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f7c68dd{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,574 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@173775ff{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,575 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@344aaf56{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,576 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55e5c33{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,577 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c0b167c{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,579 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b14725{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,580 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@689fa4ed{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,581 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ccb660a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,583 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ad93f00{/static,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,584 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@772a2737{/,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,585 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9274c4a{/api,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,586 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b49d842{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,587 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@515d8cf7{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,587 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:47:00,651 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:47:00,672 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58799.
2017-12-11 11:47:00,672 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58799
2017-12-11 11:47:00,672 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:47:00,672 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58799, None)
2017-12-11 11:47:00,674 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58799 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58799, None)
2017-12-11 11:47:00,674 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58799, None)
2017-12-11 11:47:00,674 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58799, None)
2017-12-11 11:47:00,677 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d694ada{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,682 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:47:00,682 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:47:00,683 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@541e3973{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,684 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61aa1737{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,685 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e67fc66{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,686 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@48546ac0{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,687 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62e908a3{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:47:00,693 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:47:01,139 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:47:01,140 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:47:01,140 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:47:01,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:47:01,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:47:01,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:47:01,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:47:01,142 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:47:01,143 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:47:01,143 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:47:01,145 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:47:01,153 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:47:01,154 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:47:01,154 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:47:01,157 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:47:01,158 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:47:01,277 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7352452a: startup date [Mon Dec 11 11:46:56 CST 2017]; root of context hierarchy
2017-12-11 11:47:01,282 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:47:01,305 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:47:01,311 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:47:01,676 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:47:01,795 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:47:01,807 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:47:01,807 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:47:01,809 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:47:01,879 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:47:02,496 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:47:02,602 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:47:02,917 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:47:03,015 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:47:03,058 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:47:03,062 INFO [restartedMain]                       com.Application : Started Application in 6.962 seconds (JVM running for 360.079)
2017-12-11 11:47:03,254 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:47:03,258 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 11:47:03,259 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,262 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:47:03,268 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:47:03,268 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:47:03,269 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:47:03,269 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:47:03,269 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:47:03,269 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:47:03,371 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,376 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,376 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,378 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,380 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,383 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,385 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,401 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,402 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,398 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,408 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,413 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,414 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,391 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,427 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,389 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,385 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,430 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,431 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,385 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,449 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,406 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,455 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,456 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,401 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,454 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,489 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,490 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,499 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,500 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,509 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,510 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,521 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,522 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,539 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,540 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,555 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,556 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,578 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,578 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,591 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,592 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,604 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,605 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:03,812 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:03,813 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:06,524 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:06,525 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:06,526 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:06,526 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:06,532 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:06,532 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,477 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,505 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,506 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,509 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,510 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,512 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,512 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,513 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,516 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,518 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,520 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,525 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,525 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,528 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,529 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,530 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,530 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,514 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,533 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,539 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,539 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,539 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,540 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,541 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,543 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,546 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,551 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,564 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,565 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,574 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,575 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,582 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,583 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,593 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,594 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,602 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,603 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,611 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,611 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,620 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,621 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,633 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,634 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:12,646 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:47:12,647 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:47:57,322 INFO [Thread-60] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7352452a: startup date [Mon Dec 11 11:46:56 CST 2017]; root of context hierarchy
2017-12-11 11:47:57,324 INFO [Thread-60] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:47:57,324 INFO [Thread-60] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:47:57,327 INFO [Thread-60] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@5da31609{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:47:57,340 INFO [Thread-60]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:47:57,342 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:47:57,351 INFO [Thread-60] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:47:57,351 INFO [Thread-60] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:47:57,351 INFO [Thread-60] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:47:57,351 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:47:57,356 INFO [Thread-60]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:47:58,997 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:47:58,998 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:47:59,004 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6dbd82: startup date [Mon Dec 11 11:47:59 CST 2017]; root of context hierarchy
2017-12-11 11:48:02,640 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:48:03,576 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:48:03,635 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4631 ms
2017-12-11 11:48:03,786 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:48:03,786 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:48:03,787 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:48:03,842 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:48:03,843 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:48:03,844 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:48:03,844 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:48:03,848 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:48:03,848 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:48:03,849 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:48:03,862 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58880.
2017-12-11 11:48:03,868 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:48:03,870 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:48:03,870 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:48:03,871 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:48:03,876 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-02264c7c-3a5a-45ba-9577-be1a9ab044ac
2017-12-11 11:48:03,877 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:48:03,881 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:48:03,901 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:48:03,903 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @420921ms
2017-12-11 11:48:03,906 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@226dac9d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:48:03,907 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:48:03,908 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@514d519{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,909 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5af1c00c{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,910 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6de71e78{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,910 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56a76802{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,911 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8a050d1{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,912 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76f449f7{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,913 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2de61b5b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,914 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1435d84d{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,915 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79a35751{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,916 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57f290e5{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,917 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@455994e4{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@151603db{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20cbfe16{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,919 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55b4711a{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,919 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@668b1315{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,920 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d85047b{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,921 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71ae0124{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,922 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53f0ff1f{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,922 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@403da{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,923 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ebaa2e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,924 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b18396f{/static,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,924 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1fc27efa{/,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,925 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@694da4a1{/api,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,926 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3433fa6e{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,926 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@740e3b49{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:03,927 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:48:04,002 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:48:04,028 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58897.
2017-12-11 11:48:04,028 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58897
2017-12-11 11:48:04,029 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:48:04,029 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58897, None)
2017-12-11 11:48:04,030 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58897 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58897, None)
2017-12-11 11:48:04,030 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58897, None)
2017-12-11 11:48:04,031 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58897, None)
2017-12-11 11:48:04,034 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@784510cb{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,039 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:48:04,039 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:48:04,040 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@34f6e039{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e8f18ba{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72088e60{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,043 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fd7e2b4{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,048 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bb4a2ed{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:48:04,055 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:48:04,244 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:48:04,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:48:04,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:48:04,247 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:48:04,247 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:48:04,247 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:48:04,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:48:04,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:48:04,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:48:04,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:48:04,249 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:04,252 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:48:04,252 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:48:04,252 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:48:04,257 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:04,257 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:48:04,364 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6dbd82: startup date [Mon Dec 11 11:47:59 CST 2017]; root of context hierarchy
2017-12-11 11:48:04,367 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:04,378 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:04,381 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:48:04,652 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:48:04,741 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:48:04,747 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:48:04,747 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:48:04,749 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:48:04,756 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:48:05,025 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:05,190 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:05,363 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:05,441 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:48:05,476 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:48:05,480 INFO [restartedMain]                       com.Application : Started Application in 6.617 seconds (JVM running for 422.499)
2017-12-11 11:48:11,651 INFO [Thread-76] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2e6dbd82: startup date [Mon Dec 11 11:47:59 CST 2017]; root of context hierarchy
2017-12-11 11:48:11,652 INFO [Thread-76] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:48:11,652 INFO [Thread-76] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:48:11,655 INFO [Thread-76] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@226dac9d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:48:11,656 INFO [Thread-76]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:48:11,658 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:48:11,666 INFO [Thread-76] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:48:11,666 INFO [Thread-76] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:48:11,666 INFO [Thread-76] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:48:11,666 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:48:11,671 INFO [Thread-76]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:48:12,554 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:48:12,554 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:48:12,563 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f3ceef2: startup date [Mon Dec 11 11:48:12 CST 2017]; root of context hierarchy
2017-12-11 11:48:14,704 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:48:16,046 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:48:16,111 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3548 ms
2017-12-11 11:48:16,241 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:48:16,244 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:48:16,245 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:48:16,329 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:48:16,330 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:48:16,335 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:48:16,335 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:48:16,335 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:48:16,336 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:48:16,336 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:48:16,399 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58925.
2017-12-11 11:48:16,404 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:48:16,414 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:48:16,414 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:48:16,414 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:48:16,418 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-5fe2a782-ab82-4ffc-a48c-14b5652fbf19
2017-12-11 11:48:16,419 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:48:16,423 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:48:16,437 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:48:16,439 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @433457ms
2017-12-11 11:48:16,444 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@61911414{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:48:16,444 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:48:16,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63fd236a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,446 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7481f4a3{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,446 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17b5f921{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,446 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4509b202{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,503 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bbe7778{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,504 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e18a2bc{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,505 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@323d747b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,506 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@335624ec{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,507 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6422fc2{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,508 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f5af1c3{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,511 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f34f00d{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,512 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24aca7ae{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,512 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bff5749{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,513 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28fc361{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,513 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bcd3fd6{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,514 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@38ae56eb{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,514 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@bf1d13e{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@359ec9dc{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2adb27cf{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,516 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@789a4e01{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,516 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17efd3e2{/static,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,517 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bd46467{/,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,517 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d3419c9{/api,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,520 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6983043{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,521 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13018834{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,521 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:48:16,649 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:48:16,702 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58942.
2017-12-11 11:48:16,702 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:58942
2017-12-11 11:48:16,702 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:48:16,702 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 58942, None)
2017-12-11 11:48:16,709 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:58942 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 58942, None)
2017-12-11 11:48:16,710 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 58942, None)
2017-12-11 11:48:16,710 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 58942, None)
2017-12-11 11:48:16,712 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bcfed80{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,720 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:48:16,720 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:48:16,721 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19cc8173{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,722 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1eed3d40{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,723 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18ca7008{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,724 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74678d0d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,727 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1fdb959a{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:48:16,732 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:48:17,093 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:48:17,093 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:48:17,093 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:48:17,107 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:48:17,108 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:48:17,108 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:48:17,108 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:48:17,108 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:48:17,109 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:48:17,109 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:48:17,110 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:17,112 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:48:17,113 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:48:17,113 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:48:17,116 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:17,117 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:48:17,209 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f3ceef2: startup date [Mon Dec 11 11:48:12 CST 2017]; root of context hierarchy
2017-12-11 11:48:17,215 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:17,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:17,233 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:48:17,436 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:48:17,545 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:48:17,550 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:48:17,550 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:48:17,552 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:48:17,567 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:48:17,980 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:18,168 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:18,351 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:18,461 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:48:18,511 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:48:18,514 INFO [restartedMain]                       com.Application : Started Application in 6.357 seconds (JVM running for 435.531)
2017-12-11 11:48:20,575 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:48:20,579 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 4 ms
2017-12-11 11:48:20,580 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,585 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:48:20,594 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:48:20,595 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:48:20,595 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:48:20,595 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:48:20,595 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:48:20,595 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:48:20,742 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,746 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,746 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,748 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,748 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,752 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,752 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,753 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,753 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,751 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,756 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,751 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,762 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,751 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,751 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,773 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,767 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,760 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,778 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,754 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,754 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,753 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,753 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,753 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,753 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,815 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,878 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,879 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:20,950 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:20,951 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,017 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,024 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,033 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,034 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,047 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,048 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,061 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,061 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,074 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,075 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,084 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,084 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:21,101 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:21,102 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,091 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,322 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,323 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,332 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,332 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,341 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,341 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,353 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,355 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,362 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,365 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,371 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,372 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,379 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,379 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,388 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,389 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,392 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,395 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,405 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,407 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,420 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,420 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,440 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,440 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,447 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,641 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,532 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,672 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,793 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,793 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,806 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,807 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,818 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,818 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,829 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,830 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,847 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,847 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,857 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,858 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:23,883 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:23,883 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:25,779 INFO [Thread-93] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f3ceef2: startup date [Mon Dec 11 11:48:12 CST 2017]; root of context hierarchy
2017-12-11 11:48:25,781 INFO [Thread-93] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:48:25,784 INFO [Thread-93] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:48:25,787 INFO [Thread-93] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@61911414{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:48:25,789 INFO [Thread-93]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:48:25,791 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:48:25,804 INFO [Thread-93] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:48:25,804 INFO [Thread-93] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:48:25,804 INFO [Thread-93] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:48:25,805 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:48:25,810 INFO [Thread-93]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:48:27,210 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:48:27,211 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:48:27,216 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5b54b45: startup date [Mon Dec 11 11:48:27 CST 2017]; root of context hierarchy
2017-12-11 11:48:28,579 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:48:29,541 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:48:29,576 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2360 ms
2017-12-11 11:48:29,680 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:48:29,680 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:48:29,680 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:48:29,718 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:48:29,719 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:48:29,720 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:48:29,720 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:48:29,721 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:48:29,721 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:48:29,721 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:48:29,741 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 58987.
2017-12-11 11:48:29,744 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:48:29,750 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:48:29,751 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:48:29,751 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:48:29,779 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-d9e48a3e-873b-4328-8fa2-6412f8900854
2017-12-11 11:48:29,783 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:48:29,788 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:48:29,812 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:48:29,815 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @446833ms
2017-12-11 11:48:29,819 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@1eda50fb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:48:29,820 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:48:29,820 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36371dad{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,821 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64910722{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,821 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2654740b{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,822 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c0fc6f6{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,822 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6726ab1f{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,823 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ef2e213{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@252b97ec{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45295b6d{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76aba04f{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13aa7648{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,826 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c2f17c{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,827 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6048ecf0{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,827 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@585441eb{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,828 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@595e141d{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,828 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3560f5d3{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,863 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50effae2{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,864 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2066902d{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,864 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31ce8301{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,869 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@66eaa1df{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,869 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7762eb46{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,870 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b11a205{/static,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,871 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@248303d3{/,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,872 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a7e3b08{/api,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,872 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@476476f3{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@73f272ee{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:48:29,873 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:48:29,946 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:48:29,972 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59004.
2017-12-11 11:48:29,972 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59004
2017-12-11 11:48:29,972 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:48:29,973 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59004, None)
2017-12-11 11:48:29,973 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59004 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59004, None)
2017-12-11 11:48:29,974 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59004, None)
2017-12-11 11:48:29,974 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59004, None)
2017-12-11 11:48:29,977 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c1ef433{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,020 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:48:30,020 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:48:30,021 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fac0dec{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,022 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e9ac54d{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,022 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@102076b6{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,023 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@585aa119{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,027 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75e7231f{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:48:30,097 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:48:30,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:48:30,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:48:30,494 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:48:30,495 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:48:30,496 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:48:30,496 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:48:30,496 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:48:30,496 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:48:30,496 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:48:30,497 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:48:30,498 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:30,501 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:48:30,501 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:48:30,502 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:48:30,504 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:48:30,504 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:48:30,618 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5b54b45: startup date [Mon Dec 11 11:48:27 CST 2017]; root of context hierarchy
2017-12-11 11:48:30,633 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:30,658 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:48:30,662 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:48:31,002 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:48:31,117 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:48:31,122 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:48:31,122 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:48:31,123 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:48:31,130 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:48:31,473 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:31,588 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:31,827 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:48:31,936 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:48:32,002 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:48:32,005 INFO [restartedMain]                       com.Application : Started Application in 4.894 seconds (JVM running for 449.022)
2017-12-11 11:48:35,800 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:48:35,804 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 3 ms
2017-12-11 11:48:35,805 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:35,806 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:48:35,811 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:48:35,814 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:48:35,814 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:48:35,814 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:48:35,815 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:48:35,815 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:48:36,398 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,420 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,438 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,452 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,419 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,457 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,451 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,460 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,466 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,469 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,472 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,472 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,472 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,473 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,441 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,475 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,481 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,482 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,492 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,493 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,493 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,494 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,510 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,511 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,526 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,574 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,602 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,603 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,629 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,630 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,642 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,643 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,659 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,660 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,681 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,681 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,757 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,758 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,773 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,773 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,822 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,822 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:36,842 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:36,842 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:37,326 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:37,328 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,301 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,363 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,364 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,369 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,370 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,372 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,373 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,393 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,394 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,394 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,394 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,396 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,396 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,401 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,402 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,403 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,404 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,404 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,407 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,408 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,409 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,413 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,415 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,424 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,425 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,426 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,438 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,456 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,456 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,535 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,536 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,550 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,551 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,560 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,561 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,570 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,571 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,583 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,583 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,591 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,591 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,601 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,602 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:48:39,612 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:48:39,613 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:05,982 INFO [Thread-114] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5b54b45: startup date [Mon Dec 11 11:48:27 CST 2017]; root of context hierarchy
2017-12-11 11:49:05,984 INFO [Thread-114] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:49:05,984 INFO [Thread-114] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:49:06,039 INFO [Thread-114] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@1eda50fb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:49:06,060 INFO [Thread-114]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:49:06,062 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:49:06,582 INFO [Thread-114] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:49:06,582 INFO [Thread-114] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:49:06,583 INFO [Thread-114] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:49:06,584 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:49:06,595 INFO [Thread-114]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:49:07,999 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:49:07,999 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:49:08,003 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@904e941: startup date [Mon Dec 11 11:49:08 CST 2017]; root of context hierarchy
2017-12-11 11:49:10,144 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:49:11,005 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:49:11,074 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3071 ms
2017-12-11 11:49:11,160 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:49:11,161 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:49:11,161 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:49:11,205 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:49:11,206 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:49:11,206 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:49:11,207 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:49:11,207 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:49:11,207 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:49:11,207 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:49:11,219 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59057.
2017-12-11 11:49:11,222 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:49:11,224 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:49:11,224 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:49:11,224 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:49:11,229 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e2e0f116-0b3b-48fe-9bc5-38872454dd86
2017-12-11 11:49:11,230 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:49:11,232 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:49:11,256 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:49:11,257 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @488276ms
2017-12-11 11:49:11,262 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@7902215d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:49:11,263 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:49:11,264 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29d1af90{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,264 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b68379a{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,265 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c830df8{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,266 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37416975{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,266 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f6d55a6{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,266 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74beb100{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,269 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51a1e73a{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,270 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b082f16{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43afe9f2{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,272 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e429148{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,272 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@150a14b6{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,273 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5835e14a{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,273 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d4dfce{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,274 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a72556f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,275 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f109f8c{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,276 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c11d959{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,277 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ebdbe32{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,278 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79fd5d0f{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,279 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a471de6{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,280 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@362b83c2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,287 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e5597d8{/static,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,288 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cd57000{/,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,289 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5aabf2e6{/api,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,289 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12ad960d{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,290 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3438c562{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,290 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:49:11,334 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:49:11,352 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59090.
2017-12-11 11:49:11,352 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59090
2017-12-11 11:49:11,352 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:49:11,353 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59090, None)
2017-12-11 11:49:11,353 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59090 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59090, None)
2017-12-11 11:49:11,353 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59090, None)
2017-12-11 11:49:11,354 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59090, None)
2017-12-11 11:49:11,355 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d88042d{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,359 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:49:11,359 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:49:11,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e71f8e4{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17c1ee90{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77bbfbba{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64660b28{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,370 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33d5b7f4{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:49:11,374 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:49:11,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:49:11,549 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:49:11,551 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:49:11,552 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:49:11,553 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:49:11,554 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:49:11,561 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:49:11,561 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:49:11,561 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:49:11,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:49:11,564 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:49:11,654 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@904e941: startup date [Mon Dec 11 11:49:08 CST 2017]; root of context hierarchy
2017-12-11 11:49:11,664 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:49:11,691 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:49:11,700 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:49:11,918 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:49:12,078 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:49:12,084 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:49:12,084 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:49:12,085 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:49:12,095 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:49:12,472 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:12,685 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:12,952 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:13,097 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:49:13,169 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:49:13,173 INFO [restartedMain]                       com.Application : Started Application in 5.27 seconds (JVM running for 490.191)
2017-12-11 11:49:13,297 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:49:13,302 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 5 ms
2017-12-11 11:49:13,303 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:13,305 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:49:13,317 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:49:13,318 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:49:13,318 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:49:13,318 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:49:13,318 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:49:13,318 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:49:15,645 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,647 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,651 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,652 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,677 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,678 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,685 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,686 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,699 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,700 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,700 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,701 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,725 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,732 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,745 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,747 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,753 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,754 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,775 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,775 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,776 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,776 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,776 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,781 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,785 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,786 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,815 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,816 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:15,842 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:15,844 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,355 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,356 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,375 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,375 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,387 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,387 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,661 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,662 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,681 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,681 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:16,705 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:16,705 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:20,393 INFO [Thread-134] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@904e941: startup date [Mon Dec 11 11:49:08 CST 2017]; root of context hierarchy
2017-12-11 11:49:20,395 INFO [Thread-134] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:49:20,395 INFO [Thread-134] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:49:20,400 INFO [Thread-134] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@7902215d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:49:20,512 INFO [Thread-134]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:49:20,515 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:49:20,696 INFO [Thread-134] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:49:20,696 INFO [Thread-134] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:49:20,697 INFO [Thread-134] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:49:20,697 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:49:20,703 INFO [Thread-134]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:49:22,300 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 13364 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:49:22,311 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:49:22,315 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7484b7e2: startup date [Mon Dec 11 11:49:22 CST 2017]; root of context hierarchy
2017-12-11 11:49:24,524 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:49:25,334 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:49:25,373 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3059 ms
2017-12-11 11:49:25,438 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:49:25,438 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:49:25,438 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:49:25,482 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:49:25,483 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:49:25,483 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:49:25,484 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:49:25,484 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:49:25,484 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:49:25,484 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:49:25,504 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59164.
2017-12-11 11:49:25,507 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:49:25,512 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:49:25,512 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:49:25,512 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:49:25,519 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-4d96cf36-43a0-4eaf-b766-8c273ed45f1e
2017-12-11 11:49:25,521 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:49:25,523 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:49:25,539 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:49:25,540 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @502559ms
2017-12-11 11:49:25,543 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@4bd4863{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:49:25,543 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:49:25,544 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c58799a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,545 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79e4c8bf{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,545 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@689f566d{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,546 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ea67e32{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,546 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2895aaa9{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,546 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31d206a{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,547 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61e91f3f{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,547 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@99b3b53{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,548 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2504d6f7{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,548 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c2a68fd{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,553 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ac77187{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,555 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55a28aab{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,556 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50f22dfd{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,558 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78891b9f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,558 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1965e400{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,560 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@69b10a9a{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,560 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ad7f63c{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,561 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57c56bf5{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,561 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c6e4eec{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,562 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ce6f810{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,574 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52932640{/static,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,575 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c322026{/,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,576 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b70765d{/api,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,577 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55f6a2ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,578 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29eab7b0{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,578 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:49:25,640 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:49:25,655 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59181.
2017-12-11 11:49:25,655 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59181
2017-12-11 11:49:25,657 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:49:25,657 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59181, None)
2017-12-11 11:49:25,658 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59181 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59181, None)
2017-12-11 11:49:25,658 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59181, None)
2017-12-11 11:49:25,658 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59181, None)
2017-12-11 11:49:25,659 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32f2c7e4{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,665 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:49:25,665 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:49:25,666 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6aa47e97{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,667 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d74d584{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,667 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@505614ba{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,668 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@126d3612{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,669 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5df30176{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:49:25,675 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:49:25,948 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:49:25,948 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:49:25,948 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:49:25,949 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:49:25,949 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:49:25,949 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:49:25,950 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:49:25,952 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:49:25,953 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:49:25,954 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:49:25,954 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:49:25,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:49:25,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:49:25,957 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:49:25,959 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:49:25,959 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:49:26,047 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7484b7e2: startup date [Mon Dec 11 11:49:22 CST 2017]; root of context hierarchy
2017-12-11 11:49:26,054 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:49:26,069 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:49:26,074 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:49:26,334 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:49:26,388 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:49:26,397 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:49:26,397 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:49:26,398 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:49:26,411 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:49:26,621 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:26,689 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:26,824 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:49:26,880 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:49:26,896 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:49:26,898 INFO [restartedMain]                       com.Application : Started Application in 4.76 seconds (JVM running for 503.916)
2017-12-11 11:49:53,362 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:49:53,366 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 4 ms
2017-12-11 11:49:53,366 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,373 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * XML
[THYMELEAF]     * XHTML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:49:53,378 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:49:53,439 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,446 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,450 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,451 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,450 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,455 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,454 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,462 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,453 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,463 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,462 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,481 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,482 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,483 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,485 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,460 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,489 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,479 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,493 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,494 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,477 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,495 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,472 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,467 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,505 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,465 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,546 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,547 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,559 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,560 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,570 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,571 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,581 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,582 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,592 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,593 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,603 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,604 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,614 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,614 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,631 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,631 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:53,643 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:49:53,643 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:49:59,970 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,011 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,011 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,012 WARN [http-nio-8080-exec-14] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/jsplumb.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,013 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,014 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,016 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/css/bootstrap-treeview.min.css] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,022 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,023 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-1.11.1.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,024 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,025 WARN [http-nio-8080-exec-12] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,031 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,033 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery-ui-1.9.2.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,033 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,033 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,042 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,043 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,052 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,052 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,056 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,056 WARN [http-nio-8080-exec-7] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,058 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,058 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,061 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,061 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,062 WARN [http-nio-8080-exec-3] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,063 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,201 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/d3.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,062 WARN [http-nio-8080-exec-5] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,215 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,215 WARN [http-nio-8080-exec-13] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/bootstrap-treeview.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,225 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,225 WARN [http-nio-8080-exec-8] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/json2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,233 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,233 WARN [http-nio-8080-exec-4] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jquery.jsPlumb-1.7.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,251 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,251 WARN [http-nio-8080-exec-9] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/biltong-0.2.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,258 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,259 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/jsBezier-0.6.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,266 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,267 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/static/libs/main.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:00,424 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:50:00,425 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:50:52,905 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:50:52,913 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:50:54,083 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@52eec52d: startup date [Mon Dec 11 11:50:54 CST 2017]; root of context hierarchy
2017-12-11 11:50:54,264 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 11:50:58,621 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:51:00,308 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:51:00,925 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6861 ms
2017-12-11 11:51:01,641 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:51:01,660 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:51:01,661 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:51:03,042 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:51:03,404 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 11:51:03,642 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$52a6a6a3.CGLIB$getSparkContext$3(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$52a6a6a3$$FastClassBySpringCGLIB$$a5abd121.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$52a6a6a3.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 11:51:03,756 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:51:03,783 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:51:03,783 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:51:03,783 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:51:03,784 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:51:03,785 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:51:04,536 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59257.
2017-12-11 11:51:04,571 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:51:04,626 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:51:04,636 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:51:04,637 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:51:04,671 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-de49d61a-abf2-4b1a-b1dd-031b23fafb0c
2017-12-11 11:51:04,711 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:51:04,851 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:51:05,025 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @17315ms
2017-12-11 11:51:05,165 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:51:05,190 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @17484ms
2017-12-11 11:51:05,237 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@4d8e2395{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:51:05,237 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:51:05,300 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bfd3d77{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,302 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@281e929{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,303 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c56adb7{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,306 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@354d661b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,312 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a720979{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,314 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14d08125{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,317 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@389a6a9a{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,321 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d4f6b6f{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,323 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b1b9ef{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,325 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46c31dc0{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,326 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41236502{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,327 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@777c8afe{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,328 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@511cc58a{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,329 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1607c637{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47ff6c69{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,332 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@161f0bbc{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cca69c9{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,335 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46f28ad5{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,336 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f09faef{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@744c6349{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,353 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@660a104f{/static,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,355 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a6beaed{/,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,357 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@542723c0{/api,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,358 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a3f3196{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,360 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57ee0fda{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,362 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:51:05,658 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:51:05,717 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59274.
2017-12-11 11:51:05,719 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59274
2017-12-11 11:51:05,721 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:51:05,723 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59274, None)
2017-12-11 11:51:05,728 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59274 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59274, None)
2017-12-11 11:51:05,733 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59274, None)
2017-12-11 11:51:05,736 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59274, None)
2017-12-11 11:51:05,765 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a8adec3{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,893 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:51:05,895 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:51:05,916 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b85d7f2{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,917 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@181f3952{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@373c64cf{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,918 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@734c5278{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:51:05,924 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e142237{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:51:06,817 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 11:51:07,102 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:51:08,206 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:51:08,210 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:51:08,210 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:51:08,214 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:51:08,214 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:51:08,215 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:51:08,215 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:51:08,216 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:51:08,216 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:51:08,217 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:51:08,224 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:51:08,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:51:08,246 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:51:08,248 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:51:08,268 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:51:08,268 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:51:08,743 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:51:08,948 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@52eec52d: startup date [Mon Dec 11 11:50:54 CST 2017]; root of context hierarchy
2017-12-11 11:51:08,973 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:51:09,204 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:51:09,256 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:51:11,903 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:51:12,034 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:51:12,050 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:51:12,050 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:51:12,116 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:51:12,156 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:51:13,326 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:51:13,538 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:51:14,029 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:51:14,132 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:51:14,289 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:51:14,300 INFO [restartedMain]                       com.Application : Started Application in 22.383 seconds (JVM running for 26.594)
2017-12-11 11:51:50,997 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:51:50,997 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:51:51,047 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 50 ms
2017-12-11 11:51:51,062 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,190 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:51:51,351 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:51:51,351 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:51:51,351 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:51:51,351 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:51:51,365 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:51:51,366 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:51:51,608 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,639 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,633 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,657 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,630 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,623 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,622 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,620 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,618 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,605 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,613 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,610 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:51,647 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:52,633 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:52,965 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,701 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,762 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,772 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,772 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,779 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,786 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,791 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,794 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,796 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,804 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,805 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,805 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,810 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:55,818 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:56,758 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:51:56,976 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:53:03,096 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@52eec52d: startup date [Mon Dec 11 11:50:54 CST 2017]; root of context hierarchy
2017-12-11 11:53:03,100 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:53:03,105 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:53:03,132 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@4d8e2395{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:03,237 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:53:03,267 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:53:03,310 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:53:03,311 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:53:03,313 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:53:03,321 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:53:03,327 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:53:03,597 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 11:53:03,601 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 11:53:03,623 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 11:53:04,530 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:53:04,531 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:53:04,542 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@825c270: startup date [Mon Dec 11 11:53:04 CST 2017]; root of context hierarchy
2017-12-11 11:53:09,961 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:53:11,193 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:53:11,311 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6769 ms
2017-12-11 11:53:11,459 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:53:11,462 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:53:11,463 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:53:11,538 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:53:11,540 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:53:11,544 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:53:11,545 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:53:11,545 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:53:11,545 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:53:11,545 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:53:11,631 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59333.
2017-12-11 11:53:11,644 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:53:11,654 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:53:11,654 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:53:11,654 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:53:11,662 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-df03def6-aea8-4651-a8c6-977e4b89dfc7
2017-12-11 11:53:11,667 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:53:11,671 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:53:11,713 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:53:11,715 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @144009ms
2017-12-11 11:53:11,723 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@37fe2fa9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:11,724 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:53:11,724 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5958b843{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,725 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60a44f3a{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,726 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ae799cf{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,727 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@688bf8ba{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,728 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45d1ccbd{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dc902c9{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,730 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59c71b5{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,731 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@79e7a00c{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,737 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e65aec6{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,738 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f8eac61{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,739 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@774a1ac4{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,741 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a610efc{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,742 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d886f5e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,743 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d61c1e5{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,744 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57fdd2ba{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@520384ad{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,745 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fa5ab2c{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,746 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@70ee0e0c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,747 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@425e42bb{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,748 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ad282ed{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,750 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2930ac4a{/static,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,752 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e10dfe7{/,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,753 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30952eb2{/api,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,754 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ebf3389{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,755 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ec7659b{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:11,755 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:53:11,923 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:53:12,109 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59350.
2017-12-11 11:53:12,110 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59350
2017-12-11 11:53:12,110 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:53:12,110 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59350, None)
2017-12-11 11:53:12,111 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59350 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59350, None)
2017-12-11 11:53:12,113 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59350, None)
2017-12-11 11:53:12,113 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59350, None)
2017-12-11 11:53:12,115 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@271ad6ec{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,121 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:53:12,121 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:53:12,122 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19c7333d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,123 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a975c44{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,124 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b166553{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@540a1b68{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,129 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ab92141{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:53:12,145 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:53:12,404 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:53:12,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:53:12,405 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:53:12,406 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:53:12,407 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:53:12,408 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:53:12,408 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:53:12,408 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:53:12,408 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:53:12,409 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:53:12,412 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:12,426 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:53:12,427 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:53:12,429 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:53:12,432 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:12,433 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:53:12,661 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@825c270: startup date [Mon Dec 11 11:53:04 CST 2017]; root of context hierarchy
2017-12-11 11:53:12,672 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:12,705 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:12,713 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:53:13,012 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:53:13,125 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:53:13,136 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:53:13,137 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:53:13,138 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:53:13,146 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:53:13,723 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:13,901 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:14,294 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:14,407 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:53:14,437 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:53:14,447 INFO [restartedMain]                       com.Application : Started Application in 10.21 seconds (JVM running for 146.741)
2017-12-11 11:53:18,843 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@825c270: startup date [Mon Dec 11 11:53:04 CST 2017]; root of context hierarchy
2017-12-11 11:53:18,846 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:53:18,846 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:53:18,860 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@37fe2fa9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:18,865 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:53:18,867 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:53:18,920 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:53:18,920 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:53:18,925 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:53:18,926 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:53:18,947 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:53:19,988 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:53:19,989 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:53:19,997 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@21f7c264: startup date [Mon Dec 11 11:53:19 CST 2017]; root of context hierarchy
2017-12-11 11:53:24,023 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:53:25,642 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:53:25,723 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5726 ms
2017-12-11 11:53:25,854 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:53:25,855 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:53:25,856 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:53:26,082 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:53:26,085 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:53:26,086 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:53:26,086 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:53:26,098 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:53:26,098 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:53:26,098 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:53:26,224 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59378.
2017-12-11 11:53:26,229 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:53:26,231 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:53:26,248 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:53:26,248 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:53:26,256 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-6780b88c-9177-47dd-952a-b177dab2bf13
2017-12-11 11:53:26,258 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:53:26,262 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:53:26,299 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:53:26,302 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @158596ms
2017-12-11 11:53:26,305 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@300198c2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:26,305 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:53:26,306 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@275eb9c3{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,322 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dfd1292{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,323 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63c46b25{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,323 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65c93b58{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,324 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2672e451{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,325 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24241e3f{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,326 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a429fb6{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,330 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59e31e11{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,331 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61e0d2ef{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,332 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cff99d9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,333 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7eb7da14{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b319112{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,336 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ab3a011{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,337 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51361e5f{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29883164{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,339 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b72995f{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,340 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8c26d64{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,342 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4020eac8{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,343 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@708869d5{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,344 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@21e81603{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d1ce034{/static,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,351 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64e1d90d{/,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,352 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fa94c3b{/api,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,353 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24f7ac3f{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,375 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52b9a90f{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,375 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:53:26,432 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:53:26,456 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59395.
2017-12-11 11:53:26,456 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59395
2017-12-11 11:53:26,456 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:53:26,457 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59395, None)
2017-12-11 11:53:26,458 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59395 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59395, None)
2017-12-11 11:53:26,458 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59395, None)
2017-12-11 11:53:26,458 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59395, None)
2017-12-11 11:53:26,460 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@296440ef{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,471 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:53:26,473 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:53:26,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@992a073{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f2ebfa7{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,476 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9f286f9{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,477 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2201a503{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,478 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@779a82ec{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:53:26,483 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:53:26,691 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:53:26,692 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:53:26,692 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:53:26,693 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:53:26,694 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:53:26,694 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:53:26,694 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:53:26,694 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:53:26,696 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:53:26,696 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:53:26,697 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:26,700 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:53:26,700 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:53:26,701 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:53:26,706 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:26,707 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:53:26,793 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@21f7c264: startup date [Mon Dec 11 11:53:19 CST 2017]; root of context hierarchy
2017-12-11 11:53:26,798 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:26,813 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:26,817 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:53:27,083 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:53:27,198 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:53:27,203 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:53:27,205 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:53:27,207 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:53:27,216 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:53:27,497 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:27,598 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:27,787 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:27,861 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:53:27,897 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:53:27,902 INFO [restartedMain]                       com.Application : Started Application in 8.034 seconds (JVM running for 160.196)
2017-12-11 11:53:41,318 INFO [Thread-39] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@21f7c264: startup date [Mon Dec 11 11:53:19 CST 2017]; root of context hierarchy
2017-12-11 11:53:41,320 INFO [Thread-39] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:53:41,330 INFO [Thread-39] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:53:41,335 INFO [Thread-39] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@300198c2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:41,348 INFO [Thread-39]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:53:41,352 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:53:41,360 INFO [Thread-39] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:53:41,361 INFO [Thread-39] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:53:41,361 INFO [Thread-39] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:53:41,362 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:53:41,368 INFO [Thread-39]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:53:42,055 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:53:42,055 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:53:42,063 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@718970a9: startup date [Mon Dec 11 11:53:42 CST 2017]; root of context hierarchy
2017-12-11 11:53:45,913 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:53:47,614 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:53:47,699 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5636 ms
2017-12-11 11:53:47,842 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:53:47,843 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:53:47,843 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:53:47,922 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:53:47,924 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:53:47,925 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:53:47,925 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:53:47,925 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:53:47,926 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:53:47,926 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:53:47,968 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59425.
2017-12-11 11:53:47,973 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:53:47,979 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:53:47,980 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:53:47,980 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:53:48,006 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-b6e74e39-239e-44d6-9f3f-766e74f56d10
2017-12-11 11:53:48,007 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:53:48,009 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:53:48,026 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:53:48,027 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @180321ms
2017-12-11 11:53:48,031 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@77b9b038{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:48,031 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:53:48,032 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65f5ba23{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,033 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fd915c1{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,034 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d37cc58{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,034 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7daf97b2{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,037 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51be67b8{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,038 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45f676d9{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,039 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64992132{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,040 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7dfa83b4{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,040 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5616b8da{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1799f453{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@531724cc{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,043 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c9ccbd7{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,044 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72240173{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,045 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30684782{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b67abf{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ee654b7{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,050 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11c0e8be{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,051 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53e6e75c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,052 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e201464{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f2b28b8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a72016{/static,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,057 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@278c29a3{/,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,057 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2433e08c{/api,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,058 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5380213a{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,059 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a8a774a{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,059 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:53:48,134 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:53:48,151 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59442.
2017-12-11 11:53:48,152 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59442
2017-12-11 11:53:48,152 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:53:48,152 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59442, None)
2017-12-11 11:53:48,155 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59442 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59442, None)
2017-12-11 11:53:48,157 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59442, None)
2017-12-11 11:53:48,158 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59442, None)
2017-12-11 11:53:48,160 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a9d38fb{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,167 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:53:48,167 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:53:48,169 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63e16626{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,169 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5361dffe{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,170 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@233f7446{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,171 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c39cff3{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,172 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41c56963{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:53:48,182 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:53:48,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:53:48,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:53:48,473 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:53:48,480 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:53:48,480 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:53:48,481 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:53:48,481 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:53:48,481 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:53:48,481 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:53:48,482 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:53:48,482 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:48,520 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:53:48,520 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:53:48,521 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:53:48,530 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:53:48,534 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:53:48,669 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@718970a9: startup date [Mon Dec 11 11:53:42 CST 2017]; root of context hierarchy
2017-12-11 11:53:48,676 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:48,729 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:53:48,736 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:53:49,091 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:53:49,238 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:53:49,244 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:53:49,245 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:53:49,246 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:53:49,349 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:53:49,918 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:50,015 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:50,406 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:53:50,483 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:53:50,537 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:53:50,541 INFO [restartedMain]                       com.Application : Started Application in 8.564 seconds (JVM running for 182.835)
2017-12-11 11:53:57,347 INFO [Thread-60] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@718970a9: startup date [Mon Dec 11 11:53:42 CST 2017]; root of context hierarchy
2017-12-11 11:53:57,350 INFO [Thread-60] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:53:57,351 INFO [Thread-60] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:53:57,353 INFO [Thread-60] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@77b9b038{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:53:57,357 INFO [Thread-60]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:53:57,360 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:53:57,375 INFO [Thread-60] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:53:57,375 INFO [Thread-60] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:53:57,376 INFO [Thread-60] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:53:57,377 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:53:57,383 INFO [Thread-60]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:53:58,373 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:53:58,373 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:53:58,378 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@305fc75c: startup date [Mon Dec 11 11:53:58 CST 2017]; root of context hierarchy
2017-12-11 11:54:00,351 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:54:01,834 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:54:01,994 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3616 ms
2017-12-11 11:54:02,120 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:54:02,121 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:54:02,121 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:54:02,201 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:54:02,202 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:54:02,203 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:54:02,203 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:54:02,203 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:54:02,203 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:54:02,203 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:54:02,232 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59471.
2017-12-11 11:54:02,240 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:54:02,259 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:54:02,259 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:54:02,259 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:54:02,265 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-87ade63a-2388-4011-b73b-51456f5e8d60
2017-12-11 11:54:02,266 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:54:02,271 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:54:02,296 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:54:02,297 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @194591ms
2017-12-11 11:54:02,300 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2d32ef8d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:54:02,301 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:54:02,302 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@121525eb{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,303 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a83cac2{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,303 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bf64310{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,314 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2522e970{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,314 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@142ec4f2{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,316 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@380a4000{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,319 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@82e20dd{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,321 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6215781c{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,323 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ac1bce2{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,326 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3293a93e{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,327 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@449793ab{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,328 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6fb772ae{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,329 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@345c5e67{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,330 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@37f18990{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,332 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@592a5b81{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,332 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c5f0cdf{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2479b0cf{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,334 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a5228d3{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,335 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c486520{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,336 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6698ad51{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,337 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e4b6fc9{/static,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,337 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@785c2533{/,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,338 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75e5112{/api,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,339 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f8253a8{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,344 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30e6d664{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,344 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:54:02,462 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:54:02,515 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59488.
2017-12-11 11:54:02,516 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59488
2017-12-11 11:54:02,516 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:54:02,516 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59488, None)
2017-12-11 11:54:02,518 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59488 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59488, None)
2017-12-11 11:54:02,518 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59488, None)
2017-12-11 11:54:02,518 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59488, None)
2017-12-11 11:54:02,521 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27389b84{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,528 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:54:02,528 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:54:02,530 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78983147{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,530 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@168cbb41{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,531 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1447a56{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,534 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6fc6fa80{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,537 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@426a7141{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:54:02,542 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:54:02,862 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:54:02,862 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:54:02,862 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/ajaxfileUpload],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.goUploadImg()
2017-12-11 11:54:02,866 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:54:02,867 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:54:02,867 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:54:02,867 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:54:02,867 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:54:02,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:54:02,868 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:54:02,869 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:54:02,875 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:54:02,876 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:54:02,877 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:54:02,882 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:54:02,885 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:54:03,127 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@305fc75c: startup date [Mon Dec 11 11:53:58 CST 2017]; root of context hierarchy
2017-12-11 11:54:03,147 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:54:03,198 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:54:03,207 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:54:03,705 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:54:03,816 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:54:03,822 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:54:03,823 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:54:03,824 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:54:03,830 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:54:04,039 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:54:04,144 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:54:04,322 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:54:04,386 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:54:04,408 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:54:04,412 INFO [restartedMain]                       com.Application : Started Application in 6.165 seconds (JVM running for 196.706)
2017-12-11 11:55:14,789 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:55:14,798 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 8 ms
2017-12-11 11:55:14,799 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:55:14,800 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 11:55:14,805 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 11:55:14,907 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:55:14,909 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/webjars/jquery/2.2.4/jquery.min.js] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:55:35,511 INFO [Thread-77] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@305fc75c: startup date [Mon Dec 11 11:53:58 CST 2017]; root of context hierarchy
2017-12-11 11:55:35,516 INFO [Thread-77] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:55:35,516 INFO [Thread-77] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:55:35,518 INFO [Thread-77] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2d32ef8d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:55:35,528 INFO [Thread-77]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:55:35,530 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:55:35,598 INFO [Thread-77] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:55:35,598 INFO [Thread-77] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:55:35,599 INFO [Thread-77] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:55:35,599 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:55:35,606 INFO [Thread-77]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:55:36,828 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:55:36,828 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:55:36,837 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43c4006e: startup date [Mon Dec 11 11:55:36 CST 2017]; root of context hierarchy
2017-12-11 11:55:39,233 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:55:40,111 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:55:40,151 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3314 ms
2017-12-11 11:55:40,244 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:55:40,245 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:55:40,245 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:55:40,319 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:55:40,324 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:55:40,326 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:55:40,326 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:55:40,326 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:55:40,326 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:55:40,326 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:55:40,350 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59580.
2017-12-11 11:55:40,355 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:55:40,360 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:55:40,360 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:55:40,360 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:55:40,367 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-1fae43eb-3682-41e9-aed0-76b6d56c5333
2017-12-11 11:55:40,368 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:55:40,370 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:55:40,390 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:55:40,391 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @292685ms
2017-12-11 11:55:40,400 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@49db90bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:55:40,400 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:55:40,401 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@647e065d{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,401 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45809403{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,402 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@13bb1d{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,404 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@160508a1{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,404 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@470da860{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,405 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b134af1{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,405 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2274afbf{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,406 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e764c2f{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,406 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63a13099{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,407 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e879642{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,408 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bef32e1{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,409 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e3bdc60{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,409 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3aca4c93{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,410 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6510be56{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,410 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@654490f4{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,411 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@556ccc24{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,412 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@e2e1548{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,412 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@798c0a7c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,413 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f09ae30{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,413 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b375789{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,414 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@433c2eab{/static,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b0c5235{/,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b3759d7{/api,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25e10055{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f368065{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,416 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:55:40,476 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:55:40,493 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59597.
2017-12-11 11:55:40,493 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59597
2017-12-11 11:55:40,494 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:55:40,494 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59597, None)
2017-12-11 11:55:40,495 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59597 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59597, None)
2017-12-11 11:55:40,495 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59597, None)
2017-12-11 11:55:40,496 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59597, None)
2017-12-11 11:55:40,497 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c47305c{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,504 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:55:40,504 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:55:40,505 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@436ba779{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,508 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ba29a27{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,511 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5928c6bf{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,511 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@352d130b{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,535 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@26232dfb{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:55:40,542 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:55:40,708 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:55:40,709 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:55:40,710 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:55:40,710 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:55:40,710 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:55:40,710 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:55:40,711 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:55:40,711 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:55:40,714 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:55:40,714 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:55:40,715 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:55:40,717 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:55:40,718 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:55:40,755 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:55:40,812 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43c4006e: startup date [Mon Dec 11 11:55:36 CST 2017]; root of context hierarchy
2017-12-11 11:55:40,816 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:55:40,831 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:55:40,834 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:55:41,020 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:55:41,108 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:55:41,113 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:55:41,113 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:55:41,120 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:55:41,137 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:55:41,502 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:41,599 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:41,938 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:42,027 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:55:42,078 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:55:42,082 INFO [restartedMain]                       com.Application : Started Application in 5.401 seconds (JVM running for 294.376)
2017-12-11 11:55:44,322 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:55:44,326 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 4 ms
2017-12-11 11:55:44,327 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:55:44,339 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/ajaxfileUpload] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:55:47,974 INFO [Thread-97] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@43c4006e: startup date [Mon Dec 11 11:55:36 CST 2017]; root of context hierarchy
2017-12-11 11:55:47,976 INFO [Thread-97] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:55:47,976 INFO [Thread-97] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:55:47,980 INFO [Thread-97] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@49db90bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:55:47,984 INFO [Thread-97]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:55:47,988 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:55:47,997 INFO [Thread-97] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:55:47,997 INFO [Thread-97] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:55:47,998 INFO [Thread-97] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:55:47,998 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:55:48,011 INFO [Thread-97]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:55:49,146 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 456 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:55:49,146 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:55:49,150 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@32859064: startup date [Mon Dec 11 11:55:49 CST 2017]; root of context hierarchy
2017-12-11 11:55:53,782 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:55:54,787 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:55:54,815 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5664 ms
2017-12-11 11:55:54,925 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:55:54,925 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:55:54,926 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:55:54,982 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:55:54,982 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:55:54,983 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:55:54,983 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:55:54,983 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:55:54,983 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:55:54,983 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:55:54,996 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59702.
2017-12-11 11:55:55,000 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:55:55,007 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:55:55,008 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:55:55,008 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:55:55,015 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-5546e729-26e8-4788-9f4b-ea38e076f05f
2017-12-11 11:55:55,017 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:55:55,020 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:55:55,036 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:55:55,037 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @307331ms
2017-12-11 11:55:55,041 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@442ceb89{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:55:55,041 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:55:55,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@195481d9{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,042 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@75a39301{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,043 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@462e355c{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,043 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c7d59ec{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,044 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59f80b87{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,044 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25e7bf25{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,045 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@81bb4a1{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a40bd92{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6fa43d16{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,047 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43c12bcf{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,048 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e0d4747{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,049 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d6cbe42{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,051 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@153aae41{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71e81532{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,053 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fb55f53{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,054 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56c4a117{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,055 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51332223{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,055 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@66364835{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57ddbb34{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,056 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ad21d11{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,057 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@427fdfdf{/static,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,059 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a2412cf{/,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,059 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40d10b99{/api,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,060 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e75783b{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,061 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32e1327c{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,061 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:55:55,117 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:55:55,139 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59719.
2017-12-11 11:55:55,139 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59719
2017-12-11 11:55:55,139 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:55:55,139 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59719, None)
2017-12-11 11:55:55,140 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59719 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59719, None)
2017-12-11 11:55:55,140 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59719, None)
2017-12-11 11:55:55,140 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59719, None)
2017-12-11 11:55:55,142 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@354ffc2c{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,150 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:55:55,151 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:55:55,152 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fadd233{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,152 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65110ce2{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,153 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fcce0e7{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,154 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c5fbbc0{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,157 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74da2fe5{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:55:55,164 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:55:55,373 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:55:55,374 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:55:55,374 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:55:55,374 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:55:55,374 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:55:55,375 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:55:55,375 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:55:55,375 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:55:55,380 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:55:55,380 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:55:55,380 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:55:55,480 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:55:55,481 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:55:55,547 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:55:55,641 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@32859064: startup date [Mon Dec 11 11:55:49 CST 2017]; root of context hierarchy
2017-12-11 11:55:55,645 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:55:55,668 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:55:55,672 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:55:55,968 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:55:56,052 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:55:56,057 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:55:56,057 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:55:56,058 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:55:56,065 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:55:56,318 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:56,368 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:56,606 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:55:56,832 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:55:56,874 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:55:56,879 INFO [restartedMain]                       com.Application : Started Application in 8.051 seconds (JVM running for 309.173)
2017-12-11 11:55:59,722 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 11:55:59,726 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 4 ms
2017-12-11 11:55:59,726 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:55:59,729 WARN [http-nio-8080-exec-1] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/test] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:56:02,003 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 11:56:02,004 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/test] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 11:56:46,450 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:56:46,454 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:56:47,635 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@604d571d: startup date [Mon Dec 11 11:56:47 CST 2017]; root of context hierarchy
2017-12-11 11:56:47,888 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 11:56:55,115 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:56:58,073 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:56:59,246 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 11619 ms
2017-12-11 11:57:00,158 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:57:00,179 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:57:00,181 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 11:57:02,055 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 11:57:02,681 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 11:57:02,835 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:22)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$930510f.CGLIB$getSparkContext$2(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$930510f$$FastClassBySpringCGLIB$$74d97600.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$930510f.getSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 11:57:03,004 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 11:57:03,035 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 11:57:03,036 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 11:57:03,036 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 11:57:03,037 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 11:57:03,037 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 11:57:03,565 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59786.
2017-12-11 11:57:03,592 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 11:57:03,619 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 11:57:03,626 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 11:57:03,627 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 11:57:03,653 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-bbbadf15-294d-409e-8810-f1b05f38757e
2017-12-11 11:57:03,678 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 11:57:03,750 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 11:57:03,915 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @23460ms
2017-12-11 11:57:04,009 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 11:57:04,031 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @23579ms
2017-12-11 11:57:04,071 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2108395d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:57:04,072 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 11:57:04,127 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12da8a9f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,132 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3db11c38{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,133 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7830323e{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,135 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cf88e58{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,138 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@47300ced{/stages,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,139 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24f24718{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,141 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11d18fc8{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,144 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@99db591{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,146 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5da08c49{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,148 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53885566{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,149 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@501c5640{/storage,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,150 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cd7f81a{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,151 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1df0b72f{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,153 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1efc8338{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,154 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4bda5cd8{/environment,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,155 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4928432e{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,156 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d89739b{/executors,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,158 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a9135da{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,159 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ec67261{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,161 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35e6c018{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,177 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ee73100{/static,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,179 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a312c4a{/,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,181 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45c22c10{/api,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,183 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5afd907b{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,184 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e86c08c{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,188 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 11:57:04,377 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 11:57:04,453 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59803.
2017-12-11 11:57:04,456 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59803
2017-12-11 11:57:04,460 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 11:57:04,465 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59803, None)
2017-12-11 11:57:04,475 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59803 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59803, None)
2017-12-11 11:57:04,483 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59803, None)
2017-12-11 11:57:04,485 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59803, None)
2017-12-11 11:57:04,523 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f2de55{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,717 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 11:57:04,717 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 11:57:04,729 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c4ae1a1{/SQL,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,731 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2396994a{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,732 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@253242c0{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,733 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62118e83{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 11:57:04,735 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@707c7f0f{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 11:57:05,726 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 11:57:05,985 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 11:57:06,918 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 11:57:06,919 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 11:57:06,925 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 11:57:06,926 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 11:57:06,926 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 11:57:06,926 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 11:57:06,927 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 11:57:06,927 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 11:57:06,927 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 11:57:06,929 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 11:57:06,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 11:57:06,938 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 11:57:06,940 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 11:57:06,954 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:57:06,954 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:57:07,237 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:57:07,372 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@604d571d: startup date [Mon Dec 11 11:56:47 CST 2017]; root of context hierarchy
2017-12-11 11:57:07,386 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:57:07,489 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:57:07,521 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 11:57:11,543 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:57:11,694 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:57:11,712 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 11:57:11,712 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 11:57:11,802 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 11:57:11,856 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 11:57:12,827 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:57:12,980 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:57:13,302 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 11:57:13,413 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 11:57:13,573 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:57:13,587 INFO [restartedMain]                       com.Application : Started Application in 28.892 seconds (JVM running for 33.134)
2017-12-11 11:59:46,386 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@604d571d: startup date [Mon Dec 11 11:56:47 CST 2017]; root of context hierarchy
2017-12-11 11:59:46,389 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 11:59:46,393 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 11:59:46,413 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2108395d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 11:59:46,433 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 11:59:46,476 INFO [dispatcher-event-loop-3] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 11:59:46,530 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 11:59:46,531 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 11:59:46,535 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 11:59:46,548 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 11:59:46,559 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 11:59:47,209 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 11:59:47,234 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 11:59:48,381 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 11:59:48,444 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 11:59:48,467 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@709ad3e2: startup date [Mon Dec 11 11:59:48 CST 2017]; root of context hierarchy
2017-12-11 11:59:51,918 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 11:59:53,791 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 11:59:53,990 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5523 ms
2017-12-11 11:59:54,587 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 11:59:54,588 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 11:59:54,588 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-12-11 11:59:54,588 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-12-11 11:59:54,589 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'requestContextFilter' to: [/*]
2017-12-11 11:59:55,155 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@709ad3e2: startup date [Mon Dec 11 11:59:48 CST 2017]; root of context hierarchy
2017-12-11 11:59:55,161 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:59:55,187 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 11:59:55,189 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 11:59:55,209 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:59:55,210 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:59:55,242 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 11:59:55,307 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 11:59:55,873 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 11:59:56,025 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 11:59:56,212 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 11:59:56,215 INFO [restartedMain]                       com.Application : Started Application in 8.298 seconds (JVM running for 195.762)
2017-12-11 12:00:04,928 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@709ad3e2: startup date [Mon Dec 11 11:59:48 CST 2017]; root of context hierarchy
2017-12-11 12:00:04,929 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:00:05,718 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:00:05,719 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:00:05,732 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@79d4086c: startup date [Mon Dec 11 12:00:05 CST 2017]; root of context hierarchy
2017-12-11 12:00:08,392 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:00:11,207 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:00:11,373 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5641 ms
2017-12-11 12:00:11,616 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:00:11,618 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:00:11,618 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:00:11,842 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:00:11,844 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:00:11,845 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:00:11,845 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:00:11,846 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:00:11,846 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:00:11,846 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:00:11,874 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59876.
2017-12-11 12:00:11,879 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:00:11,901 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:00:11,902 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:00:11,902 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:00:11,947 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-296b8a92-7918-4e4d-9928-c6a78e499a26
2017-12-11 12:00:11,949 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:00:11,953 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:00:11,988 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:00:11,990 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @211537ms
2017-12-11 12:00:12,003 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@aa65ffc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:00:12,004 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:00:12,005 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bb15a3{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,014 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2aeb29c8{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,015 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4846c339{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,017 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@517a767b{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,019 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bc39c66{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,020 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e976d99{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,020 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5af65e57{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,028 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f68c16{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,030 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4821edf6{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,034 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2fcfdab4{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,035 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20192c31{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,036 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a4bd8e4{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,040 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@15b760b7{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,044 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1fbb7658{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,046 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78d52dac{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,048 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7fe1e9ce{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,051 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3235a32f{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,055 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b15c1eb{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,057 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52edde9{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,058 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ca19788{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,059 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@cb75307{/static,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,060 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45f3cbf3{/,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,062 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24fc9426{/api,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,064 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@364c23cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,065 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@523320d4{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,065 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:00:12,267 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:00:12,392 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59893.
2017-12-11 12:00:12,392 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59893
2017-12-11 12:00:12,393 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:00:12,394 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59893, None)
2017-12-11 12:00:12,395 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59893 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59893, None)
2017-12-11 12:00:12,397 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59893, None)
2017-12-11 12:00:12,398 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59893, None)
2017-12-11 12:00:12,400 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@661fc00c{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,408 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:00:12,408 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:00:12,409 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dd309a9{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,410 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f1e9384{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,414 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8449c75{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,415 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31d27ded{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,424 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@728ff398{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:00:12,481 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:00:12,963 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:00:12,963 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:00:12,969 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:00:12,970 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:00:12,970 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:00:12,970 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:00:12,971 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:00:12,971 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:00:12,971 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:00:12,972 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:00:12,977 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:00:12,977 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:00:12,978 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:00:12,981 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:00:12,981 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:00:13,085 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:00:13,186 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@79d4086c: startup date [Mon Dec 11 12:00:05 CST 2017]; root of context hierarchy
2017-12-11 12:00:13,205 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:00:13,337 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:00:13,342 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:00:13,740 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:00:13,953 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:00:13,960 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:00:13,960 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:00:13,961 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:00:13,977 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:00:14,354 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:00:14,435 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:00:14,620 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:00:14,743 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:00:14,791 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:00:14,799 INFO [restartedMain]                       com.Application : Started Application in 9.182 seconds (JVM running for 214.346)
2017-12-11 12:01:31,420 INFO [Thread-28] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@79d4086c: startup date [Mon Dec 11 12:00:05 CST 2017]; root of context hierarchy
2017-12-11 12:01:31,425 INFO [Thread-28] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:01:31,426 INFO [Thread-28] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:01:31,432 INFO [Thread-28] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@aa65ffc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:01:31,434 INFO [Thread-28]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:01:31,436 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:01:31,450 INFO [Thread-28] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:01:31,450 INFO [Thread-28] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:01:31,451 INFO [Thread-28] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:01:31,454 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:01:31,489 INFO [Thread-28]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:01:32,982 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:01:32,984 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:01:32,990 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@f14135b: startup date [Mon Dec 11 12:01:32 CST 2017]; root of context hierarchy
2017-12-11 12:01:36,488 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:01:37,666 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:01:37,699 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4709 ms
2017-12-11 12:01:37,864 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:01:37,865 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:01:37,865 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:01:38,103 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:01:38,106 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:01:38,109 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:01:38,109 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:01:38,109 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:01:38,109 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:01:38,110 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:01:38,166 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 59953.
2017-12-11 12:01:38,184 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:01:38,190 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:01:38,191 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:01:38,191 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:01:38,202 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-10e1cffb-0e78-4313-a83a-98e7db32e309
2017-12-11 12:01:38,204 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:01:38,209 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:01:38,243 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:01:38,246 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @297793ms
2017-12-11 12:01:38,250 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@7d8ed5a9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:01:38,250 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:01:38,252 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@649a892a{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,266 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a178462{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,267 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11dc21d0{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,268 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@77b115cc{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,269 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f8cb535{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,270 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c4be279{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f3e2996{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43d43eb2{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,272 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ccbc52{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,273 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@589d5828{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,274 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@711e010a{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,275 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f61a9ef{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,275 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32105227{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,276 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72a2632e{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,277 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4907e57e{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,278 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2cc7c9db{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,279 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@136afea2{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,280 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2788ed22{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,290 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@db5843{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,291 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4efd7b21{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,292 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51777fdd{/static,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,293 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39d63670{/,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,295 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7916d331{/api,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,296 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@24eedd2f{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,297 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@42257045{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,297 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:01:38,373 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:01:38,410 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59970.
2017-12-11 12:01:38,411 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:59970
2017-12-11 12:01:38,412 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:01:38,412 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 59970, None)
2017-12-11 12:01:38,413 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:59970 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 59970, None)
2017-12-11 12:01:38,414 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 59970, None)
2017-12-11 12:01:38,414 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 59970, None)
2017-12-11 12:01:38,416 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5bcf9a5f{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,439 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:01:38,443 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:01:38,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3163ec4c{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@60afe33b{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e39d1a4{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,449 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2a61ccf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,451 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d00d810{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:01:38,459 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:01:38,769 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:01:38,770 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:01:38,773 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:01:38,775 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:01:38,775 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:01:38,775 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:01:38,775 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:01:38,776 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:01:38,776 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:01:38,778 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:01:38,783 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:01:38,784 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:01:38,784 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:01:38,791 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:01:38,791 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:01:38,914 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:01:38,983 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@f14135b: startup date [Mon Dec 11 12:01:32 CST 2017]; root of context hierarchy
2017-12-11 12:01:38,991 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:01:39,017 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:01:39,023 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:01:39,386 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:01:39,641 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:01:39,649 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:01:39,650 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:01:39,651 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:01:39,663 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:01:40,398 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:01:40,602 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:01:40,926 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:01:41,105 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:01:41,182 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:01:41,186 INFO [restartedMain]                       com.Application : Started Application in 8.351 seconds (JVM running for 300.733)
2017-12-11 12:01:45,574 INFO [main]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:01:46,213 WARN [main] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 12:01:46,469 ERROR [main]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at util.SparkUtil$.main(SparkUtil.scala:12)
	at util.SparkUtil.main(SparkUtil.scala)
2017-12-11 12:01:46,899 INFO [main]         org.apache.spark.SparkContext : Submitted application: test
2017-12-11 12:01:46,941 INFO [main]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:01:46,943 INFO [main]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:01:46,944 INFO [main]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:01:46,944 INFO [main]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:01:46,945 INFO [main]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:01:49,546 INFO [main]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60004.
2017-12-11 12:01:49,610 INFO [main]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:01:49,720 INFO [main]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:01:49,729 INFO [main] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:01:49,730 INFO [main] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:01:49,810 INFO [main] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-640e6517-7e11-49be-b12c-9b2e73c21c65
2017-12-11 12:01:49,902 INFO [main] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:01:50,089 INFO [main]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:01:50,320 INFO [main]      org.spark_project.jetty.util.log : Logging initialized @11943ms
2017-12-11 12:01:50,434 INFO [main] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:01:50,467 INFO [main] org.spark_project.jetty.server.Server : Started @12091ms
2017-12-11 12:01:50,498 WARN [main]           org.apache.spark.util.Utils : Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2017-12-11 12:01:50,511 INFO [main] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@63c5efee{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2017-12-11 12:01:50,511 INFO [main]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4041.
2017-12-11 12:01:50,598 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c22d4f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,600 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e521c1e{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,602 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d5d9e5{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,607 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@362a019c{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,609 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c48c0c0{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,618 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@674c583e{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,619 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f23a3a0{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,624 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,626 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25bcd0c7{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,627 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63cd604c{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,628 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a4e343{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,629 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@62dae245{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,631 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6fff253c{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,633 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@591e58fa{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,634 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f94c4db{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,636 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72ccd81a{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,639 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64bc21ac{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,641 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d25e6bb{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,643 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9d157ff{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,644 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5df417a7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,661 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f69d591{/static,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,662 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71104a4{/,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,665 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72f46e16{/api,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,666 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5217f3d0{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,667 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:01:50,671 INFO [main]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4041
2017-12-11 12:01:51,044 INFO [main]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:01:51,144 INFO [main]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60021.
2017-12-11 12:01:51,145 INFO [main] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60021
2017-12-11 12:01:51,150 INFO [main] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:01:51,154 INFO [main] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60021, None)
2017-12-11 12:01:51,163 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60021 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60021, None)
2017-12-11 12:01:51,171 INFO [main] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60021, None)
2017-12-11 12:01:51,172 INFO [main] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60021, None)
2017-12-11 12:01:51,863 INFO [main] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:01:52,806 INFO [main]         org.apache.spark.SparkContext : Starting job: collect at SparkUtil.scala:18
2017-12-11 12:01:53,196 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Registering RDD 2 (map at SparkUtil.scala:18)
2017-12-11 12:01:53,200 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 0 (collect at SparkUtil.scala:18) with 3 output partitions
2017-12-11 12:01:53,201 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 1 (collect at SparkUtil.scala:18)
2017-12-11 12:01:53,201 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List(ShuffleMapStage 0)
2017-12-11 12:01:53,204 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List(ShuffleMapStage 0)
2017-12-11 12:01:53,220 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at SparkUtil.scala:18), which has no missing parents
2017-12-11 12:01:53,711 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0 stored as values in memory (estimated size 3.2 KB, free 898.5 MB)
2017-12-11 12:01:54,003 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0_piece0 stored as bytes in memory (estimated size 1984.0 B, free 898.5 MB)
2017-12-11 12:01:54,009 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added broadcast_0_piece0 in memory on 192.168.211.1:60021 (size: 1984.0 B, free: 898.5 MB)
2017-12-11 12:01:54,014 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2017-12-11 12:01:54,056 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at SparkUtil.scala:18) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 12:01:54,058 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 0.0 with 3 tasks
2017-12-11 12:01:54,148 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4816 bytes)
2017-12-11 12:01:54,152 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4843 bytes)
2017-12-11 12:01:54,154 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 4846 bytes)
2017-12-11 12:01:54,166 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Running task 0.0 in stage 0.0 (TID 0)
2017-12-11 12:01:54,166 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Running task 1.0 in stage 0.0 (TID 1)
2017-12-11 12:01:54,167 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Running task 2.0 in stage 0.0 (TID 2)
2017-12-11 12:01:54,664 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 0.0 (TID 0). 941 bytes result sent to driver
2017-12-11 12:01:54,665 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 0.0 (TID 1). 1027 bytes result sent to driver
2017-12-11 12:01:54,665 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 0.0 (TID 2). 1027 bytes result sent to driver
2017-12-11 12:01:54,698 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 0.0 (TID 1) in 544 ms on localhost (executor driver) (1/3)
2017-12-11 12:01:54,704 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 0.0 (TID 0) in 590 ms on localhost (executor driver) (2/3)
2017-12-11 12:01:54,705 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 0.0 (TID 2) in 552 ms on localhost (executor driver) (3/3)
2017-12-11 12:01:54,712 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-12-11 12:01:54,729 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ShuffleMapStage 0 (map at SparkUtil.scala:18) finished in 0.635 s
2017-12-11 12:01:54,731 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : looking for newly runnable stages
2017-12-11 12:01:54,735 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : running: Set()
2017-12-11 12:01:54,736 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : waiting: Set(ResultStage 1)
2017-12-11 12:01:54,737 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : failed: Set()
2017-12-11 12:01:54,747 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 1 (ShuffledRDD[3] at reduceByKey at SparkUtil.scala:18), which has no missing parents
2017-12-11 12:01:54,768 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 898.5 MB)
2017-12-11 12:01:54,776 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1968.0 B, free 898.5 MB)
2017-12-11 12:01:54,778 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added broadcast_1_piece0 in memory on 192.168.211.1:60021 (size: 1968.0 B, free: 898.5 MB)
2017-12-11 12:01:54,780 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-12-11 12:01:54,787 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 1 (ShuffledRDD[3] at reduceByKey at SparkUtil.scala:18) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 12:01:54,787 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 1.0 with 3 tasks
2017-12-11 12:01:54,801 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 1.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-12-11 12:01:54,803 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 1.0 (TID 4, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-12-11 12:01:54,805 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 1.0 (TID 5, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-12-11 12:01:54,806 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Running task 0.0 in stage 1.0 (TID 3)
2017-12-11 12:01:54,816 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Running task 1.0 in stage 1.0 (TID 4)
2017-12-11 12:01:54,817 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Running task 2.0 in stage 1.0 (TID 5)
2017-12-11 12:01:54,859 INFO [Executor task launch worker for task 4] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 12:01:54,859 INFO [Executor task launch worker for task 5] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 12:01:54,859 INFO [Executor task launch worker for task 3] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 2 non-empty blocks out of 3 blocks
2017-12-11 12:01:54,864 INFO [Executor task launch worker for task 5] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 13 ms
2017-12-11 12:01:54,864 INFO [Executor task launch worker for task 4] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 15 ms
2017-12-11 12:01:54,864 INFO [Executor task launch worker for task 3] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 11 ms
2017-12-11 12:01:54,983 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 1.0 (TID 5). 1238 bytes result sent to driver
2017-12-11 12:01:54,983 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 1.0 (TID 3). 1286 bytes result sent to driver
2017-12-11 12:01:54,983 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 1.0 (TID 4). 1197 bytes result sent to driver
2017-12-11 12:01:54,988 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 1.0 (TID 3) in 192 ms on localhost (executor driver) (1/3)
2017-12-11 12:01:54,989 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 1.0 (TID 4) in 188 ms on localhost (executor driver) (2/3)
2017-12-11 12:01:54,993 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 1.0 (TID 5) in 189 ms on localhost (executor driver) (3/3)
2017-12-11 12:01:54,994 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-12-11 12:01:54,995 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 1 (collect at SparkUtil.scala:18) finished in 0.200 s
2017-12-11 12:01:55,006 INFO [main] org.apache.spark.scheduler.DAGScheduler : Job 0 finished: collect at SparkUtil.scala:18, took 2.198461 s
2017-12-11 12:01:55,017 INFO [Thread-1]         org.apache.spark.SparkContext : Invoking stop() from shutdown hook
2017-12-11 12:01:55,024 INFO [Thread-1] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@63c5efee{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2017-12-11 12:01:55,027 INFO [Thread-1]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4041
2017-12-11 12:01:55,041 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:01:55,083 INFO [Thread-1] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:01:55,084 INFO [Thread-1] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:01:55,090 INFO [Thread-1] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:01:55,092 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:01:55,097 INFO [Thread-1]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:01:55,098 INFO [Thread-1] org.apache.spark.util.ShutdownHookManager : Shutdown hook called
2017-12-11 12:01:55,099 INFO [Thread-1] org.apache.spark.util.ShutdownHookManager : Deleting directory C:\Users\domino\AppData\Local\Temp\spark-fda61fe7-49ca-4335-b0d0-23ead52f5a3d
2017-12-11 12:03:58,278 INFO [Thread-44] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@f14135b: startup date [Mon Dec 11 12:01:32 CST 2017]; root of context hierarchy
2017-12-11 12:03:58,284 INFO [Thread-44] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:03:58,284 INFO [Thread-44] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:03:58,288 INFO [Thread-44] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@7d8ed5a9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:03:58,304 INFO [Thread-44]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:03:58,306 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:03:58,333 INFO [Thread-44] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:03:58,333 INFO [Thread-44] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:03:58,334 INFO [Thread-44] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:03:58,335 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:03:58,347 INFO [Thread-44]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:03:59,677 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:03:59,679 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:03:59,690 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4ba2610b: startup date [Mon Dec 11 12:03:59 CST 2017]; root of context hierarchy
2017-12-11 12:04:02,316 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:04:03,777 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:04:03,816 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4126 ms
2017-12-11 12:04:03,925 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:04:03,925 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:04:03,926 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:04:03,999 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:04:04,000 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:04:04,003 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:04:04,003 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:04:04,004 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:04:04,004 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:04:04,004 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:04:04,145 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60075.
2017-12-11 12:04:04,149 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:04:04,152 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:04:04,152 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:04:04,152 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:04:04,158 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-7dbde40e-f072-4352-bc07-53644f1904a5
2017-12-11 12:04:04,159 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:04:04,161 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:04:04,233 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:04:04,235 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @443783ms
2017-12-11 12:04:04,242 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@2fc7d4de{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:04:04,242 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:04:04,243 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@505e3d53{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,243 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12634b6a{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,244 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22061d48{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,245 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1766aa73{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,247 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ef6912b{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,247 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17cbc82d{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,248 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7056ab80{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,249 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a54f853{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,249 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d6be502{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,251 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3d8f949c{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,255 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d927ab{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,256 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1751175e{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,257 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@289fc800{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,258 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bcfb706{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,258 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33553901{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,259 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c5f6b60{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,260 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12932a89{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,263 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b25cb94{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,264 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cec0d8b{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,265 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@10275bd0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,267 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7edd1240{/static,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,269 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6bb6a5a3{/,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,270 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@111c91d2{/api,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7e4530df{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@93b8fc2{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,272 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:04:04,360 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:04:04,392 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60092.
2017-12-11 12:04:04,392 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60092
2017-12-11 12:04:04,393 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:04:04,393 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60092, None)
2017-12-11 12:04:04,394 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60092 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60092, None)
2017-12-11 12:04:04,394 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60092, None)
2017-12-11 12:04:04,395 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60092, None)
2017-12-11 12:04:04,397 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52678f13{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,402 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:04:04,402 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:04:04,404 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@50213abe{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,405 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b278ee1{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,406 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43906c5b{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,407 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c45476d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,409 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1976ae14{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:04:04,414 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:04:04,758 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:04:04,759 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:04:04,760 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:04:04,760 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:04:04,760 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:04:04,760 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:04:04,761 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:04:04,761 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:04:04,761 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:04:04,763 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:04,769 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:04:04,769 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:04:04,769 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:04:04,773 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:04,774 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:04:04,834 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:04:04,889 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4ba2610b: startup date [Mon Dec 11 12:03:59 CST 2017]; root of context hierarchy
2017-12-11 12:04:04,894 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:04,915 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:04,919 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:04:05,085 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:04:05,198 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:04:05,221 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:04:05,221 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:04:05,222 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:04:05,232 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:04:05,661 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:05,780 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:05,952 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:06,022 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:04:06,070 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:04:06,078 INFO [restartedMain]                       com.Application : Started Application in 6.591 seconds (JVM running for 445.625)
2017-12-11 12:04:25,107 INFO [Thread-64] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4ba2610b: startup date [Mon Dec 11 12:03:59 CST 2017]; root of context hierarchy
2017-12-11 12:04:25,120 INFO [Thread-64] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:04:25,121 INFO [Thread-64] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:04:25,128 INFO [Thread-64] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@2fc7d4de{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:04:25,286 INFO [Thread-64]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:04:25,292 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:04:25,432 INFO [Thread-64] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:04:25,432 INFO [Thread-64] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:04:25,432 INFO [Thread-64] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:04:25,435 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:04:25,443 INFO [Thread-64]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:04:27,035 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:04:27,035 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:04:27,046 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@24e547f8: startup date [Mon Dec 11 12:04:27 CST 2017]; root of context hierarchy
2017-12-11 12:04:28,730 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:04:29,496 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:04:29,609 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2563 ms
2017-12-11 12:04:29,694 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:04:29,694 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:04:29,694 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:04:29,757 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:04:29,759 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:04:29,760 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:04:29,760 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:04:29,761 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:04:29,761 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:04:29,761 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:04:29,775 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60121.
2017-12-11 12:04:29,778 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:04:29,780 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:04:29,781 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:04:29,781 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:04:29,786 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-01898d00-23d8-4584-84b5-1c621f76e2e7
2017-12-11 12:04:29,787 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:04:29,789 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:04:29,804 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:04:29,806 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @469353ms
2017-12-11 12:04:29,809 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@43ce6dc6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:04:29,809 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:04:29,810 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68fc8f96{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,810 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ce1bee2{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,811 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@153f14a7{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,811 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1532adce{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,815 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c33911b{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,816 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8e6d65{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,816 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@508c95f1{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,817 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@343c1a55{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,817 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@bfa4643{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,818 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d6c1443{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,819 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40bef07b{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,819 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@467c16f5{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,820 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@139177d4{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,820 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20b850ef{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,821 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@475bda54{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,822 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ad773c2{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,822 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d58df7c{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,823 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@27d979ef{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,823 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@39fa87b8{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,824 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49313f4b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6666e1bf{/static,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,825 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a3a2559{/,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,826 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6325bfea{/api,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,826 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cd7fa89{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,828 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28006762{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,828 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:04:29,872 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:04:29,884 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60139.
2017-12-11 12:04:29,884 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60139
2017-12-11 12:04:29,884 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:04:29,885 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60139, None)
2017-12-11 12:04:29,885 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60139 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60139, None)
2017-12-11 12:04:29,886 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60139, None)
2017-12-11 12:04:29,886 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60139, None)
2017-12-11 12:04:29,887 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@656509e3{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,892 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:04:29,892 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:04:29,894 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5add7a4d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,895 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@440a5744{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,896 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b597dbe{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,896 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@496c025d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,898 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2bfa568a{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:04:29,905 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:04:30,061 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:04:30,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:04:30,064 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:04:30,066 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:04:30,066 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:04:30,066 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:04:30,067 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:04:30,067 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:04:30,067 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:04:30,068 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:30,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:04:30,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:04:30,071 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:04:30,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:30,073 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:04:30,104 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:04:30,156 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@24e547f8: startup date [Mon Dec 11 12:04:27 CST 2017]; root of context hierarchy
2017-12-11 12:04:30,158 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:30,171 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:30,174 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:04:30,318 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:04:30,406 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:04:30,412 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:04:30,412 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:04:30,423 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:04:30,433 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:04:31,220 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:31,427 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:31,779 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:31,930 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:04:32,088 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:04:32,092 INFO [restartedMain]                       com.Application : Started Application in 5.156 seconds (JVM running for 471.639)
2017-12-11 12:04:51,272 INFO [Thread-80] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@24e547f8: startup date [Mon Dec 11 12:04:27 CST 2017]; root of context hierarchy
2017-12-11 12:04:51,274 INFO [Thread-80] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:04:51,275 INFO [Thread-80] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:04:51,278 INFO [Thread-80] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@43ce6dc6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:04:51,281 INFO [Thread-80]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:04:51,292 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:04:51,310 INFO [Thread-80] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:04:51,310 INFO [Thread-80] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:04:51,310 INFO [Thread-80] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:04:51,310 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:04:51,319 INFO [Thread-80]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:04:52,241 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:04:52,241 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:04:52,245 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@30655c62: startup date [Mon Dec 11 12:04:52 CST 2017]; root of context hierarchy
2017-12-11 12:04:54,484 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:04:55,225 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:04:55,293 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3048 ms
2017-12-11 12:04:55,562 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:04:55,562 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:04:55,562 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:04:55,885 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:04:55,887 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:04:55,889 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:04:55,889 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:04:55,889 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:04:55,889 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:04:55,889 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:04:56,126 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60175.
2017-12-11 12:04:56,130 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:04:56,171 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:04:56,172 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:04:56,172 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:04:56,178 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-6e8402c7-b64a-41c7-81ee-27c4940aa579
2017-12-11 12:04:56,179 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:04:56,181 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:04:56,215 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:04:56,218 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @495765ms
2017-12-11 12:04:56,222 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@4f16f675{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:04:56,222 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:04:56,223 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@71183f6{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,223 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5d6d375f{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,245 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e35eeba{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,246 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b67823e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,246 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@690bf909{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,247 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@457fbd10{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,248 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4fa87c02{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,248 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30c66ff3{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,249 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d4281bd{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,250 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68715467{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,251 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@459ac0ea{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,252 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14eacc54{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,252 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cde129b{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,253 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b0f80c8{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,953 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1886f7b1{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d41c48b{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,954 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55493c0b{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,955 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2474be41{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,956 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@29310799{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,956 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d0c4d1e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,957 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f55970c{/static,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,958 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17f1001e{/,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,959 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5086230f{/api,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,959 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@200f6a1{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,960 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6de0efeb{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:04:56,960 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:04:57,013 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:04:57,110 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60192.
2017-12-11 12:04:57,154 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60192
2017-12-11 12:04:57,154 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:04:57,156 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60192, None)
2017-12-11 12:04:57,156 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60192 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60192, None)
2017-12-11 12:04:57,157 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60192, None)
2017-12-11 12:04:57,157 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60192, None)
2017-12-11 12:04:57,159 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@713139ee{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,163 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:04:57,164 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:04:57,165 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2cb90561{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,165 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74af571c{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@16b2905a{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,167 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@371e19da{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,169 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@92eecbc{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:04:57,176 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:04:57,441 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:04:57,442 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:04:57,445 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:04:57,445 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:04:57,445 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:04:57,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:04:57,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:04:57,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:04:57,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:04:57,447 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:57,450 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:04:57,450 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:04:57,450 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:04:57,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:04:57,454 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:04:57,504 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:04:57,558 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@30655c62: startup date [Mon Dec 11 12:04:52 CST 2017]; root of context hierarchy
2017-12-11 12:04:57,563 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:57,586 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:04:57,589 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:04:57,850 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:04:57,987 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:04:57,995 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:04:57,995 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:04:57,997 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:04:58,012 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:04:58,408 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:58,839 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:04:59,405 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:00,019 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:05:00,194 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:05:00,201 INFO [restartedMain]                       com.Application : Started Application in 8.079 seconds (JVM running for 499.748)
2017-12-11 12:05:02,637 INFO [Thread-97] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@30655c62: startup date [Mon Dec 11 12:04:52 CST 2017]; root of context hierarchy
2017-12-11 12:05:02,639 INFO [Thread-97] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:05:02,639 INFO [Thread-97] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:05:02,645 INFO [Thread-97] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@4f16f675{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:05:02,663 INFO [Thread-97]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:05:02,666 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:05:02,679 INFO [Thread-97] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:05:02,679 INFO [Thread-97] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:05:02,683 INFO [Thread-97] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:05:02,687 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:05:02,693 INFO [Thread-97]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:05:04,181 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:05:04,182 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:05:04,186 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55e95595: startup date [Mon Dec 11 12:05:04 CST 2017]; root of context hierarchy
2017-12-11 12:05:07,272 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:05:08,210 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:05:08,264 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4078 ms
2017-12-11 12:05:08,367 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:05:08,368 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:05:08,368 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:05:08,428 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:05:08,429 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:05:08,430 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:05:08,430 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:05:08,430 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:05:08,431 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:05:08,431 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:05:08,440 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60218.
2017-12-11 12:05:08,443 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:05:08,444 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:05:08,444 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:05:08,444 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:05:08,448 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-e7673816-5dd9-4228-9ff4-0c9303f1fba7
2017-12-11 12:05:08,449 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:05:08,450 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:05:08,463 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:05:08,465 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @508012ms
2017-12-11 12:05:08,467 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@18994227{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:05:08,468 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:05:08,468 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@44e263c4{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,468 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c82330c{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,469 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@c0db744{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,469 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f6a22cf{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,469 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56c0f6a{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,470 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@72c4c442{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,470 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2220eab8{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,470 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d55b822{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,470 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a56ee8f{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f8c9471{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78384e8c{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1976cd91{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,472 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49dc6c23{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,472 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53ebf80d{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,472 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a7238ff{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,473 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fc036aa{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,473 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b798f86{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,474 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7a6013b8{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,474 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@420fce67{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,474 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@44986f9f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@569c0ebd{/static,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@159535f1{/,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,475 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2dd38daf{/api,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,476 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f565caf{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,476 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@776faa93{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,476 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:05:08,501 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:05:08,508 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60235.
2017-12-11 12:05:08,508 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60235
2017-12-11 12:05:08,508 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:05:08,508 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60235, None)
2017-12-11 12:05:08,509 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60235 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60235, None)
2017-12-11 12:05:08,509 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60235, None)
2017-12-11 12:05:08,509 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60235, None)
2017-12-11 12:05:08,510 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3727611e{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,514 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:05:08,514 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:05:08,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fcdf150{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,515 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1cf176df{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,516 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19b5e1c2{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,516 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@692d0820{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,518 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9c49f12{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:05:08,522 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:05:08,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:05:08,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:05:08,611 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:05:08,611 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:05:08,611 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:05:08,611 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:05:08,611 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:05:08,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:05:08,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:05:08,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:05:08,613 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:05:08,614 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:05:08,614 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:05:08,616 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:05:08,616 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:05:08,642 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:05:08,671 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55e95595: startup date [Mon Dec 11 12:05:04 CST 2017]; root of context hierarchy
2017-12-11 12:05:08,675 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:05:08,687 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:05:08,689 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:05:08,872 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:05:08,944 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:05:08,947 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:05:08,948 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:05:08,949 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:05:08,956 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:05:09,138 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:09,232 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:09,427 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:09,487 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:05:09,544 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:05:09,554 INFO [restartedMain]                       com.Application : Started Application in 5.508 seconds (JVM running for 509.101)
2017-12-11 12:05:17,490 INFO [Thread-117] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55e95595: startup date [Mon Dec 11 12:05:04 CST 2017]; root of context hierarchy
2017-12-11 12:05:17,492 INFO [Thread-117] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:05:17,492 INFO [Thread-117] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:05:17,495 INFO [Thread-117] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@18994227{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:05:17,496 INFO [Thread-117]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:05:17,498 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:05:17,510 INFO [Thread-117] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:05:17,511 INFO [Thread-117] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:05:17,511 INFO [Thread-117] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:05:17,512 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:05:17,518 INFO [Thread-117]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 12:05:18,698 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14196 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 12:05:18,698 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 12:05:18,703 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@12208aaf: startup date [Mon Dec 11 12:05:18 CST 2017]; root of context hierarchy
2017-12-11 12:05:20,812 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 12:05:21,836 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 12:05:21,882 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3179 ms
2017-12-11 12:05:21,964 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 12:05:21,964 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 12:05:21,964 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 12:05:22,096 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 12:05:22,098 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 12:05:22,100 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 12:05:22,100 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 12:05:22,100 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 12:05:22,100 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 12:05:22,100 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 12:05:22,127 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 60266.
2017-12-11 12:05:22,130 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 12:05:22,133 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 12:05:22,134 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 12:05:22,134 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 12:05:22,142 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-f0aaaa93-17db-4f09-b941-0334ec36e9af
2017-12-11 12:05:22,143 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 12:05:22,145 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 12:05:22,159 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 12:05:22,161 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @521709ms
2017-12-11 12:05:22,165 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@71bc8d97{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:05:22,165 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 12:05:22,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@402d0ed3{/jobs,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,166 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@15aa7c8{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,167 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c6c8d97{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,167 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33331e8a{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,168 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@588f1ef{/stages,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,168 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55164729{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,169 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c270a21{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,169 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3341d7f{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,170 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6d62f9c0{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,170 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4be920b3{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,171 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2cb41682{/storage,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,171 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e36b9e0{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,172 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2657ef7f{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,172 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56050158{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,173 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3afbf645{/environment,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,173 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@731f74f3{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,173 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@43e284ff{/executors,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,174 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@339a6c2d{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,174 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@32add338{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,175 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@380c7616{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,176 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7af5cbf5{/static,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,177 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45f0417e{/,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,177 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@589accc7{/api,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,178 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ac9bddd{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,179 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f797b8a{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,179 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 12:05:22,235 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 12:05:22,247 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60283.
2017-12-11 12:05:22,247 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:60283
2017-12-11 12:05:22,248 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 12:05:22,248 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 60283, None)
2017-12-11 12:05:22,248 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:60283 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 60283, None)
2017-12-11 12:05:22,249 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 60283, None)
2017-12-11 12:05:22,250 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 60283, None)
2017-12-11 12:05:22,251 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e5841dd{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,257 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 12:05:22,257 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 12:05:22,258 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d2fcb7b{/SQL,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,259 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d0d1f04{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,260 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@500ce22c{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,260 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f27d71d{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,261 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@59efdb78{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 12:05:22,265 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 12:05:22,576 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 12:05:22,577 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 12:05:22,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 12:05:22,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 12:05:22,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 12:05:22,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 12:05:22,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 12:05:22,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 12:05:22,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 12:05:22,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 12:05:22,608 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 12:05:22,609 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 12:05:22,609 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 12:05:22,614 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 12:05:22,614 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 12:05:22,713 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 12:05:22,755 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@12208aaf: startup date [Mon Dec 11 12:05:18 CST 2017]; root of context hierarchy
2017-12-11 12:05:22,763 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:05:22,777 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 12:05:22,783 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 12:05:22,989 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 12:05:23,076 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 12:05:23,087 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 12:05:23,088 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 12:05:23,098 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 12:05:23,114 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 12:05:23,640 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:23,885 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:24,530 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 12:05:24,794 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 12:05:24,834 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 12:05:24,839 INFO [restartedMain]                       com.Application : Started Application in 6.265 seconds (JVM running for 524.386)
2017-12-11 12:09:49,831 INFO [Thread-134] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@12208aaf: startup date [Mon Dec 11 12:05:18 CST 2017]; root of context hierarchy
2017-12-11 12:09:49,836 INFO [Thread-134] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 12:09:49,836 INFO [Thread-134] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 12:09:49,843 INFO [Thread-134] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@71bc8d97{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 12:09:49,850 INFO [Thread-134]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 12:09:49,863 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 12:09:49,922 INFO [Thread-134] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 12:09:49,922 INFO [Thread-134] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 12:09:49,923 INFO [Thread-134] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 12:09:49,924 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 12:09:49,949 INFO [Thread-134]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 14:14:00,412 INFO [main]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:14:16,456 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 6388 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:14:16,464 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:14:17,309 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@db93c8c: startup date [Mon Dec 11 14:14:17 CST 2017]; root of context hierarchy
2017-12-11 14:14:17,555 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 14:14:23,134 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:14:24,801 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:14:25,403 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 8101 ms
2017-12-11 14:14:25,707 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:14:25,716 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:14:25,717 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:14:25,894 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'algorithmRestControl': Unsatisfied dependency expressed through field 'wordCountServiceJava'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.apache.spark.api.java.JavaSparkContext' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2017-12-11 14:14:26,013 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:14:26,685 ERROR [restartedMain] org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter : 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field sc in com.spark.service.WordCountServiceJava required a bean of type 'org.apache.spark.api.java.JavaSparkContext' that could not be found.


Action:

Consider defining a bean of type 'org.apache.spark.api.java.JavaSparkContext' in your configuration.

2017-12-11 14:15:12,880 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 15236 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:15:12,882 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:15:14,098 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@aa6e92c: startup date [Mon Dec 11 14:15:14 CST 2017]; root of context hierarchy
2017-12-11 14:15:14,220 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 14:15:18,275 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:15:20,446 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:15:21,589 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7500 ms
2017-12-11 14:15:22,531 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:15:22,555 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:15:22,557 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:15:22,791 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'algorithmRestControl': Unsatisfied dependency expressed through field 'wordCountServiceJava'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.apache.spark.api.java.JavaSparkContext' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2017-12-11 14:15:22,847 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:15:23,316 ERROR [restartedMain] org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter : 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field sc in com.spark.service.WordCountServiceJava required a bean of type 'org.apache.spark.api.java.JavaSparkContext' that could not be found.


Action:

Consider defining a bean of type 'org.apache.spark.api.java.JavaSparkContext' in your configuration.

2017-12-11 14:24:21,473 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:24:21,477 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:24:22,408 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f8b4a3: startup date [Mon Dec 11 14:24:22 CST 2017]; root of context hierarchy
2017-12-11 14:24:22,633 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 14:24:26,934 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:24:28,867 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:24:29,429 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 7034 ms
2017-12-11 14:24:29,834 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:24:29,849 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:24:29,849 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:24:30,842 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:24:31,231 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 14:24:31,417 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at com.spark.config.SparkConfig.getJavaSparkContext(SparkConfig.scala:36)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getJavaSparkContext$6(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getJavaSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 14:24:31,620 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:24:31,716 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:24:31,719 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:24:31,720 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:24:31,721 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:24:31,729 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:24:32,745 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62083.
2017-12-11 14:24:32,774 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:24:32,802 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:24:32,806 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:24:32,806 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:24:32,825 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-2d3abdcf-ba92-4614-b57d-cdc2cd5248b5
2017-12-11 14:24:32,857 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:24:32,966 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:24:33,130 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @17299ms
2017-12-11 14:24:33,246 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:24:33,269 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @17444ms
2017-12-11 14:24:33,299 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@7b8dabd2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:24:33,299 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:24:33,346 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@315552d2{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,347 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2022b6a5{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,348 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@14b57eac{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,350 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a30a8e0{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,353 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5fba0876{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,355 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f7c6051{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,356 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3ab76897{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,360 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e7c3c94{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,361 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46cc3cef{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,362 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@569b66af{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,364 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c7e87fe{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,365 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b676997{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,366 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@f495682{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,370 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f39ca9e{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,371 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ec20ec1{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,373 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@310bc082{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,374 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31b60481{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,375 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e4b56e{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,377 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@592c2816{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,379 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30b21468{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,394 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d90fa19{/static,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,396 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4b0e092e{/,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,398 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78b66e8{/api,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,400 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d374c6b{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,401 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@25224e07{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,405 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:24:33,645 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:24:33,688 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62101.
2017-12-11 14:24:33,689 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62101
2017-12-11 14:24:33,691 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:24:33,694 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62101, None)
2017-12-11 14:24:33,700 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62101 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62101, None)
2017-12-11 14:24:33,707 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62101, None)
2017-12-11 14:24:33,708 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62101, None)
2017-12-11 14:24:33,747 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49876d41{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:33,990 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-11 14:24:34,157 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:24:34,161 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:24:34,177 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f68b933{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:24:34,178 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c701692{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:34,181 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@596c92ad{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:24:34,184 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fd4cf5c{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:24:34,189 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5df86da9{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:24:35,351 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 14:24:35,652 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:24:36,495 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 14:24:36,497 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 14:24:36,497 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/wordCountServiceJava],methods=[GET]}" onto public java.util.Map<java.lang.String, java.lang.Integer> com.spark.control.AlgorithmRestControl.getWordCountServiceJava()
2017-12-11 14:24:36,500 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 14:24:36,501 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 14:24:36,501 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 14:24:36,502 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 14:24:36,502 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 14:24:36,502 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 14:24:36,503 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 14:24:36,505 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 14:24:36,519 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 14:24:36,520 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 14:24:36,522 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 14:24:36,540 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 14:24:36,541 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 14:24:36,920 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 14:24:37,062 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f8b4a3: startup date [Mon Dec 11 14:24:22 CST 2017]; root of context hierarchy
2017-12-11 14:24:37,077 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:24:37,195 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:24:37,230 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:24:41,420 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 14:24:41,673 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 14:24:41,705 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 14:24:41,706 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 14:24:41,797 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 14:24:41,874 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 14:24:43,472 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:24:43,781 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:24:44,218 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:24:44,341 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 14:24:44,542 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 14:24:44,558 INFO [restartedMain]                       com.Application : Started Application in 24.539 seconds (JVM running for 28.733)
2017-12-11 14:24:48,549 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 14:24:48,550 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 14:24:48,623 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 73 ms
2017-12-11 14:24:48,647 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:48,750 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 14:24:48,931 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 14:24:48,931 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 14:24:48,932 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 14:24:48,932 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 14:24:48,943 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XHTML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XML
[THYMELEAF]     * VALIDXML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 14:24:48,943 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 14:24:49,295 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,306 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,292 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,333 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,336 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,302 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,298 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,357 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,345 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,328 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,326 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,322 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:49,319 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:50,183 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:24:50,355 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,713 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,764 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,765 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,766 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,777 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,780 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,784 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,787 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,792 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,793 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,805 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,805 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,805 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:11,805 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:12,337 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:12,451 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:12,571 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:25:12,585 WARN [http-nio-8080-exec-6] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 14:26:15,995 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,036 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,038 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,044 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,045 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,049 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,045 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,045 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,045 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,050 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,065 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,075 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,079 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,082 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,495 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:26:16,595 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:27:14,083 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:27:14,387 INFO [http-nio-8080-exec-7]         org.apache.spark.SparkContext : Starting job: count at WordCountServiceJava.java:39
2017-12-11 14:27:14,404 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 0 (count at WordCountServiceJava.java:39) with 3 output partitions
2017-12-11 14:27:14,404 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 0 (count at WordCountServiceJava.java:39)
2017-12-11 14:27:14,405 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List()
2017-12-11 14:27:14,409 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List()
2017-12-11 14:27:14,414 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at WordCountServiceJava.java:29), which has no missing parents
2017-12-11 14:27:14,507 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 898.5 MB)
2017-12-11 14:27:14,663 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 898.5 MB)
2017-12-11 14:27:14,670 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added broadcast_0_piece0 in memory on 192.168.211.1:62101 (size: 1006.0 B, free: 898.5 MB)
2017-12-11 14:27:14,675 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:14,701 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at WordCountServiceJava.java:29) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:14,702 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 0.0 with 3 tasks
2017-12-11 14:27:14,755 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:27:14,758 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:27:14,760 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 4843 bytes)
2017-12-11 14:27:14,772 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Running task 0.0 in stage 0.0 (TID 0)
2017-12-11 14:27:14,772 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Running task 2.0 in stage 0.0 (TID 2)
2017-12-11 14:27:14,772 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Running task 1.0 in stage 0.0 (TID 1)
2017-12-11 14:27:14,932 INFO [Executor task launch worker for task 0] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:27:14,932 INFO [Executor task launch worker for task 2] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_2 stored as values in memory (estimated size 96.0 B, free 898.5 MB)
2017-12-11 14:27:14,933 INFO [Executor task launch worker for task 1] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:27:14,934 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_0 in memory on 192.168.211.1:62101 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:27:14,937 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_2 in memory on 192.168.211.1:62101 (size: 96.0 B, free: 898.5 MB)
2017-12-11 14:27:14,938 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_1 in memory on 192.168.211.1:62101 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:27:14,985 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 0.0 (TID 1). 1400 bytes result sent to driver
2017-12-11 14:27:14,985 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 0.0 (TID 2). 1443 bytes result sent to driver
2017-12-11 14:27:14,989 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
2017-12-11 14:27:15,005 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 0.0 (TID 1) in 245 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:15,010 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 0.0 (TID 0) in 275 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:15,016 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 0.0 (TID 2) in 257 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:15,028 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 0 (count at WordCountServiceJava.java:39) finished in 0.305 s
2017-12-11 14:27:15,020 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-12-11 14:27:15,044 INFO [http-nio-8080-exec-7] org.apache.spark.scheduler.DAGScheduler : Job 0 finished: count at WordCountServiceJava.java:39, took 0.657335 s
2017-12-11 14:27:15,181 INFO [http-nio-8080-exec-7]         org.apache.spark.SparkContext : Starting job: collect at WordCountServiceJava.java:66
2017-12-11 14:27:15,198 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Registering RDD 3 (mapToPair at WordCountServiceJava.java:48)
2017-12-11 14:27:15,201 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 1 (collect at WordCountServiceJava.java:66) with 3 output partitions
2017-12-11 14:27:15,201 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 2 (collect at WordCountServiceJava.java:66)
2017-12-11 14:27:15,201 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List(ShuffleMapStage 1)
2017-12-11 14:27:15,204 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List(ShuffleMapStage 1)
2017-12-11 14:27:15,215 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at WordCountServiceJava.java:48), which has no missing parents
2017-12-11 14:27:15,258 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1 stored as values in memory (estimated size 3.7 KB, free 898.5 MB)
2017-12-11 14:27:15,269 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 898.5 MB)
2017-12-11 14:27:15,271 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo : Added broadcast_1_piece0 in memory on 192.168.211.1:62101 (size: 2.1 KB, free: 898.5 MB)
2017-12-11 14:27:15,273 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:15,278 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at WordCountServiceJava.java:48) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:15,278 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 1.0 with 3 tasks
2017-12-11 14:27:15,289 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 1.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:27:15,290 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 1.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:27:15,292 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 1.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 4832 bytes)
2017-12-11 14:27:15,293 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Running task 0.0 in stage 1.0 (TID 3)
2017-12-11 14:27:15,295 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Running task 1.0 in stage 1.0 (TID 4)
2017-12-11 14:27:15,295 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Running task 2.0 in stage 1.0 (TID 5)
2017-12-11 14:27:15,316 INFO [Executor task launch worker for task 4] org.apache.spark.storage.BlockManager : Found block rdd_0_1 locally
2017-12-11 14:27:15,318 INFO [Executor task launch worker for task 3] org.apache.spark.storage.BlockManager : Found block rdd_0_0 locally
2017-12-11 14:27:15,318 INFO [Executor task launch worker for task 5] org.apache.spark.storage.BlockManager : Found block rdd_0_2 locally
2017-12-11 14:27:15,409 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 1.0 (TID 4). 1027 bytes result sent to driver
2017-12-11 14:27:15,415 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 1.0 (TID 5). 1113 bytes result sent to driver
2017-12-11 14:27:15,423 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 1.0 (TID 5) in 132 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:15,427 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 1.0 (TID 3). 941 bytes result sent to driver
2017-12-11 14:27:15,439 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 1.0 (TID 4) in 150 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:15,441 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 1.0 (TID 3) in 157 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:15,441 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-12-11 14:27:15,444 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ShuffleMapStage 1 (mapToPair at WordCountServiceJava.java:48) finished in 0.161 s
2017-12-11 14:27:15,448 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : looking for newly runnable stages
2017-12-11 14:27:15,450 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : running: Set()
2017-12-11 14:27:15,451 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : waiting: Set(ResultStage 2)
2017-12-11 14:27:15,452 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : failed: Set()
2017-12-11 14:27:15,461 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at WordCountServiceJava.java:57), which has no missing parents
2017-12-11 14:27:15,473 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 898.5 MB)
2017-12-11 14:27:15,478 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_2_piece0 stored as bytes in memory (estimated size 1897.0 B, free 898.5 MB)
2017-12-11 14:27:15,485 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo : Added broadcast_2_piece0 in memory on 192.168.211.1:62101 (size: 1897.0 B, free: 898.5 MB)
2017-12-11 14:27:15,487 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:15,490 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at WordCountServiceJava.java:57) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:15,490 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 2.0 with 3 tasks
2017-12-11 14:27:15,500 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 2.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
2017-12-11 14:27:15,501 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 2.0 (TID 7, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-12-11 14:27:15,503 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 2.0 (TID 8, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-12-11 14:27:15,504 INFO [Executor task launch worker for task 6]    org.apache.spark.executor.Executor : Running task 2.0 in stage 2.0 (TID 6)
2017-12-11 14:27:15,504 INFO [Executor task launch worker for task 8]    org.apache.spark.executor.Executor : Running task 1.0 in stage 2.0 (TID 8)
2017-12-11 14:27:15,504 INFO [Executor task launch worker for task 7]    org.apache.spark.executor.Executor : Running task 0.0 in stage 2.0 (TID 7)
2017-12-11 14:27:15,560 INFO [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:27:15,560 INFO [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 0 non-empty blocks out of 3 blocks
2017-12-11 14:27:15,560 INFO [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:27:15,567 INFO [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 14 ms
2017-12-11 14:27:15,568 INFO [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 15 ms
2017-12-11 14:27:15,588 INFO [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 15 ms
2017-12-11 14:27:15,600 INFO [Executor task launch worker for task 6]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 2.0 (TID 6). 1091 bytes result sent to driver
2017-12-11 14:27:15,603 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 2.0 (TID 6) in 110 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:15,613 INFO [Executor task launch worker for task 7]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 2.0 (TID 7). 1237 bytes result sent to driver
2017-12-11 14:27:15,615 INFO [Executor task launch worker for task 8]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 2.0 (TID 8). 1252 bytes result sent to driver
2017-12-11 14:27:15,618 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 2.0 (TID 7) in 117 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:15,619 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 2.0 (TID 8) in 116 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:15,619 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-12-11 14:27:15,626 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 2 (collect at WordCountServiceJava.java:66) finished in 0.132 s
2017-12-11 14:27:15,629 INFO [http-nio-8080-exec-7] org.apache.spark.scheduler.DAGScheduler : Job 1 finished: collect at WordCountServiceJava.java:66, took 0.447570 s
2017-12-11 14:27:35,510 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:27:35,525 INFO [http-nio-8080-exec-4]         org.apache.spark.SparkContext : Starting job: count at WordCountServiceJava.java:39
2017-12-11 14:27:35,526 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 2 (count at WordCountServiceJava.java:39) with 3 output partitions
2017-12-11 14:27:35,526 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 3 (count at WordCountServiceJava.java:39)
2017-12-11 14:27:35,526 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List()
2017-12-11 14:27:35,531 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List()
2017-12-11 14:27:35,531 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 3 (ParallelCollectionRDD[5] at parallelize at WordCountServiceJava.java:29), which has no missing parents
2017-12-11 14:27:35,534 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_3 stored as values in memory (estimated size 1448.0 B, free 898.5 MB)
2017-12-11 14:27:35,544 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_3_piece0 stored as bytes in memory (estimated size 1010.0 B, free 898.5 MB)
2017-12-11 14:27:35,548 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerInfo : Added broadcast_3_piece0 in memory on 192.168.211.1:62101 (size: 1010.0 B, free: 898.5 MB)
2017-12-11 14:27:35,552 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:35,562 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 3 (ParallelCollectionRDD[5] at parallelize at WordCountServiceJava.java:29) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:35,562 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 3.0 with 3 tasks
2017-12-11 14:27:35,565 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:27:35,566 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:27:35,566 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 4843 bytes)
2017-12-11 14:27:35,567 INFO [Executor task launch worker for task 9]    org.apache.spark.executor.Executor : Running task 0.0 in stage 3.0 (TID 9)
2017-12-11 14:27:35,567 INFO [Executor task launch worker for task 10]    org.apache.spark.executor.Executor : Running task 1.0 in stage 3.0 (TID 10)
2017-12-11 14:27:35,567 INFO [Executor task launch worker for task 11]    org.apache.spark.executor.Executor : Running task 2.0 in stage 3.0 (TID 11)
2017-12-11 14:27:35,576 INFO [Executor task launch worker for task 9] org.apache.spark.storage.memory.MemoryStore : Block rdd_5_0 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:27:35,577 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added rdd_5_0 in memory on 192.168.211.1:62101 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:27:35,578 INFO [Executor task launch worker for task 11] org.apache.spark.storage.memory.MemoryStore : Block rdd_5_2 stored as values in memory (estimated size 96.0 B, free 898.5 MB)
2017-12-11 14:27:35,578 INFO [Executor task launch worker for task 10] org.apache.spark.storage.memory.MemoryStore : Block rdd_5_1 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:27:35,578 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo : Added rdd_5_2 in memory on 192.168.211.1:62101 (size: 96.0 B, free: 898.5 MB)
2017-12-11 14:27:35,579 INFO [Executor task launch worker for task 9]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 3.0 (TID 9). 1400 bytes result sent to driver
2017-12-11 14:27:35,579 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo : Added rdd_5_1 in memory on 192.168.211.1:62101 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:27:35,582 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 3.0 (TID 9) in 19 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:35,582 INFO [Executor task launch worker for task 10]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 3.0 (TID 10). 1357 bytes result sent to driver
2017-12-11 14:27:35,583 INFO [Executor task launch worker for task 11]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 3.0 (TID 11). 1357 bytes result sent to driver
2017-12-11 14:27:35,585 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 3.0 (TID 10) in 20 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:35,588 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 3.0 (TID 11) in 21 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:35,589 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2017-12-11 14:27:35,591 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 3 (count at WordCountServiceJava.java:39) finished in 0.027 s
2017-12-11 14:27:35,592 INFO [http-nio-8080-exec-4] org.apache.spark.scheduler.DAGScheduler : Job 2 finished: count at WordCountServiceJava.java:39, took 0.066602 s
2017-12-11 14:27:35,613 INFO [http-nio-8080-exec-4]         org.apache.spark.SparkContext : Starting job: collect at WordCountServiceJava.java:66
2017-12-11 14:27:35,614 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Registering RDD 8 (mapToPair at WordCountServiceJava.java:48)
2017-12-11 14:27:35,615 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 3 (collect at WordCountServiceJava.java:66) with 3 output partitions
2017-12-11 14:27:35,615 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 5 (collect at WordCountServiceJava.java:66)
2017-12-11 14:27:35,615 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List(ShuffleMapStage 4)
2017-12-11 14:27:35,615 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List(ShuffleMapStage 4)
2017-12-11 14:27:35,617 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ShuffleMapStage 4 (MapPartitionsRDD[8] at mapToPair at WordCountServiceJava.java:48), which has no missing parents
2017-12-11 14:27:35,621 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 898.5 MB)
2017-12-11 14:27:35,627 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 898.5 MB)
2017-12-11 14:27:35,628 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerInfo : Added broadcast_4_piece0 in memory on 192.168.211.1:62101 (size: 2.1 KB, free: 898.5 MB)
2017-12-11 14:27:35,629 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:35,630 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[8] at mapToPair at WordCountServiceJava.java:48) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:35,630 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 4.0 with 3 tasks
2017-12-11 14:27:35,632 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 4.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:27:35,632 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 4.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:27:35,634 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 4.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 4832 bytes)
2017-12-11 14:27:35,634 INFO [Executor task launch worker for task 12]    org.apache.spark.executor.Executor : Running task 0.0 in stage 4.0 (TID 12)
2017-12-11 14:27:35,634 INFO [Executor task launch worker for task 14]    org.apache.spark.executor.Executor : Running task 2.0 in stage 4.0 (TID 14)
2017-12-11 14:27:35,634 INFO [Executor task launch worker for task 13]    org.apache.spark.executor.Executor : Running task 1.0 in stage 4.0 (TID 13)
2017-12-11 14:27:35,639 INFO [Executor task launch worker for task 12] org.apache.spark.storage.BlockManager : Found block rdd_5_0 locally
2017-12-11 14:27:35,639 INFO [Executor task launch worker for task 14] org.apache.spark.storage.BlockManager : Found block rdd_5_2 locally
2017-12-11 14:27:35,640 INFO [Executor task launch worker for task 13] org.apache.spark.storage.BlockManager : Found block rdd_5_1 locally
2017-12-11 14:27:35,665 INFO [Executor task launch worker for task 12]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 4.0 (TID 12). 941 bytes result sent to driver
2017-12-11 14:27:35,666 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 4.0 (TID 12) in 35 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:35,681 INFO [Executor task launch worker for task 14]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 4.0 (TID 14). 1070 bytes result sent to driver
2017-12-11 14:27:35,682 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 4.0 (TID 14) in 50 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:35,691 INFO [Executor task launch worker for task 13]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 4.0 (TID 13). 941 bytes result sent to driver
2017-12-11 14:27:35,692 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 4.0 (TID 13) in 60 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:35,692 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2017-12-11 14:27:35,693 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ShuffleMapStage 4 (mapToPair at WordCountServiceJava.java:48) finished in 0.062 s
2017-12-11 14:27:35,694 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : looking for newly runnable stages
2017-12-11 14:27:35,694 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : running: Set()
2017-12-11 14:27:35,694 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : waiting: Set(ResultStage 5)
2017-12-11 14:27:35,694 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : failed: Set()
2017-12-11 14:27:35,697 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 5 (ShuffledRDD[9] at reduceByKey at WordCountServiceJava.java:57), which has no missing parents
2017-12-11 14:27:35,701 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 898.5 MB)
2017-12-11 14:27:35,708 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_5_piece0 stored as bytes in memory (estimated size 1898.0 B, free 898.5 MB)
2017-12-11 14:27:35,709 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerInfo : Added broadcast_5_piece0 in memory on 192.168.211.1:62101 (size: 1898.0 B, free: 898.5 MB)
2017-12-11 14:27:35,710 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:27:35,711 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 5 (ShuffledRDD[9] at reduceByKey at WordCountServiceJava.java:57) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:27:35,712 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 5.0 with 3 tasks
2017-12-11 14:27:35,713 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 5.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
2017-12-11 14:27:35,714 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 5.0 (TID 16, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-12-11 14:27:35,714 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 5.0 (TID 17, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-12-11 14:27:35,715 INFO [Executor task launch worker for task 15]    org.apache.spark.executor.Executor : Running task 2.0 in stage 5.0 (TID 15)
2017-12-11 14:27:35,715 INFO [Executor task launch worker for task 16]    org.apache.spark.executor.Executor : Running task 0.0 in stage 5.0 (TID 16)
2017-12-11 14:27:35,716 INFO [Executor task launch worker for task 17]    org.apache.spark.executor.Executor : Running task 1.0 in stage 5.0 (TID 17)
2017-12-11 14:27:35,725 INFO [Executor task launch worker for task 15] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 0 non-empty blocks out of 3 blocks
2017-12-11 14:27:35,725 INFO [Executor task launch worker for task 15] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 1 ms
2017-12-11 14:27:35,725 INFO [Executor task launch worker for task 16] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:27:35,725 INFO [Executor task launch worker for task 16] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 0 ms
2017-12-11 14:27:35,727 INFO [Executor task launch worker for task 15]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 5.0 (TID 15). 1005 bytes result sent to driver
2017-12-11 14:27:35,733 INFO [Executor task launch worker for task 16]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 5.0 (TID 16). 1237 bytes result sent to driver
2017-12-11 14:27:35,740 INFO [Executor task launch worker for task 17] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:27:35,741 INFO [Executor task launch worker for task 17] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 1 ms
2017-12-11 14:27:35,751 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 5.0 (TID 15) in 39 ms on localhost (executor driver) (1/3)
2017-12-11 14:27:35,753 INFO [Executor task launch worker for task 17]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 5.0 (TID 17). 1166 bytes result sent to driver
2017-12-11 14:27:35,753 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 5.0 (TID 16) in 39 ms on localhost (executor driver) (2/3)
2017-12-11 14:27:35,757 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 5.0 (TID 17) in 43 ms on localhost (executor driver) (3/3)
2017-12-11 14:27:35,757 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2017-12-11 14:27:35,760 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 5 (collect at WordCountServiceJava.java:66) finished in 0.047 s
2017-12-11 14:27:35,770 INFO [http-nio-8080-exec-4] org.apache.spark.scheduler.DAGScheduler : Job 3 finished: collect at WordCountServiceJava.java:66, took 0.156776 s
2017-12-11 14:28:38,193 INFO [Thread-18] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6f8b4a3: startup date [Mon Dec 11 14:24:22 CST 2017]; root of context hierarchy
2017-12-11 14:28:38,196 INFO [Thread-18] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 14:28:38,198 INFO [Thread-18] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 14:28:38,210 INFO [Thread-18] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@7b8dabd2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:28:38,215 INFO [Thread-18]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 14:28:38,236 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 14:28:38,858 INFO [Thread-18] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 14:28:38,859 INFO [Thread-18] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 14:28:38,864 INFO [Thread-18] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 14:28:38,870 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 14:28:38,948 INFO [Thread-18]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 14:28:39,012 INFO [Thread-18]         org.apache.spark.SparkContext : SparkContext already stopped.
2017-12-11 14:28:39,913 INFO [Thread-18] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 14:28:39,997 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 14:28:40,041 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 14:28:40,904 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:28:40,905 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:28:40,961 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1c17efe1: startup date [Mon Dec 11 14:28:40 CST 2017]; root of context hierarchy
2017-12-11 14:28:44,449 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:28:46,402 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:28:46,534 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5573 ms
2017-12-11 14:28:46,787 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:28:46,788 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:28:46,788 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:28:47,020 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'algorithmRestControl' defined in file [D:\SparkVisualMl\target\classes\com\spark\control\AlgorithmRestControl.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
2017-12-11 14:28:47,043 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:28:47,054 ERROR [restartedMain] org.springframework.boot.SpringApplication : Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'algorithmRestControl' defined in file [D:\SparkVisualMl\target\classes\com\spark\control\AlgorithmRestControl.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:526)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:344)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessMergedBeanDefinition(CommonAnnotationBeanPostProcessor.java:297)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyMergedBeanDefinitionPostProcessors(AbstractAutowireCapableBeanFactory.java:992)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:523)
	... 20 more
Caused by: java.lang.NoClassDefFoundError: Lcom/spark/service/WordCountServiceJava;
	at java.lang.Class.getDeclaredFields0(Native Method)
	at java.lang.Class.privateGetDeclaredFields(Class.java:2583)
	at java.lang.Class.getDeclaredFields(Class.java:1916)
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:715)
	at org.springframework.util.ReflectionUtils.doWithLocalFields(ReflectionUtils.java:656)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.buildResourceMetadata(CommonAnnotationBeanPostProcessor.java:361)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:340)
	... 23 more
Caused by: java.lang.ClassNotFoundException: com.spark.service.WordCountServiceJava
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:151)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 30 more
2017-12-11 14:29:15,483 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:29:15,487 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:29:15,500 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@39fa465b: startup date [Mon Dec 11 14:29:15 CST 2017]; root of context hierarchy
2017-12-11 14:29:18,470 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:29:23,553 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:29:23,787 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 8287 ms
2017-12-11 14:29:23,889 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:29:23,890 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:29:23,890 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:29:24,258 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:29:24,260 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:29:24,261 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:29:24,261 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:29:24,261 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:29:24,261 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:29:24,262 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:29:24,364 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62229.
2017-12-11 14:29:24,369 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:29:24,370 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:29:24,378 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:29:24,378 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:29:24,394 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-9fc99f1d-59d2-4ef6-bac3-52d1f24004d5
2017-12-11 14:29:24,397 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:29:24,407 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:29:24,432 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:29:24,434 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @308609ms
2017-12-11 14:29:24,442 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@4dd1c5a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:29:24,442 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:29:24,444 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@356e4c69{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67b92e2b{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,446 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63cc1654{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,447 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@52a4b5a9{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4516f7a8{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ee50bf5{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,449 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3374cc9b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,451 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@33816e72{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,452 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@9435774{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,453 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f9678a1{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,453 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2216ff54{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,454 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4af75e00{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,455 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11a0a07{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,458 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@54c8268c{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,459 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ce5db24{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,460 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4636cc9f{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,461 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4cbbfd24{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,462 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@140f3caf{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,463 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4015684d{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,464 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@230500ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,467 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3cf7ee2c{/static,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,468 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c192414{/,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,469 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@65410996{/api,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,470 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f361aa4{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,471 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5f976161{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,472 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:29:24,531 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:29:24,554 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62246.
2017-12-11 14:29:24,554 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62246
2017-12-11 14:29:24,555 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:29:24,555 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62246, None)
2017-12-11 14:29:24,556 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62246 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62246, None)
2017-12-11 14:29:24,557 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62246, None)
2017-12-11 14:29:24,558 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62246, None)
2017-12-11 14:29:24,560 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5765757e{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,581 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-11 14:29:24,582 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:29:24,582 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:29:24,584 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6514eeba{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,585 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b3f7e8b{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,590 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@20cc25d7{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,591 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@590c487b{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,597 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5feff49e{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:29:24,611 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:29:24,934 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 14:29:24,934 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 14:29:24,935 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/wordCountServiceJava],methods=[GET]}" onto public java.util.Map<java.lang.String, java.lang.Integer> com.spark.control.AlgorithmRestControl.getWordCountServiceJava()
2017-12-11 14:29:24,936 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 14:29:24,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 14:29:24,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 14:29:24,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 14:29:24,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 14:29:24,937 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 14:29:24,938 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 14:29:24,938 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 14:29:24,955 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 14:29:24,955 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 14:29:24,956 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 14:29:24,990 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 14:29:24,991 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 14:29:25,105 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 14:29:25,200 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@39fa465b: startup date [Mon Dec 11 14:29:15 CST 2017]; root of context hierarchy
2017-12-11 14:29:25,211 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:29:25,265 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:29:25,273 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:29:25,678 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 14:29:25,832 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 14:29:25,844 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 14:29:25,844 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 14:29:25,848 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 14:29:25,858 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 14:29:26,218 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:29:26,300 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:29:26,504 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:29:26,562 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 14:29:26,595 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 14:29:26,600 INFO [restartedMain]                       com.Application : Started Application in 11.269 seconds (JVM running for 310.775)
2017-12-11 14:29:28,584 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@39fa465b: startup date [Mon Dec 11 14:29:15 CST 2017]; root of context hierarchy
2017-12-11 14:29:28,590 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 14:29:28,590 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 14:29:28,595 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@4dd1c5a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:29:28,611 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 14:29:28,613 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 14:29:28,627 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 14:29:28,627 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 14:29:28,628 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 14:29:28,658 INFO [dispatcher-event-loop-2] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 14:29:28,666 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 14:29:28,765 INFO [Thread-22]         org.apache.spark.SparkContext : SparkContext already stopped.
2017-12-11 14:29:31,230 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:29:31,230 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:29:31,236 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@26cf7e16: startup date [Mon Dec 11 14:29:31 CST 2017]; root of context hierarchy
2017-12-11 14:29:35,518 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:29:37,074 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:29:37,121 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 5885 ms
2017-12-11 14:29:37,628 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:29:37,630 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:29:37,631 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:29:37,712 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'algorithmRestControl' defined in file [D:\SparkVisualMl\target\classes\com\spark\control\AlgorithmRestControl.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
2017-12-11 14:29:37,923 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:29:37,929 ERROR [restartedMain] org.springframework.boot.SpringApplication : Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'algorithmRestControl' defined in file [D:\SparkVisualMl\target\classes\com\spark\control\AlgorithmRestControl.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:526)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: java.lang.IllegalStateException: Failed to introspect bean class [com.spark.control.AlgorithmRestControl] for resource metadata: could not find class that it depends on
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:344)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessMergedBeanDefinition(CommonAnnotationBeanPostProcessor.java:297)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyMergedBeanDefinitionPostProcessors(AbstractAutowireCapableBeanFactory.java:992)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:523)
	... 20 more
Caused by: java.lang.NoClassDefFoundError: Lcom/spark/service/WordCountServiceJava;
	at java.lang.Class.getDeclaredFields0(Native Method)
	at java.lang.Class.privateGetDeclaredFields(Class.java:2583)
	at java.lang.Class.getDeclaredFields(Class.java:1916)
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:715)
	at org.springframework.util.ReflectionUtils.doWithLocalFields(ReflectionUtils.java:656)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.buildResourceMetadata(CommonAnnotationBeanPostProcessor.java:361)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:340)
	... 23 more
Caused by: java.lang.ClassNotFoundException: com.spark.service.WordCountServiceJava
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:151)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 30 more
2017-12-11 14:30:04,544 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:30:04,547 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:30:04,552 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4afa1736: startup date [Mon Dec 11 14:30:04 CST 2017]; root of context hierarchy
2017-12-11 14:30:06,891 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:30:08,392 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:30:08,489 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3937 ms
2017-12-11 14:30:08,590 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:30:08,591 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:30:08,591 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:30:08,662 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:30:08,703 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:30:08,704 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:30:08,705 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:30:08,705 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:30:08,705 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:30:08,705 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:30:08,721 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62283.
2017-12-11 14:30:08,725 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:30:08,728 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:30:08,728 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:30:08,729 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:30:08,736 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-083d9aad-d836-432f-b630-4224b5b558fd
2017-12-11 14:30:08,737 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:30:08,739 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:30:08,769 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:30:08,774 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @352948ms
2017-12-11 14:30:08,778 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@579cf756{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:30:08,778 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:30:08,781 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b102722{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,782 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4785b20c{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,784 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dc0cb0a{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,788 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c9732ef{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,789 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4ea1d314{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,790 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5ab283f0{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,790 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49ebe010{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,791 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76dbaaa0{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,791 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7c72799c{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,792 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f0d436a{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,794 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@553b0369{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,796 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57b856d0{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,797 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@318d689b{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,799 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6cbaac8d{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a14bf60{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,800 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@417d5454{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,801 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@367885{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,802 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17ae5dd{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,803 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2c3ec2e1{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,804 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2637ec27{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,805 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1841496c{/static,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,808 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c39896b{/,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,809 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@19d4387b{/api,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,810 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2f769fe7{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,811 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ae0b90f{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,811 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:30:08,871 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:30:08,896 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62301.
2017-12-11 14:30:08,897 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62301
2017-12-11 14:30:08,897 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:30:08,897 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62301, None)
2017-12-11 14:30:08,898 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62301 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62301, None)
2017-12-11 14:30:08,898 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62301, None)
2017-12-11 14:30:08,899 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62301, None)
2017-12-11 14:30:08,901 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31714127{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,914 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-11 14:30:08,916 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:30:08,921 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:30:08,923 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c8ba005{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,924 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f8538e1{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,925 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ada5f65{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,926 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7d9278cf{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,931 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@35f8efdf{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:30:08,941 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:30:09,204 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 14:30:09,205 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 14:30:09,205 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/wordCountServiceJava],methods=[GET]}" onto public java.util.Map<java.lang.String, java.lang.Integer> com.spark.control.AlgorithmRestControl.getWordCountServiceJava()
2017-12-11 14:30:09,207 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 14:30:09,220 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 14:30:09,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 14:30:09,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 14:30:09,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 14:30:09,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 14:30:09,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 14:30:09,222 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 14:30:09,225 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 14:30:09,225 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 14:30:09,226 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 14:30:09,230 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 14:30:09,231 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 14:30:09,345 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 14:30:09,446 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4afa1736: startup date [Mon Dec 11 14:30:04 CST 2017]; root of context hierarchy
2017-12-11 14:30:09,465 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:30:09,525 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:30:09,531 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:30:09,858 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 14:30:10,201 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 14:30:10,207 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 14:30:10,207 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 14:30:10,208 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 14:30:10,223 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 14:30:10,708 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:30:10,800 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:30:11,148 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:30:11,336 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 14:30:11,569 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 14:30:11,573 INFO [restartedMain]                       com.Application : Started Application in 7.183 seconds (JVM running for 355.747)
2017-12-11 14:30:14,797 INFO [Thread-41] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4afa1736: startup date [Mon Dec 11 14:30:04 CST 2017]; root of context hierarchy
2017-12-11 14:30:14,799 INFO [Thread-41] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 14:30:14,800 INFO [Thread-41] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 14:30:14,804 INFO [Thread-41] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@579cf756{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:30:14,896 INFO [Thread-41]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 14:30:14,912 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 14:30:14,960 INFO [Thread-41] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 14:30:14,960 INFO [Thread-41] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 14:30:14,962 INFO [Thread-41] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 14:30:14,962 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 14:30:14,969 INFO [Thread-41]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 14:30:15,054 INFO [Thread-41]         org.apache.spark.SparkContext : SparkContext already stopped.
2017-12-11 14:30:16,311 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:30:16,313 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:30:16,323 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d04f245: startup date [Mon Dec 11 14:30:16 CST 2017]; root of context hierarchy
2017-12-11 14:30:18,409 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:30:20,953 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:30:21,008 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4685 ms
2017-12-11 14:30:21,148 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:30:21,150 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:30:21,150 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:30:21,250 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'algorithmRestControl': Unsatisfied dependency expressed through field 'wordCountServiceJava'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.spark.service.WordCountServiceJava' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2017-12-11 14:30:21,277 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:30:21,785 ERROR [restartedMain] org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter : 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field wordCountServiceJava in com.spark.control.AlgorithmRestControl required a bean of type 'com.spark.service.WordCountServiceJava' that could not be found.


Action:

Consider defining a bean of type 'com.spark.service.WordCountServiceJava' in your configuration.

2017-12-11 14:35:56,748 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:35:56,750 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:35:56,755 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2c007a7b: startup date [Mon Dec 11 14:35:56 CST 2017]; root of context hierarchy
2017-12-11 14:35:59,652 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:36:00,860 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:36:00,969 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4214 ms
2017-12-11 14:36:01,078 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:36:01,079 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:36:01,079 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:36:01,214 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:36:01,216 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:36:01,218 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:36:01,219 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:36:01,222 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:36:01,222 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:36:01,222 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:36:01,261 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62439.
2017-12-11 14:36:01,265 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:36:01,316 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:36:01,316 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:36:01,316 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:36:01,325 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-c4b05b98-0579-4d84-82d9-efa76a136e90
2017-12-11 14:36:01,326 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:36:01,328 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:36:01,421 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:36:01,425 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @705600ms
2017-12-11 14:36:01,430 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@5f87818e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:36:01,430 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:36:01,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e09065e{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,431 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b693d35{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,432 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4e1c869f{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,433 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bb0850{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,434 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4beb1ca2{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,435 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@199746e3{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@217b2d7b{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,436 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@695dd708{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,438 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@129cf91b{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,440 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2e9c15d6{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,441 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@110dca28{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,442 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5467939{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,442 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7bd41431{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,443 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@51723518{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,444 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@30818659{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,444 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f54116b{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,445 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63f0bf12{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,446 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@728bd4c1{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,447 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@31f0cebd{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,448 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a07777b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,450 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4d90be7c{/static,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,450 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6eccdee6{/,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,452 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4c3ad3a6{/api,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,453 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5428c7ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,454 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4268c044{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,454 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:36:01,645 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:36:01,735 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62456.
2017-12-11 14:36:01,735 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62456
2017-12-11 14:36:01,736 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:36:01,739 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62456, None)
2017-12-11 14:36:01,740 INFO [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62456 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62456, None)
2017-12-11 14:36:01,741 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62456, None)
2017-12-11 14:36:01,741 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62456, None)
2017-12-11 14:36:01,743 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@28a1fb21{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,749 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:36:01,749 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:36:01,750 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2717ffce{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,750 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@724b52a6{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,751 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@12d4fc0e{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,752 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@76c70e7e{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,754 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2cffdc13{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:36:01,758 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:36:01,827 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
2017-12-11 14:36:01,877 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:36:01,895 ERROR [restartedMain] org.springframework.boot.SpringApplication : Application startup failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:599)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 24 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	... 36 more
Caused by: org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2472)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2468)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2468)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2557)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:85)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at com.spark.config.SparkConfig.getJavaSparkContext(SparkConfig.scala:36)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getJavaSparkContext$6(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getJavaSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	... 37 more
2017-12-11 14:36:06,877 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 14092 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:36:06,879 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:36:06,883 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@75c33dd0: startup date [Mon Dec 11 14:36:06 CST 2017]; root of context hierarchy
2017-12-11 14:36:09,574 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:36:10,854 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:36:10,909 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4026 ms
2017-12-11 14:36:11,003 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:36:11,004 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:36:11,004 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:36:11,070 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:36:11,081 WARN [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
2017-12-11 14:36:11,095 INFO [restartedMain] org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2017-12-11 14:36:11,101 ERROR [restartedMain] org.springframework.boot.SpringApplication : Application startup failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'wordCountServiceJava': Unsatisfied dependency expressed through field 'sc'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getJavaSparkContext' defined in class path resource [com/spark/config/SparkConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:599)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 24 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'getJavaSparkContext' threw exception; nested exception is org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	... 36 more
Caused by: org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
com.spark.config.SparkConfig.getSparkContext(SparkConfig.scala:23)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getSparkContext$0(<generated>)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getSparkContext(<generated>)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2472)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2468)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2468)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2557)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:85)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at com.spark.config.SparkConfig.getJavaSparkContext(SparkConfig.scala:36)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.CGLIB$getJavaSparkContext$6(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385$$FastClassBySpringCGLIB$$eae21e82.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$7f67f385.getJavaSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	... 37 more
2017-12-11 14:36:58,808 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1096 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:36:58,814 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:36:59,697 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1cce2ce6: startup date [Mon Dec 11 14:36:59 CST 2017]; root of context hierarchy
2017-12-11 14:36:59,834 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-11 14:37:04,394 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:37:06,015 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:37:06,546 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6857 ms
2017-12-11 14:37:06,959 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:37:06,975 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:37:06,976 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:37:07,994 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:37:08,383 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-11 14:37:08,501 ERROR [restartedMain]          org.apache.hadoop.util.Shell : Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\domino\Downloads\hadoop-2.6.5\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at com.spark.config.SparkConfig.getJavaSparkContext(SparkConfig.scala:36)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$77582331.CGLIB$getJavaSparkContext$0(<generated>)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$77582331$$FastClassBySpringCGLIB$$32ded88a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358)
	at com.spark.config.SparkConfig$$EnhancerBySpringCGLIB$$77582331.getJavaSparkContext(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-11 14:37:08,653 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:37:08,696 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:37:08,697 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:37:08,698 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:37:08,698 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:37:08,699 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:37:09,871 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62571.
2017-12-11 14:37:09,927 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:37:09,983 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:37:09,991 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:37:09,992 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:37:10,022 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-185b9051-fe87-43ad-9160-345f66589d24
2017-12-11 14:37:10,088 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:37:10,346 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:37:10,661 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @17607ms
2017-12-11 14:37:10,857 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:37:10,934 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @17884ms
2017-12-11 14:37:11,007 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3f428c1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:37:11,007 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:37:11,086 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7287409f{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,088 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@131b99a7{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,089 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ce9d3f5{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,093 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2726fa7a{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,094 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@460ccb99{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,095 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@11f58da6{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,096 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23fdd500{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,113 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3f10fdd7{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,115 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ba94d64{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,119 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@22cc897a{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,121 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@23a0cc32{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,122 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2eade538{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,125 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5248983e{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,126 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ad8e219{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,128 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ba1d3b5{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,129 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@775b09ac{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,131 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e2ae63e{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,138 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6c76f4df{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,147 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3335dc05{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,158 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@57d5c843{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,192 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@ecd230f{/static,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,196 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74dda53d{/,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,201 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@64373c94{/api,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,211 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3276517c{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,216 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d349488{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,243 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:37:11,540 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:37:11,580 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62588.
2017-12-11 14:37:11,581 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62588
2017-12-11 14:37:11,582 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:37:11,584 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62588, None)
2017-12-11 14:37:11,589 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62588 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62588, None)
2017-12-11 14:37:11,593 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62588, None)
2017-12-11 14:37:11,594 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62588, None)
2017-12-11 14:37:11,641 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a17695a{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,755 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-11 14:37:11,945 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:37:11,947 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:37:11,965 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@10e5ba5d{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,967 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3c6e1d2e{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,973 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f36e12d{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,978 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3bceb3ea{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:37:11,981 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@226ba6f2{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:37:12,921 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-11 14:37:13,155 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:37:13,990 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 14:37:13,991 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 14:37:13,991 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/wordCountServiceJava],methods=[GET]}" onto public java.util.Map<java.lang.String, java.lang.Integer> com.spark.control.AlgorithmRestControl.getWordCountServiceJava()
2017-12-11 14:37:13,994 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 14:37:13,995 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 14:37:13,995 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 14:37:13,995 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 14:37:13,997 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 14:37:13,998 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 14:37:13,998 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 14:37:13,999 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 14:37:14,011 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 14:37:14,013 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 14:37:14,014 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 14:37:14,030 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 14:37:14,030 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 14:37:14,346 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 14:37:14,470 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1cce2ce6: startup date [Mon Dec 11 14:36:59 CST 2017]; root of context hierarchy
2017-12-11 14:37:14,486 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:37:14,578 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:37:14,615 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:37:18,288 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 14:37:18,626 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 14:37:18,656 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 14:37:18,656 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 14:37:18,745 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 14:37:18,798 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 14:37:20,340 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:37:20,591 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:37:21,140 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:37:21,270 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 14:37:21,436 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 14:37:21,450 INFO [restartedMain]                       com.Application : Started Application in 24.182 seconds (JVM running for 28.4)
2017-12-11 14:37:21,752 INFO [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 14:37:21,753 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 14:37:21,876 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 123 ms
2017-12-11 14:37:21,912 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,061 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 14:37:22,257 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 14:37:22,257 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 14:37:22,258 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 14:37:22,258 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 14:37:22,272 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 14:37:22,273 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 14:37:22,605 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,616 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,623 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,611 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,610 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,652 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,659 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,700 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,692 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,689 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,671 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,663 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:22,746 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:23,328 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:23,502 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:39,481 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:37:39,776 INFO [http-nio-8080-exec-11]         org.apache.spark.SparkContext : Starting job: count at WordCountServiceJava.java:39
2017-12-11 14:37:39,799 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 0 (count at WordCountServiceJava.java:39) with 3 output partitions
2017-12-11 14:37:39,800 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 0 (count at WordCountServiceJava.java:39)
2017-12-11 14:37:39,801 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List()
2017-12-11 14:37:39,803 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List()
2017-12-11 14:37:39,810 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at WordCountServiceJava.java:29), which has no missing parents
2017-12-11 14:37:39,889 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 898.5 MB)
2017-12-11 14:37:40,014 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 898.5 MB)
2017-12-11 14:37:40,018 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo : Added broadcast_0_piece0 in memory on 192.168.211.1:62588 (size: 1006.0 B, free: 898.5 MB)
2017-12-11 14:37:40,021 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:37:40,044 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at WordCountServiceJava.java:29) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:37:40,045 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 0.0 with 3 tasks
2017-12-11 14:37:40,094 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:37:40,097 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2017-12-11 14:37:40,098 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 4843 bytes)
2017-12-11 14:37:40,135 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Running task 2.0 in stage 0.0 (TID 2)
2017-12-11 14:37:40,135 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Running task 0.0 in stage 0.0 (TID 0)
2017-12-11 14:37:40,135 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Running task 1.0 in stage 0.0 (TID 1)
2017-12-11 14:37:40,268 INFO [Executor task launch worker for task 1] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:37:40,268 INFO [Executor task launch worker for task 2] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_2 stored as values in memory (estimated size 96.0 B, free 898.5 MB)
2017-12-11 14:37:40,269 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_1 in memory on 192.168.211.1:62588 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:37:40,269 INFO [Executor task launch worker for task 0] org.apache.spark.storage.memory.MemoryStore : Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 898.5 MB)
2017-12-11 14:37:40,270 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_2 in memory on 192.168.211.1:62588 (size: 96.0 B, free: 898.5 MB)
2017-12-11 14:37:40,273 INFO [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo : Added rdd_0_0 in memory on 192.168.211.1:62588 (size: 16.0 B, free: 898.5 MB)
2017-12-11 14:37:40,309 INFO [Executor task launch worker for task 1]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 0.0 (TID 1). 1486 bytes result sent to driver
2017-12-11 14:37:40,309 INFO [Executor task launch worker for task 2]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 0.0 (TID 2). 1486 bytes result sent to driver
2017-12-11 14:37:40,309 INFO [Executor task launch worker for task 0]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
2017-12-11 14:37:40,331 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 0.0 (TID 1) in 232 ms on localhost (executor driver) (1/3)
2017-12-11 14:37:40,337 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 0.0 (TID 0) in 261 ms on localhost (executor driver) (2/3)
2017-12-11 14:37:40,337 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 0.0 (TID 2) in 240 ms on localhost (executor driver) (3/3)
2017-12-11 14:37:40,341 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-12-11 14:37:40,349 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 0 (count at WordCountServiceJava.java:39) finished in 0.285 s
2017-12-11 14:37:40,360 INFO [http-nio-8080-exec-11] org.apache.spark.scheduler.DAGScheduler : Job 0 finished: count at WordCountServiceJava.java:39, took 0.582722 s
2017-12-11 14:37:40,447 INFO [http-nio-8080-exec-11]         org.apache.spark.SparkContext : Starting job: collect at WordCountServiceJava.java:66
2017-12-11 14:37:40,464 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Registering RDD 3 (mapToPair at WordCountServiceJava.java:48)
2017-12-11 14:37:40,467 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Got job 1 (collect at WordCountServiceJava.java:66) with 3 output partitions
2017-12-11 14:37:40,468 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Final stage: ResultStage 2 (collect at WordCountServiceJava.java:66)
2017-12-11 14:37:40,468 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Parents of final stage: List(ShuffleMapStage 1)
2017-12-11 14:37:40,469 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Missing parents: List(ShuffleMapStage 1)
2017-12-11 14:37:40,478 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at WordCountServiceJava.java:48), which has no missing parents
2017-12-11 14:37:40,502 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1 stored as values in memory (estimated size 3.7 KB, free 898.5 MB)
2017-12-11 14:37:40,512 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 898.5 MB)
2017-12-11 14:37:40,514 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo : Added broadcast_1_piece0 in memory on 192.168.211.1:62588 (size: 2.1 KB, free: 898.5 MB)
2017-12-11 14:37:40,516 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:37:40,530 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at WordCountServiceJava.java:48) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:37:40,531 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 1.0 with 3 tasks
2017-12-11 14:37:40,549 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 1.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:37:40,553 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 1.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 4816 bytes)
2017-12-11 14:37:40,554 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 1.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 4832 bytes)
2017-12-11 14:37:40,557 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Running task 0.0 in stage 1.0 (TID 3)
2017-12-11 14:37:40,559 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Running task 2.0 in stage 1.0 (TID 5)
2017-12-11 14:37:40,559 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Running task 1.0 in stage 1.0 (TID 4)
2017-12-11 14:37:40,592 INFO [Executor task launch worker for task 3] org.apache.spark.storage.BlockManager : Found block rdd_0_0 locally
2017-12-11 14:37:40,592 INFO [Executor task launch worker for task 5] org.apache.spark.storage.BlockManager : Found block rdd_0_2 locally
2017-12-11 14:37:40,592 INFO [Executor task launch worker for task 4] org.apache.spark.storage.BlockManager : Found block rdd_0_1 locally
2017-12-11 14:37:40,675 INFO [Executor task launch worker for task 3]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 1.0 (TID 3). 941 bytes result sent to driver
2017-12-11 14:37:40,675 INFO [Executor task launch worker for task 4]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 1.0 (TID 4). 984 bytes result sent to driver
2017-12-11 14:37:40,680 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 1.0 (TID 4) in 128 ms on localhost (executor driver) (1/3)
2017-12-11 14:37:40,687 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 1.0 (TID 3) in 150 ms on localhost (executor driver) (2/3)
2017-12-11 14:37:40,701 INFO [Executor task launch worker for task 5]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 1.0 (TID 5). 1113 bytes result sent to driver
2017-12-11 14:37:40,703 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 1.0 (TID 5) in 150 ms on localhost (executor driver) (3/3)
2017-12-11 14:37:40,703 INFO [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-12-11 14:37:40,705 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ShuffleMapStage 1 (mapToPair at WordCountServiceJava.java:48) finished in 0.168 s
2017-12-11 14:37:40,707 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : looking for newly runnable stages
2017-12-11 14:37:40,707 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : running: Set()
2017-12-11 14:37:40,708 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : waiting: Set(ResultStage 2)
2017-12-11 14:37:40,708 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : failed: Set()
2017-12-11 14:37:40,713 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at WordCountServiceJava.java:57), which has no missing parents
2017-12-11 14:37:40,721 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 898.5 MB)
2017-12-11 14:37:40,725 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore : Block broadcast_2_piece0 stored as bytes in memory (estimated size 1897.0 B, free 898.5 MB)
2017-12-11 14:37:40,729 INFO [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo : Added broadcast_2_piece0 in memory on 192.168.211.1:62588 (size: 1897.0 B, free: 898.5 MB)
2017-12-11 14:37:40,730 INFO [dag-scheduler-event-loop]         org.apache.spark.SparkContext : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2017-12-11 14:37:40,732 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : Submitting 3 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at WordCountServiceJava.java:57) (first 15 tasks are for partitions Vector(0, 1, 2))
2017-12-11 14:37:40,733 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl : Adding task set 2.0 with 3 tasks
2017-12-11 14:37:40,736 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 2.0 in stage 2.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 4621 bytes)
2017-12-11 14:37:40,737 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 0.0 in stage 2.0 (TID 7, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-12-11 14:37:40,738 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager : Starting task 1.0 in stage 2.0 (TID 8, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-12-11 14:37:40,738 INFO [Executor task launch worker for task 6]    org.apache.spark.executor.Executor : Running task 2.0 in stage 2.0 (TID 6)
2017-12-11 14:37:40,738 INFO [Executor task launch worker for task 8]    org.apache.spark.executor.Executor : Running task 1.0 in stage 2.0 (TID 8)
2017-12-11 14:37:40,738 INFO [Executor task launch worker for task 7]    org.apache.spark.executor.Executor : Running task 0.0 in stage 2.0 (TID 7)
2017-12-11 14:37:40,774 INFO [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:37:40,774 INFO [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 1 non-empty blocks out of 3 blocks
2017-12-11 14:37:40,774 INFO [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator : Getting 0 non-empty blocks out of 3 blocks
2017-12-11 14:37:40,777 INFO [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 8 ms
2017-12-11 14:37:40,777 INFO [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 8 ms
2017-12-11 14:37:40,777 INFO [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator : Started 0 remote fetches in 8 ms
2017-12-11 14:37:40,808 INFO [Executor task launch worker for task 7]    org.apache.spark.executor.Executor : Finished task 0.0 in stage 2.0 (TID 7). 1237 bytes result sent to driver
2017-12-11 14:37:40,813 INFO [Executor task launch worker for task 8]    org.apache.spark.executor.Executor : Finished task 1.0 in stage 2.0 (TID 8). 1252 bytes result sent to driver
2017-12-11 14:37:40,825 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager : Finished task 1.0 in stage 2.0 (TID 8) in 88 ms on localhost (executor driver) (1/3)
2017-12-11 14:37:40,826 INFO [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager : Finished task 0.0 in stage 2.0 (TID 7) in 89 ms on localhost (executor driver) (2/3)
2017-12-11 14:37:40,829 INFO [Executor task launch worker for task 6]    org.apache.spark.executor.Executor : Finished task 2.0 in stage 2.0 (TID 6). 1048 bytes result sent to driver
2017-12-11 14:37:40,831 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager : Finished task 2.0 in stage 2.0 (TID 6) in 96 ms on localhost (executor driver) (3/3)
2017-12-11 14:37:40,831 INFO [task-result-getter-3] org.apache.spark.scheduler.TaskSchedulerImpl : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-12-11 14:37:40,832 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler : ResultStage 2 (collect at WordCountServiceJava.java:66) finished in 0.098 s
2017-12-11 14:37:40,833 INFO [http-nio-8080-exec-11] org.apache.spark.scheduler.DAGScheduler : Job 1 finished: collect at WordCountServiceJava.java:66, took 0.384615 s
2017-12-11 14:39:01,417 INFO [Thread-22] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1cce2ce6: startup date [Mon Dec 11 14:36:59 CST 2017]; root of context hierarchy
2017-12-11 14:39:01,428 INFO [Thread-22] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-11 14:39:01,433 INFO [Thread-22] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-11 14:39:01,445 INFO [Thread-22] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3f428c1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:39:01,459 INFO [Thread-22]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.211.1:4040
2017-12-11 14:39:01,484 INFO [dispatcher-event-loop-2] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-11 14:39:01,654 INFO [Thread-22] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-11 14:39:01,655 INFO [Thread-22] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-11 14:39:01,657 INFO [Thread-22] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-11 14:39:01,672 INFO [dispatcher-event-loop-3] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-11 14:39:01,684 INFO [Thread-22]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-11 14:39:01,707 INFO [Thread-22]         org.apache.spark.SparkContext : SparkContext already stopped.
2017-12-11 14:39:02,217 INFO [Thread-22] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-11 14:39:02,228 INFO [localhost-startStop-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Destroying Spring FrameworkServlet 'dispatcherServlet'
2017-12-11 14:39:02,257 WARN [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-11 14:39:03,045 INFO [restartedMain]                       com.Application : Starting Application on DESKTOP-5NH31VQ with PID 1096 (D:\SparkVisualMl\target\classes started by lilingui in D:\SparkVisualMl)
2017-12-11 14:39:03,045 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-11 14:39:03,084 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@41844d3f: startup date [Mon Dec 11 14:39:03 CST 2017]; root of context hierarchy
2017-12-11 14:39:05,878 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-11 14:39:06,832 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-11 14:39:06,881 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3797 ms
2017-12-11 14:39:06,997 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-11 14:39:06,998 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-11 14:39:06,998 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-11 14:39:07,101 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-11 14:39:07,105 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-11 14:39:07,106 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: lilingui
2017-12-11 14:39:07,107 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: lilingui
2017-12-11 14:39:07,107 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-11 14:39:07,107 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-11 14:39:07,107 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lilingui); groups with view permissions: Set(); users  with modify permissions: Set(lilingui); groups with modify permissions: Set()
2017-12-11 14:39:07,124 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 62644.
2017-12-11 14:39:07,127 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-11 14:39:07,129 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-11 14:39:07,129 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-11 14:39:07,129 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-11 14:39:07,140 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at C:\Users\domino\AppData\Local\Temp\blockmgr-8d423013-c80e-4341-bc92-38a45e78108c
2017-12-11 14:39:07,144 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 898.5 MB
2017-12-11 14:39:07,163 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-11 14:39:07,219 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-11 14:39:07,221 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @134172ms
2017-12-11 14:39:07,258 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@42c4c5c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-11 14:39:07,258 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-11 14:39:07,259 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@34e38b56{/jobs,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,261 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@56449faa{/jobs/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,262 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@18fdf3f2{/jobs/job,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,262 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2644902e{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,263 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d22caa{/stages,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,264 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b57596a{/stages/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,265 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7464fb86{/stages/stage,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,266 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4f9feee4{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,267 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ab748a5{/stages/pool,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,269 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7b2bfb9{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,270 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fe2b815{/storage,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,271 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ecd72b4{/storage/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,272 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2af263b8{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,273 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@517edc69{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,283 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a3d9c63{/environment,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,284 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@739edfd2{/environment/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,304 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7810ad78{/executors,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,305 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@fc6498c{/executors/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,305 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2b13fa5d{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,307 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ac0dd3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,312 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a81d60b{/static,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,313 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4a114e1f{/,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,314 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@509a9015{/api,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,315 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74110cc4{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,316 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3a1e969b{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,316 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.211.1:4040
2017-12-11 14:39:07,451 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-11 14:39:07,486 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62661.
2017-12-11 14:39:07,487 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.211.1:62661
2017-12-11 14:39:07,487 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-11 14:39:07,487 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.211.1, 62661, None)
2017-12-11 14:39:07,488 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.211.1:62661 with 898.5 MB RAM, BlockManagerId(driver, 192.168.211.1, 62661, None)
2017-12-11 14:39:07,489 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.211.1, 62661, None)
2017-12-11 14:39:07,489 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.211.1, 62661, None)
2017-12-11 14:39:07,491 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@221cae43{/metrics/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,514 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-11 14:39:07,516 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/SparkVisualMl/spark-warehouse/').
2017-12-11 14:39:07,516 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/D:/SparkVisualMl/spark-warehouse/'.
2017-12-11 14:39:07,520 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@41480be2{/SQL,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,521 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4867dee6{/SQL/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,522 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1ccf1a43{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,522 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c90ff51{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,526 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@550c4dec{/static/sql,null,AVAILABLE,@Spark}
2017-12-11 14:39:07,533 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-11 14:39:08,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-11 14:39:08,221 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-11 14:39:08,225 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/wordCountServiceJava],methods=[GET]}" onto public java.util.Map<java.lang.String, java.lang.Integer> com.spark.control.AlgorithmRestControl.getWordCountServiceJava()
2017-12-11 14:39:08,227 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-11 14:39:08,232 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-11 14:39:08,233 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-11 14:39:08,233 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-11 14:39:08,233 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-11 14:39:08,234 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-11 14:39:08,234 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-11 14:39:08,235 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-11 14:39:08,242 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-11 14:39:08,243 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-11 14:39:08,243 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-11 14:39:08,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-11 14:39:08,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-11 14:39:08,649 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-11 14:39:08,798 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@41844d3f: startup date [Mon Dec 11 14:39:03 CST 2017]; root of context hierarchy
2017-12-11 14:39:08,803 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:39:08,834 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-11 14:39:08,843 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-11 14:39:09,664 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-11 14:39:10,269 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-11 14:39:10,285 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-11 14:39:10,285 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-11 14:39:10,288 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-11 14:39:10,298 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-11 14:39:11,339 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:39:11,600 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:39:12,020 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-11 14:39:12,154 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-11 14:39:12,265 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-12-11 14:39:12,288 INFO [restartedMain]                       com.Application : Started Application in 9.461 seconds (JVM running for 139.239)
2017-12-11 14:47:31,535 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-11 14:47:31,540 INFO [http-nio-8080-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 5 ms
2017-12-11 14:47:31,542 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,545 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-11 14:47:31,570 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-11 14:47:31,570 INFO [http-nio-8080-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-11 14:47:31,570 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-11 14:47:31,570 INFO [http-nio-8080-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-11 14:47:31,576 INFO [http-nio-8080-exec-1]   org.thymeleaf.TemplateEngine.CONFIG : [THYMELEAF] TEMPLATE ENGINE CONFIGURATION:
[THYMELEAF] * Cache Factory implementation: org.thymeleaf.cache.StandardCacheManager
[THYMELEAF] * Template modes:
[THYMELEAF]     * LEGACYHTML5
[THYMELEAF]     * VALIDXML
[THYMELEAF]     * HTML5
[THYMELEAF]     * XHTML
[THYMELEAF]     * VALIDXHTML
[THYMELEAF]     * XML
[THYMELEAF] * Template resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
[THYMELEAF] * Message resolvers (in order):
[THYMELEAF]     * org.thymeleaf.spring4.messageresolver.SpringMessageResolver
[THYMELEAF] * Dialect [1 of 2]: org.thymeleaf.spring4.dialect.SpringStandardDialect
[THYMELEAF]     * Prefix: "th"
[THYMELEAF] * Dialect [2 of 2]: nz.net.ultraq.thymeleaf.LayoutDialect
[THYMELEAF]     * Prefix: "layout"
[THYMELEAF] TEMPLATE ENGINE CONFIGURED OK
2017-12-11 14:47:31,576 INFO [http-nio-8080-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-11 14:47:31,730 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,735 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,733 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,753 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,765 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,771 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,731 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,768 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,755 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,750 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,742 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,738 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:31,738 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:32,200 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:32,287 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,017 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,060 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,083 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,086 INFO [http-nio-8080-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,091 INFO [http-nio-8080-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,092 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,094 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,135 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,133 INFO [http-nio-8080-exec-13]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,129 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,124 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,117 INFO [http-nio-8080-exec-12]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,109 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,094 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,634 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,729 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,807 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:47:37,817 WARN [http-nio-8080-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 14:52:36,573 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,619 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,620 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,621 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,622 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,633 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,635 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,640 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,643 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,644 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,651 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,652 INFO [http-nio-8080-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,653 INFO [http-nio-8080-exec-14]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,673 INFO [http-nio-8080-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,932 INFO [http-nio-8080-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:52:36,989 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,525 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,551 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,561 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,582 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,582 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,582 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,585 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,588 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,594 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,602 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,611 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,619 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,623 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:02,627 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:03,714 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:53:04,051 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,847 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,956 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,958 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,964 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,964 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,972 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,972 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,980 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,982 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,985 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,986 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,990 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:25,992 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:26,000 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:27,146 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:58:27,393 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,493 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,631 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,633 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,704 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,677 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,674 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,668 INFO [http-nio-8080-exec-18]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,668 INFO [http-nio-8080-exec-17]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,655 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,651 INFO [http-nio-8080-exec-22]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,649 INFO [http-nio-8080-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,638 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,635 INFO [http-nio-8080-exec-20]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:30,635 INFO [http-nio-8080-exec-21]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:32,129 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:32,382 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:32,690 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 14:59:32,692 WARN [http-nio-8080-exec-10] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 15:03:38,613 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,711 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,718 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,718 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,733 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,751 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,765 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,779 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,801 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,812 INFO [http-nio-8080-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,980 INFO [http-nio-8080-exec-23]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,990 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,992 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:38,992 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:40,160 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:03:40,352 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,385 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,456 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,486 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,495 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,505 INFO [http-nio-8080-exec-23]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,510 INFO [http-nio-8080-exec-21]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,514 INFO [http-nio-8080-exec-15]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,519 INFO [http-nio-8080-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,522 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,531 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,538 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,540 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,541 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:22,541 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:23,739 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:04:23,987 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,624 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,704 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,710 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,714 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,719 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,722 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,723 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,726 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,732 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,732 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,800 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,815 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,817 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:29,821 INFO [http-nio-8080-exec-30]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:30,914 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:20:31,147 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,564 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,656 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,657 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,662 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,663 INFO [http-nio-8080-exec-27]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,666 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,664 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,672 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,682 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,682 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,686 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,699 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,702 INFO [http-nio-8080-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:16,704 INFO [http-nio-8080-exec-16]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:17,161 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:17,345 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:17,540 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:17,542 WARN [http-nio-8080-exec-26] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 15:21:35,582 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,648 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,652 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,655 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,656 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,658 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,660 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,661 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,656 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,660 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,664 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,666 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,670 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:35,671 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:37,192 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:21:37,475 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,694 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,745 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,748 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,765 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,778 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,779 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,780 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,785 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,789 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,789 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,807 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,862 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,876 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:41,881 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:43,081 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:22:43,308 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,236 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,304 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,304 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,310 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,317 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,318 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,319 INFO [http-nio-8080-exec-24]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,319 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,319 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,322 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,378 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,378 INFO [http-nio-8080-exec-34]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,380 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:49,380 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:50,410 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:25:50,676 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:29,982 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,039 INFO [http-nio-8080-exec-34]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,040 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,041 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,047 INFO [http-nio-8080-exec-19]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,063 INFO [http-nio-8080-exec-31]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,063 INFO [http-nio-8080-exec-26]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,066 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,066 INFO [http-nio-8080-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,071 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,084 INFO [http-nio-8080-exec-35]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,086 INFO [http-nio-8080-exec-37]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,087 INFO [http-nio-8080-exec-38]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,086 INFO [http-nio-8080-exec-36]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,409 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,482 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,604 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 15:27:30,607 WARN [http-nio-8080-exec-11] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
2017-12-11 16:09:30,066 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,143 INFO [http-nio-8080-exec-37]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,144 INFO [http-nio-8080-exec-35]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,151 INFO [http-nio-8080-exec-36]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,153 INFO [http-nio-8080-exec-37]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,151 INFO [http-nio-8080-exec-35]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,160 INFO [http-nio-8080-exec-37]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,161 INFO [http-nio-8080-exec-11]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,166 INFO [http-nio-8080-exec-35]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,171 INFO [http-nio-8080-exec-25]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,238 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,243 INFO [http-nio-8080-exec-42]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,251 INFO [http-nio-8080-exec-41]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:30,244 INFO [http-nio-8080-exec-40]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:31,258 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:09:31,441 INFO [http-nio-8080-exec-36]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,788 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,862 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,865 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,868 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,870 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,875 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,878 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,881 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,884 INFO [http-nio-8080-exec-29]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,888 INFO [http-nio-8080-exec-32]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:22,966 INFO [http-nio-8080-exec-43]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:23,009 INFO [http-nio-8080-exec-45]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:23,016 INFO [http-nio-8080-exec-46]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:23,019 INFO [http-nio-8080-exec-44]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:24,282 INFO [http-nio-8080-exec-28]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-11 16:16:24,734 INFO [http-nio-8080-exec-39]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:31:29,387 INFO [restartedMain]                       com.Application : Starting Application on master with PID 16265 (/root/IdeaProjects/SparkVisualMl/target/classes started by root in /root/IdeaProjects/SparkVisualMl)
2017-12-18 21:31:29,392 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-18 21:31:30,524 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@564ea59c: startup date [Mon Dec 18 21:31:30 PST 2017]; root of context hierarchy
2017-12-18 21:31:30,772 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-18 21:31:34,591 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-18 21:31:36,089 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-12-18 21:31:36,518 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6005 ms
2017-12-18 21:31:36,807 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-18 21:31:36,818 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-18 21:31:36,821 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-18 21:31:37,466 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-18 21:31:37,818 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-18 21:31:38,164 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-18 21:31:38,205 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: root
2017-12-18 21:31:38,205 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: root
2017-12-18 21:31:38,206 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-18 21:31:38,206 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-18 21:31:38,207 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2017-12-18 21:31:38,860 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 42284.
2017-12-18 21:31:38,897 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-18 21:31:38,937 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-18 21:31:38,944 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-18 21:31:38,946 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-18 21:31:38,968 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at /tmp/blockmgr-f3c05d99-965d-4017-949f-ad24beec6a9a
2017-12-18 21:31:39,007 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 719.0 MB
2017-12-18 21:31:39,160 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-18 21:31:39,358 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @16114ms
2017-12-18 21:31:39,449 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-18 21:31:39,470 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @16227ms
2017-12-18 21:31:39,501 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@3e3588b3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-18 21:31:39,501 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-18 21:31:39,544 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@45797868{/jobs,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,547 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@173dddfb{/jobs/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,550 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@53ee598e{/jobs/job,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,551 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6583a49f{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,551 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@459b00c9{/stages,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,552 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1bc4dad5{/stages/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,554 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4719f814{/stages/stage,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,555 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5b9150e1{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,556 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1d809c48{/stages/pool,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,560 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@198cb57e{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,561 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@665790c6{/storage,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,561 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@dc62f58{/storage/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,562 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@49726547{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,563 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6e6ee110{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,564 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f7c5240{/environment,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,566 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@518d90d2{/environment/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,567 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1b58bc3a{/executors,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,568 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7ab5ddb8{/executors/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,570 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6ab04727{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,570 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6792f023{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,583 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@78bab43{/static,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,584 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b233cf0{/,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,585 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2dbe0320{/api,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,590 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@8471cd8{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,592 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@80e948{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-18 21:31:39,595 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.107.131:4040
2017-12-18 21:31:39,871 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-18 21:31:39,922 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36587.
2017-12-18 21:31:39,923 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.107.131:36587
2017-12-18 21:31:39,924 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-18 21:31:39,926 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.107.131, 36587, None)
2017-12-18 21:31:39,929 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.107.131:36587 with 719.0 MB RAM, BlockManagerId(driver, 192.168.107.131, 36587, None)
2017-12-18 21:31:39,937 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.107.131, 36587, None)
2017-12-18 21:31:39,937 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.107.131, 36587, None)
2017-12-18 21:31:39,970 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1e242509{/metrics/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:40,071 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-18 21:31:40,276 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/root/IdeaProjects/SparkVisualMl/spark-warehouse').
2017-12-18 21:31:40,279 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/root/IdeaProjects/SparkVisualMl/spark-warehouse'.
2017-12-18 21:31:40,299 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6a6ca4af{/SQL,null,AVAILABLE,@Spark}
2017-12-18 21:31:40,311 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@d1eb4f8{/SQL/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:40,321 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@637fac97{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-18 21:31:40,329 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5813fe75{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-18 21:31:40,342 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@649b6203{/static/sql,null,AVAILABLE,@Spark}
2017-12-18 21:31:41,108 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-18 21:31:41,455 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-18 21:31:41,518 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-18 21:31:42,233 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-18 21:31:42,242 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-18 21:31:42,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/wordCountInFile],methods=[GET]}" onto public com.alibaba.fastjson.JSONObject com.spark.control.AlgorithmRestControl.getWordCountInFile(java.lang.String)
2017-12-18 21:31:42,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/sqls],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmRestControl.sqlExecRes(java.lang.String)
2017-12-18 21:31:42,245 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/datasource/mysql],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmRestControl.dataSourceForMysql(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
2017-12-18 21:31:42,249 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-18 21:31:42,249 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-18 21:31:42,249 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-18 21:31:42,249 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-18 21:31:42,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-18 21:31:42,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-18 21:31:42,251 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-18 21:31:42,256 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/utils/uploadjar],methods=[POST]}" onto public org.springframework.http.ResponseEntity com.spark.control.UtilControl.uploadJar(org.springframework.web.multipart.MultipartFile)
2017-12-18 21:31:42,262 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-18 21:31:42,268 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-18 21:31:42,270 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-18 21:31:42,270 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-18 21:31:42,284 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-18 21:31:42,284 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-18 21:31:42,628 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-18 21:31:42,724 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@564ea59c: startup date [Mon Dec 18 21:31:30 PST 2017]; root of context hierarchy
2017-12-18 21:31:42,751 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-18 21:31:42,895 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-18 21:31:44,394 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-18 21:31:44,491 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-18 21:31:44,507 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-18 21:31:44,507 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-18 21:31:44,549 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-18 21:31:44,592 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-18 21:31:45,383 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:31:45,500 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:31:45,696 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:31:45,760 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-18 21:31:45,886 ERROR [restartedMain] org.apache.coyote.http11.Http11NioProtocol : Failed to start end point associated with ProtocolHandler [http-nio-8080]
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210)
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:980)
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:573)
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:993)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225)
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:247)
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:190)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:545)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2017-12-18 21:31:45,892 ERROR [restartedMain] org.apache.catalina.core.StandardService : Failed to start connector [Connector[HTTP/1.1-8080]]
org.apache.catalina.LifecycleException: Failed to start component [Connector[HTTP/1.1-8080]]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:167)
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225)
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:247)
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:190)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:545)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.Application.main(Application.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.apache.catalina.LifecycleException: service.getName(): "Tomcat";  Protocol handler start failed
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1000)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	... 18 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210)
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:980)
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:573)
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:993)
	... 19 more
2017-12-18 21:31:45,951 INFO [restartedMain] org.apache.catalina.core.StandardService : Stopping service Tomcat
2017-12-18 21:31:45,992 WARN [localhost-startStop-1] org.apache.catalina.loader.WebappClassLoaderBase : The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.lang.Object.wait(Native Method)
 java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)
2017-12-18 21:31:46,049 ERROR [restartedMain] org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter : 

***************************
APPLICATION FAILED TO START
***************************

Description:

The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured.

Action:

Verify the connector's configuration, identify and stop any process that's listening on port 8080, or configure this application to listen on another port.

2017-12-18 21:31:46,057 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@564ea59c: startup date [Mon Dec 18 21:31:30 PST 2017]; root of context hierarchy
2017-12-18 21:31:46,067 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Stopping beans in phase 2147483647
2017-12-18 21:31:46,072 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown
2017-12-18 21:31:46,095 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Stopped Spark@3e3588b3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-18 21:31:46,114 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Stopped Spark web UI at http://192.168.107.131:4040
2017-12-18 21:31:46,133 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint : MapOutputTrackerMasterEndpoint stopped!
2017-12-18 21:31:46,187 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore cleared
2017-12-18 21:31:46,187 INFO [restartedMain] org.apache.spark.storage.BlockManager : BlockManager stopped
2017-12-18 21:31:46,196 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : BlockManagerMaster stopped
2017-12-18 21:31:46,201 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-12-18 21:31:46,206 INFO [restartedMain]         org.apache.spark.SparkContext : Successfully stopped SparkContext
2017-12-18 21:31:46,206 INFO [restartedMain]         org.apache.spark.SparkContext : SparkContext already stopped.
2017-12-18 21:31:46,231 INFO [Thread-6] org.apache.spark.util.ShutdownHookManager : Shutdown hook called
2017-12-18 21:31:46,238 INFO [Thread-6] org.apache.spark.util.ShutdownHookManager : Deleting directory /tmp/spark-313a74cc-d692-480a-9046-19645474bad5
2017-12-18 21:32:25,567 INFO [restartedMain]                       com.Application : Starting Application on master with PID 16408 (/root/IdeaProjects/SparkVisualMl/target/classes started by root in /root/IdeaProjects/SparkVisualMl)
2017-12-18 21:32:25,587 INFO [restartedMain]                       com.Application : No active profile set, falling back to default profiles: default
2017-12-18 21:32:26,949 INFO [restartedMain] org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@434cc5dc: startup date [Mon Dec 18 21:32:26 PST 2017]; root of context hierarchy
2017-12-18 21:32:27,108 INFO [background-preinit] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.3.4.Final
2017-12-18 21:32:29,959 INFO [restartedMain] org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-12-18 21:32:31,533 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8081 (http)
2017-12-18 21:32:31,885 INFO [localhost-startStop-1] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 4940 ms
2017-12-18 21:32:32,116 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]
2017-12-18 21:32:32,125 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-12-18 21:32:32,126 INFO [localhost-startStop-1] org.springframework.boot.web.servlet.FilterRegistrationBean : Mapping filter: 'corsFilter' to: [/*]
2017-12-18 21:32:32,902 INFO [restartedMain]         org.apache.spark.SparkContext : Running Spark version 2.2.0
2017-12-18 21:32:33,224 WARN [restartedMain] org.apache.hadoop.util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-12-18 21:32:33,542 INFO [restartedMain]         org.apache.spark.SparkContext : Submitted application: "Sparkå¯è§åæºå¨å­¦ä¹ "
2017-12-18 21:32:33,584 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls to: root
2017-12-18 21:32:33,585 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls to: root
2017-12-18 21:32:33,585 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing view acls groups to: 
2017-12-18 21:32:33,585 INFO [restartedMain]      org.apache.spark.SecurityManager : Changing modify acls groups to: 
2017-12-18 21:32:33,588 INFO [restartedMain]      org.apache.spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2017-12-18 21:32:34,162 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'sparkDriver' on port 35366.
2017-12-18 21:32:34,201 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering MapOutputTracker
2017-12-18 21:32:34,231 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering BlockManagerMaster
2017-12-18 21:32:34,236 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-12-18 21:32:34,238 INFO [restartedMain] org.apache.spark.storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
2017-12-18 21:32:34,255 INFO [restartedMain] org.apache.spark.storage.DiskBlockManager : Created local directory at /tmp/blockmgr-83d344b5-6db4-4b44-8bef-7f9f860ea682
2017-12-18 21:32:34,291 INFO [restartedMain] org.apache.spark.storage.memory.MemoryStore : MemoryStore started with capacity 719.0 MB
2017-12-18 21:32:34,354 INFO [restartedMain]             org.apache.spark.SparkEnv : Registering OutputCommitCoordinator
2017-12-18 21:32:34,577 INFO [restartedMain]      org.spark_project.jetty.util.log : Logging initialized @12539ms
2017-12-18 21:32:34,700 INFO [restartedMain] org.spark_project.jetty.server.Server : jetty-9.3.z-SNAPSHOT
2017-12-18 21:32:34,737 INFO [restartedMain] org.spark_project.jetty.server.Server : Started @12706ms
2017-12-18 21:32:34,772 INFO [restartedMain] org.spark_project.jetty.server.AbstractConnector : Started ServerConnector@28f09531{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-12-18 21:32:34,773 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'SparkUI' on port 4040.
2017-12-18 21:32:34,852 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2380d7f8{/jobs,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,853 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@40de326e{/jobs/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,854 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@a3157e1{/jobs/job,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,856 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2d7fc5a0{/jobs/job/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,856 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2488b313{/stages,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,857 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2ffdb815{/stages/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,863 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6b5562ae{/stages/stage,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,867 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c06021f{/stages/stage/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,870 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@67dc4560{/stages/pool,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@251778bb{/stages/pool/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,873 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@44d6ccfd{/storage,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,876 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7f3939a4{/storage/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,878 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f8ba5c9{/storage/rdd,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,881 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@124b57ca{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,882 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7cd5ba2d{/environment,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,885 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5dff35ba{/environment/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,885 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@55ef87cf{/executors,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,887 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7276619f{/executors/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,888 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@def8bad{/executors/threadDump,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,888 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1c64de71{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,905 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74a15ad9{/static,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,906 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5a11f7d3{/,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,909 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@398a9886{/api,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,913 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@74c0c86e{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,914 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@63a3404{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-12-18 21:32:34,918 INFO [restartedMain]           org.apache.spark.ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://192.168.107.131:4040
2017-12-18 21:32:35,170 INFO [restartedMain]    org.apache.spark.executor.Executor : Starting executor ID driver on host localhost
2017-12-18 21:32:35,257 INFO [restartedMain]           org.apache.spark.util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42483.
2017-12-18 21:32:35,258 INFO [restartedMain] org.apache.spark.network.netty.NettyBlockTransferService : Server created on 192.168.107.131:42483
2017-12-18 21:32:35,259 INFO [restartedMain] org.apache.spark.storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-12-18 21:32:35,260 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 192.168.107.131, 42483, None)
2017-12-18 21:32:35,265 INFO [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerMasterEndpoint : Registering block manager 192.168.107.131:42483 with 719.0 MB RAM, BlockManagerId(driver, 192.168.107.131, 42483, None)
2017-12-18 21:32:35,268 INFO [restartedMain] org.apache.spark.storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 192.168.107.131, 42483, None)
2017-12-18 21:32:35,269 INFO [restartedMain] org.apache.spark.storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 192.168.107.131, 42483, None)
2017-12-18 21:32:35,308 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1f38e03{/metrics/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:35,504 WARN [restartedMain]         org.apache.spark.SparkContext : Using an existing SparkContext; some configuration may not take effect.
2017-12-18 21:32:35,621 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/root/IdeaProjects/SparkVisualMl/spark-warehouse/').
2017-12-18 21:32:35,621 INFO [restartedMain] org.apache.spark.sql.internal.SharedState : Warehouse path is 'file:/root/IdeaProjects/SparkVisualMl/spark-warehouse/'.
2017-12-18 21:32:35,649 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@300314f3{/SQL,null,AVAILABLE,@Spark}
2017-12-18 21:32:35,657 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@46d0bb66{/SQL/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:35,664 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4201d8d8{/SQL/execution,null,AVAILABLE,@Spark}
2017-12-18 21:32:35,668 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@488dd89a{/SQL/execution/json,null,AVAILABLE,@Spark}
2017-12-18 21:32:35,681 INFO [restartedMain] org.spark_project.jetty.server.handler.ContextHandler : Started o.s.j.s.ServletContextHandler@17792ecb{/static/sql,null,AVAILABLE,@Spark}
2017-12-18 21:32:36,555 WARN [restartedMain] org.apache.spark.sql.internal.SharedState : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2017-12-18 21:32:36,796 INFO [restartedMain] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef : Registered StateStoreCoordinator endpoint
2017-12-18 21:32:36,856 WARN [restartedMain] org.apache.spark.sql.SparkSession$Builder : Using an existing SparkSession; some configuration may not take effect.
2017-12-18 21:32:37,574 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/index],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.index()
2017-12-18 21:32:37,575 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/test],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmControl.test()
2017-12-18 21:32:37,583 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/wordCountInFile],methods=[GET]}" onto public com.alibaba.fastjson.JSONObject com.spark.control.AlgorithmRestControl.getWordCountInFile(java.lang.String)
2017-12-18 21:32:37,583 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/sqls],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmRestControl.sqlExecRes(java.lang.String)
2017-12-18 21:32:37,583 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/algorithm/datasource/mysql],methods=[GET]}" onto public java.lang.String com.spark.control.AlgorithmRestControl.dataSourceForMysql(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
2017-12-18 21:32:37,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/list],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.getAccounts()
2017-12-18 21:32:37,590 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/dburl]}" onto public java.lang.String com.spark.control.TestControl.geturl()
2017-12-18 21:32:37,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/sc],methods=[GET]}" onto public org.apache.spark.SparkContext com.spark.control.TestControl.geSc()
2017-12-18 21:32:37,591 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/name],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.geName()
2017-12-18 21:32:37,596 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello/{id}],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer)
2017-12-18 21:32:37,596 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello1],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello(java.lang.Integer,java.lang.String)
2017-12-18 21:32:37,597 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/hello],methods=[GET]}" onto public java.lang.String com.spark.control.TestControl.sayHello1(java.lang.Integer)
2017-12-18 21:32:37,601 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/utils/uploadjar],methods=[POST]}" onto public org.springframework.http.ResponseEntity com.spark.control.UtilControl.uploadJar(org.springframework.web.multipart.MultipartFile)
2017-12-18 21:32:37,606 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2017-12-18 21:32:37,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2017-12-18 21:32:37,612 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2017-12-18 21:32:37,615 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2017-12-18 21:32:37,631 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-12-18 21:32:37,633 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-12-18 21:32:37,997 INFO [restartedMain] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Mapped URL path [/static/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-12-18 21:32:38,079 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@434cc5dc: startup date [Mon Dec 18 21:32:26 PST 2017]; root of context hierarchy
2017-12-18 21:32:38,092 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : Detected ResponseBodyAdvice bean in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-18 21:32:38,169 INFO [restartedMain] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : Detected ResponseBodyAdvice implementation in com.ruijc.fastjson.advice.FastJsonResponseBodyAdvice
2017-12-18 21:32:39,921 INFO [restartedMain] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer : LiveReload server is running on port 35729
2017-12-18 21:32:40,018 INFO [restartedMain] org.springframework.jmx.export.annotation.AnnotationMBeanExporter : Registering beans for JMX exposure on startup
2017-12-18 21:32:40,034 INFO [restartedMain] org.springframework.context.support.DefaultLifecycleProcessor : Starting beans in phase 2147483647
2017-12-18 21:32:40,036 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Context refreshed
2017-12-18 21:32:40,081 INFO [restartedMain] springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2017-12-18 21:32:40,123 INFO [restartedMain] springfox.documentation.spring.web.scanners.ApiListingReferenceScanner : Scanning for api listing references
2017-12-18 21:32:40,865 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:32:40,979 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:32:41,200 WARN [restartedMain] springfox.documentation.schema.property.CachingModelPropertiesProvider : Exception calculating properties for model(org.apache.spark.SparkConf) -> ModelContext{type=org.apache.spark.SparkConf, isReturnType=true}. java.lang.IllegalArgumentException: Conflicting setter definitions for property "executorEnv": org.apache.spark.SparkConf#setExecutorEnv(1 params) vs org.apache.spark.SparkConf#setExecutorEnv(1 params)
2017-12-18 21:32:41,263 INFO [restartedMain] springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator : Generating unique operation named: sayHelloUsingGET_1
2017-12-18 21:32:41,470 INFO [restartedMain] org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8081 (http)
2017-12-18 21:32:41,483 INFO [restartedMain]                       com.Application : Started Application in 17.267 seconds (JVM running for 19.451)
2017-12-18 21:33:24,376 INFO [http-nio-8081-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-12-18 21:33:24,377 INFO [http-nio-8081-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started
2017-12-18 21:33:24,415 INFO [http-nio-8081-exec-1] org.springframework.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 38 ms
2017-12-18 21:33:24,436 INFO [http-nio-8081-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,498 INFO [http-nio-8081-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] INITIALIZING TEMPLATE ENGINE
2017-12-18 21:33:24,623 INFO [http-nio-8081-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] INITIALIZING TEMPLATE RESOLVER: org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver
2017-12-18 21:33:24,626 INFO [http-nio-8081-exec-1] org.thymeleaf.templateresolver.AbstractTemplateResolver : [THYMELEAF] TEMPLATE RESOLVER INITIALIZED OK
2017-12-18 21:33:24,627 INFO [http-nio-8081-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] INITIALIZING MESSAGE RESOLVER: org.thymeleaf.spring4.messageresolver.SpringMessageResolver
2017-12-18 21:33:24,629 INFO [http-nio-8081-exec-1] org.thymeleaf.messageresolver.AbstractMessageResolver : [THYMELEAF] MESSAGE RESOLVER INITIALIZED OK
2017-12-18 21:33:24,670 INFO [http-nio-8081-exec-1]          org.thymeleaf.TemplateEngine : [THYMELEAF] TEMPLATE ENGINE INITIALIZED
2017-12-18 21:33:24,808 INFO [http-nio-8081-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,809 INFO [http-nio-8081-exec-4]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,809 INFO [http-nio-8081-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,808 INFO [http-nio-8081-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,811 INFO [http-nio-8081-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,827 INFO [http-nio-8081-exec-7]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,953 INFO [http-nio-8081-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,971 INFO [http-nio-8081-exec-8]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,980 INFO [http-nio-8081-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,992 INFO [http-nio-8081-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:24,979 INFO [http-nio-8081-exec-10]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,009 INFO [http-nio-8081-exec-1]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,015 INFO [http-nio-8081-exec-3]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,023 INFO [http-nio-8081-exec-5]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,277 INFO [http-nio-8081-exec-6]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,376 INFO [http-nio-8081-exec-9]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,397 INFO [http-nio-8081-exec-2]           com.spark.config.CorsFilter : 过滤器被使用
2017-12-18 21:33:25,408 WARN [http-nio-8081-exec-2] org.springframework.web.servlet.PageNotFound : No mapping found for HTTP request with URI [/favicon.ico] in DispatcherServlet with name 'dispatcherServlet'
