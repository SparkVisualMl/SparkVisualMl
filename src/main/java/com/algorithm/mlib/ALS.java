package com.algorithm.mlib;import com.algorithm.interfaces.AlgorithmInterface;import org.apache.spark.sql.Row;import java.util.HashMap;import org.apache.spark.sql.Dataset;public class ALS implements AlgorithmInterface {    Dataset<Row> dataset = null;    /**     * 初始化算法参数     * @return HashMap<String,String> args     */    @Override    public HashMap<String,String> getArgs() {        HashMap<String,String> map = new HashMap();        map.put("MaxIter","5");        map.put("RegParam","0.01");        map.put("UserCol","userId");        map.put("ItemCol","movieId");        map.put("ColdStartStrategy","drop");        map.put("MetricName","rmse");        map.put("LabelCol","rating");        map.put("PredictionCol","prediction");        map.put("UserPrecNum","10");        map.put("ItemPrecNum","10");        return map;    }    /**     * 初始化输入数据     * @param dataset Dataset<Row> dataset     */    @Override    public void setInputData(Dataset dataset) {        this.dataset = dataset;    }    @Override    public Dataset<Row> getInputData() {        return this.dataset;    }    @Override    public void setOutputData() {    }    @Override    public Dataset getOutPutData() {        return null;    }    @Override    public void compute() {        HashMap<String,String > args = getArgs();        Dataset<Row> dataset = getInputData();    }}